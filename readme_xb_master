https://github.com/ssbandjl/linux.git
upstream: git remote add upstream https://github.com/torvalds/linux.git
git remote add upstream
git fetch upstream
git merge upstream/master

代码: https://elixir.bootlin.com/linux/v6.0-rc1/source/drivers/nvme/host/pci.c#L504

nvme协议参考: https://github.com/andyBrake/andyBrake.github.io/blob/master/doc/nvme_express.md


----- nvme start -----
nvme
static struct blk_mq_ops nvme_mq_ops -> struct blk_mq_ops 
static const struct blk_mq_ops bsg_mq_ops = {
    .queue_rq		= bsg_queue_rq,
    .init_request		= bsg_init_rq,
    .exit_request		= bsg_exit_rq,
    .complete		= bsg_complete,
    .timeout		= bsg_timeout,
};

驱动目录: drivers/nvme/Makefile
参考: https://mp.weixin.qq.com/s/GKVIY_NOXDfUCOho4zBMzw
Kconfig 文件的作用是：
1.控制make menuconfig时， 出现的配置选项；
2.根据用户配置界面的选择，将配置结果保存在.config 配置文件（该文件将提供给Makefile使用，用以决定要编译的内核组件以及如何编译）

drivers/nvme/host/core.c
module_init(nvme_core_init) -> static int __init nvme_core_init(void)
alloc_chrdev_region nvme
class_create("nvme")

target驱动实现: https://github.com/torvalds/linux/commit/8f000cac6e7a6edca7ab93bafc7ed28b27c1545b
enum {
    NVMET_RDMA_REQ_INLINE_DATA	= (1 << 0),
    NVMET_RDMA_REQ_INVALIDATE_RKEY	= (1 << 1),
};
所有 NVMe 逻辑都位于通用目标中，该模块只是在它与 RDMA 子系统中的通用代码之间提供了一个小粘合剂。



drivers/nvme/target/rdma.c
static int __init nvmet_rdma_init(void)
ib_register_client -> drivers/infiniband/core/device.c -> int ib_register_client -> IB 驱动程序的上层用户可以使用 ib_register_client() 来注册 IB 设备添加和删除的回调。 添加 IB 设备时，将调用每个已注册客户端的 add 方法（按照客户端注册的顺序），而当删除设备时，将调用每个客户端的 remove 方法（按照客户端注册的相反顺序）。 另外，调用ib_register_client()时，客户端会收到所有已经注册的设备的add回调
nvmet_register_transport -> int nvmet_register_transport
    down_write
    up_write

EXPORT_SYMBOL(ib_register_client) 导出符号表


内存区域: zone_type
内核将zone按照不同的使用用途划分为不同的type，位于include/linux/
mmzone.h文件中：
ZONE_DMA:主要为了兼容ISA设备，在该设备中DMA只能访问低于16M内存地址，只能将其单独划出来进行管理。
ZONE_DMA32:针对32位系统进行兼容，一般在使用ZONE_DMA时由于16M内存过小，而有些设备DMA寻址能达到32位，在64位系统中为了能够兼容32位系统，划分了ZONE_DMA32，该物理内存为低于32位，以满足32位寻址的DMA。
ZONE_NORMAL：使用正常的物理内存区域，大部分申请的内存都使用的该区域。
ZONE_HIGHMEM:只会出现在32位系统中，这是由于在32位系统中，物理内存最多能够直接映射到内核中896M内存，但是为了兼容大于896M内存系统，将大于896M的高端内存以弥补地址空间不足的问题。高端内存映射不会采用一一映射，而是在使用的时候才映射，在64位系统中由于使用空间足够，不需要ZONE_HIGHMEM。
ZONE_MOVEABLE:可移动或收收区域，该zone一般称为伪ZONE，所管理的物理内存来自于ZONE_NORMAL或者ZONE_HIGHMEM中根据配置划分出的一片物理内存为ZONE_MOVABLE


内存块标签:
enum memblock_flags {
    MEMBLOCK_NONE		= 0x0,	/* No special request */
    MEMBLOCK_HOTPLUG	= 0x1,	/* hotpluggable region */
    MEMBLOCK_MIRROR		= 0x2,	/* mirrored region */
    MEMBLOCK_NOMAP		= 0x4,	/* don't add to kernel direct mapping */
    MEMBLOCK_DRIVER_MANAGED = 0x8,	/* always detected via a driver */
    MEMBLOCK_RSRV_NOINIT	= 0x10,	/* don't initialize struct pages */
};


iopath,
write(fd, "pilgrimtao is cool", 18)
    ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count)
        vfs_write(f.file, buf, count, ppos)
            if (file->f_op->write) -> 首选普通写
                ret = file->f_op->write(file, buf, count, pos)
            else if (file->f_op->write_iter) -> 如果没有实现普通写,但是实现了迭代写, 则调用同步写
                ret = new_sync_write(file, buf, count, pos)
                    call_write_iter(filp, &kiocb, &iter)
                        return file->f_op->write_iter(kio, iter) -> fs.h, -> xfs_file_write_iter
                            if (IS_DAX(inode)) -> 如果是直接访问（Direct Access，DAX）
                                return xfs_file_dax_write(iocb, from) -> ...
                            if (iocb->ki_flags & IOCB_DIRECT) -> 如果在写的逻辑__generic_file_write_iter里面，发现设置了IOCB_DIRECT，则调用generic_file_direct_write，里面同样会调用address_space的direct_IO的函数，将数据直接写入硬盘: https://www.cnblogs.com/luozhiyun/p/13061199.html
                                ret = xfs_file_dio_write(iocb, from)
                            return xfs_file_buffered_write(iocb, from) -> 默认带缓存的写
                                iomap_file_buffered_write -> iomap_iter -> .iomap_begin -> xfs_buffered_write_iomap_begin


drivers/infiniband/core/verbs.c
struct ib_pd *__ib_alloc_pd


blk_mq_rdma_map_queues

nvme块层队列函数操作表
static const struct blk_mq_ops nvme_mq_ops = {
    .queue_rq	= nvme_queue_rq,
    .queue_rqs	= nvme_queue_rqs,
    .complete	= nvme_pci_complete_rq,
    .commit_rqs	= nvme_commit_rqs,
    .init_hctx	= nvme_init_hctx,
    .init_request	= nvme_pci_init_request,
    .map_queues	= nvme_pci_map_queues,
    .timeout	= nvme_timeout,
    .poll		= nvme_poll,
};






nvme请求入队:
static blk_status_t nvme_queue_rq(struct blk_mq_hw_ctx *hctx, const struct blk_mq_queue_data *bd)
    ret = nvme_prep_rq(dev, req) -> 准备nvme请求
        nvme_setup_cmd(req->q->queuedata, req) -> 设置nvme命令(重要函数)
        nvme_start_request(req)



static struct blk_mq_hw_ctx *blk_mq_alloc_and_init_hctx(struct blk_mq_tag_set *set, struct request_queue *q, int hctx_idx, int node)
    static int blk_mq_init_hctx(struct request_queue *q, struct blk_mq_tag_set *set, struct blk_mq_hw_ctx *hctx, unsigned hctx_idx)
        初始化块层的IO入队请求
        static int blk_mq_init_request(struct blk_mq_tag_set *set, struct request *rq, unsigned int hctx_idx, int node)
            set->ops->init_request(set, rq, hctx_idx, node) -> static int nvme_pci_init_request(struct blk_mq_tag_set *set, struct request *req, unsigned int hctx_idx, unsigned int numa_node)




static int blk_mq_alloc_rqs(struct blk_mq_tag_set *set,struct blk_mq_tags *tags, unsigned int hctx_idx, unsigned int depth)



host头文件: 
drivers/nvme/host/nvme.h



blk_status_t nvme_setup_cmd(struct nvme_ns *ns, struct request *req)
{
    struct nvme_command *cmd = nvme_req(req)->cmd;
    blk_status_t ret = BLK_STS_OK;

    if (!(req->rq_flags & RQF_DONTPREP))
        nvme_clear_nvme_request(req);

    switch (req_op(req)) {
    case REQ_OP_DRV_IN:
    case REQ_OP_DRV_OUT:
        /* these are setup prior to execution in nvme_init_request() */
        break;
    case REQ_OP_FLUSH:
        nvme_setup_flush(ns, cmd);
        break;
    case REQ_OP_ZONE_RESET_ALL:
    case REQ_OP_ZONE_RESET:
        ret = nvme_setup_zone_mgmt_send(ns, req, cmd, NVME_ZONE_RESET);
        break;
    case REQ_OP_ZONE_OPEN:
        ret = nvme_setup_zone_mgmt_send(ns, req, cmd, NVME_ZONE_OPEN);
        break;
    case REQ_OP_ZONE_CLOSE:
        ret = nvme_setup_zone_mgmt_send(ns, req, cmd, NVME_ZONE_CLOSE);
        break;
    case REQ_OP_ZONE_FINISH:
        ret = nvme_setup_zone_mgmt_send(ns, req, cmd, NVME_ZONE_FINISH);
        break;
    case REQ_OP_WRITE_ZEROES:
        ret = nvme_setup_write_zeroes(ns, req, cmd);
        break;
    case REQ_OP_DISCARD:
        ret = nvme_setup_discard(ns, req, cmd);
        break;
    case REQ_OP_READ:
        ret = nvme_setup_rw(ns, req, cmd, nvme_cmd_read);
        break;
    case REQ_OP_WRITE:
        ret = nvme_setup_rw(ns, req, cmd, nvme_cmd_write);
        break;
    case REQ_OP_ZONE_APPEND:
        ret = nvme_setup_rw(ns, req, cmd, nvme_cmd_zone_append);
        break;
    default:
        WARN_ON_ONCE(1);
        return BLK_STS_IOERR;
    }

    cmd->common.command_id = nvme_cid(req);
    trace_nvme_setup_cmd(req, cmd);
    return ret;
}


nvme io命令:
参考: include/linux/nvme.h
enum nvme_opcode {
    nvme_cmd_flush		= 0x00,
    nvme_cmd_write		= 0x01,
    nvme_cmd_read		= 0x02,
    nvme_cmd_write_uncor	= 0x04,
    nvme_cmd_compare	= 0x05,
    nvme_cmd_write_zeroes	= 0x08,
    nvme_cmd_dsm		= 0x09,
    nvme_cmd_verify		= 0x0c,
    nvme_cmd_resv_register	= 0x0d,
    nvme_cmd_resv_report	= 0x0e,
    nvme_cmd_resv_acquire	= 0x11,
    nvme_cmd_resv_release	= 0x15,
    nvme_cmd_zone_mgmt_send	= 0x79,
    nvme_cmd_zone_mgmt_recv	= 0x7a,
    nvme_cmd_zone_append	= 0x7d,
    nvme_cmd_vendor_start	= 0x80,
};

封装读写命令:
static inline blk_status_t nvme_setup_rw(struct nvme_ns *ns, struct request *req, struct nvme_command *cmnd, enum nvme_opcode op)
    ...
    cmnd->rw.opcode = op;
    cmnd->rw.slba = cpu_to_le64(nvme_sect_to_lba(ns, blk_rq_pos(req)))
    cmnd->rw.length = cpu_to_le16((blk_rq_bytes(req) >> ns->lba_shift) - 1)
    ...

----- nvme end -----


blk:
Software Staging Queue 會以 struct blk_mq_ctx 這個結構來表示
Hardware Dispatch Queue 會以 struct blk_mq_hw_ctx 這個結構來表示



blk_rq_timed_out_timer
綜合以上，當 blk_mq_start_request 被呼叫而開始一個 request 的處理流程。blk_mq_start_request 會執行 blk_add_timer -> mod_timer。藉此讓之前提到的 timer task blk_rq_timed_out_timer 在一段時間後被執行。而這個 timer task 最後就會啟動 &q->timeout_work 下註冊的 blk_mq_timeout_work，後者最後可以透過 blk_mq_check_expired -> blk_mq_rq_timed_out 去觸發 timeout 方法。
而 NVMe driver 中定義的 timeout 方法為 nvme_timeout。不過由於其本身內容與 blk-mq 自身機制關係較少，比較多是與 NVMe 相關，細節我們就不在此章節釐清


nvme完成io:
queue_request_irq
static irqreturn_t nvme_irq(int irq, void *data)
    nvme_poll_cq nvme_poll
        while (nvme_cqe_pending(nvmeq))
            nvme_handle_cqe(nvmeq, iob, nvmeq->cq_head)
                nvme_pci_complete_rq(req)
            nvme_update_cq_head(nvmeq)
        nvme_ring_cq_doorbell(nvmeq) -> 敲环形完成队列的门铃
            nvme_dbbuf_update_and_check_event


nvme块设备:
nvme块设备驱动的注册位置在哪呢？居然在nvme_scan_work里面，它我们前面分析过，启动nvme设备的一堆work queue里面就有它。它内部的操作是遍历nvme设备的所有namespace，发现某个ns不存在就会用nvme_alloc_ns去注册一个块设备并加入到ns链表中，所以nvme设备的namespace才是一个块设备，而nvme设备是被视为了一个字符设备。这个块设备的内存结构为nvme_ns，操作集则是nvme_fops，一堆函数里面重点看看nvme_ioctl，这个函数和最开始注册的字符设备驱动的nvme_dev_ioctl的名称和内部实现都很像，看到这里我已经有点懵了，怎么整了两套ioctrl出来，实现也像。为什么要整两套出来，暂时没想通。但是两者还是有一点区别的，字符设备处理了NVME_IOCTL_ADMIN_CMD、NVME_IOCTL_IO_CMD、NVME_IOCTL_RESET、NVME_IOCTL_SUBSYS_RESET、NVME_IOCTL_RESCAN；而块设备处理了NVME_IOCTL_ADMIN_CMD、NVME_IOCTL_IO_CMD、NVME_IOCTL_ID、NVME_IOCTL_SUBMIT_IO。

3-1、块设备结构nvme_ns内部包含了request_queue,gendisk这两个块设备驱动必要成员。request_queue就用nvme_ctrl的tagset（是个指针，指向的是nvme_dev结构中的那个tagset）创建出来的，所以这里才去创建了nvme设备io请求的request queue哦。disk里面就会注册这个块设备的操作集struct block_device_operations nvme_fops，按照块设备的实现机制，这个操作集里面是不包含读写操作的，读写通过前面的queue来下发。而下发的实现就是通过nvme_submit_io这个函数来实现的，前面也已经提到过了。
3-2、NVME_IOCTL_SUBMIT_IO，NVME_IOCTL_ADMIN_CMD 这些命令宏是定义在公共头文件内的，所以用户态程序可见。猜测用户态下发命令请求，io请求的时候，应该都是通过用户态的ioctrl来实现的，连读写请求也是哦，因为仔细看nvme_submit_io这个函数内的实现，是将用户态的io请求参数拷贝到了内核空间，并且使用了里面的addr字段，表示数据所在的地址


nvme_sq_copy_cmd
static inline void nvme_write_sq_db(struct nvme_queue *nvmeq, bool write_sq)
    nvmeq->last_sq_tail = nvmeq->sq_tail -> 然后向SQ的doorbell里写入tail信息

nvme_handle_cqe
    nvme_pci_complete_rq


intel e810,
commit: https://lore.kernel.org/all/20210520143809.819-7-shiraz.saleem@intel.com/T/
以下补丁系列介绍了适用于 X722 iWARP 设备的统一英特尔 RDMA (irdma) 以太网协议驱动程序以及支持 iWARP 和 RoCEv2 的新 E810 设备。 irdma 模块取代了 X722 的旧版 i40iw 模块，并扩展了已为 i40iw 定义的 ABI。 它向后兼容旧版 X722 rdma 核心提供程序 (libi40iw)。 X722 和 E810 是支持 RDMA 的 PCI 网络设备。 该父设备的 RDMA 块通过使用最近为 5.11 内核添加的核心辅助总线基础结构导出到“irdma”的辅助设备来表示。 父 PCI netdev 驱动程序“i40e”和“ice”使用封装的私有数据/操作注册辅助 RDMA 设备，这些数据/操作绑定到在 irdma 模块中注册的辅助驱动程序。 该补丁集最初作为 RFC 提交，我们在其中得到了反馈，提出了 RDMA 驱动程序附加到 netdev PCI 驱动程序 [1] 拥有的 PCI 设备的通用方案。 探索了使用平台总线和 MFD 的解决方案，但被社区拒绝，共识是添加新的总线基础设施来支持这种使用模型。 该系列的进一步修订以及辅助总线已提交[2]。 此时，Greg KH 要求我们将辅助总线审查和修订流程纳入内部邮件列表，并获得受人尊敬的内核贡献者的认可，以及包括 Nvidia 在内的所有主要利益相关者的共识（用于 mlx5 子功能使用） -案例）和英特尔声音驱动程序。 这个过程花了一段时间，并阻碍了该 netdev/irdma 系列的进一步开发/审查。 辅助总线最终在5.11中被合并。 在本次提交的 v1-->v2 和 v4-->v5 之间，IIDC 根据反馈进行了重大重写，我们希望它现在更符合社区的需求。 目前，E810 默认为 RoCEv2。 在未来的补丁中，将通过 devlink 提供对协议切换到 iWARP 的运行时支持。 该系列是针对 5.13-rc1 构建的，目前包含 netdev 补丁以方便查看。 这包括更新“ice”驱动程序以提供 RDMA 支持，并将“i40e”驱动程序转换为使用辅助总线基础设施。 一旦社区确认此提交，就可以提交共享拉取请求。 v5-->v6：*将 aux 设备名称从 <模块>.intel_rdma_<rdma 协议>.<num> 压缩为 <模块>.<rdma 协议>.<num> *修复 alloc_hw_stats 的驱动程序 API，仅导出端口统计信息 sysfs v4-->v5：*导出所有 IIDC 核心操作回调并从 irdma 直接调用。 irdma 依赖于 i40e 和ice。 *删除协议切换的 devlink 运行时选项。 E810 上默认为 RoCEv2。 将通过 [3] 中讨论的社区工作添加切换到 IWARP 的运行时选项 *导出 iidc_auxiliary_dev 中的ice_pf 指针，该指针在 irdma drv.probe() 中可用，并使用它派生 PCI 函数相关子字段。 *使用定义来设置辅助开发名称，而不是 kasprintf。 *删除 IIDC 中的所有未来配置。 删除 IIDC 中的多个辅助驱动程序支持。 *添加核心驱动程序的辅助操作回调以直接在 iidc_auxiliary_drv 对象中使用。 *修复ice中的auxdevice ida资源泄漏，并更新到i40e中最新的ida API。 *删除 IIDC 和 irdma 驱动程序中任何残留的 VF 残渣。 *简化 IIDC API 以添加和删除 RDMA qset。 删除 iidc_res_base 联合使用。 *使用直接调用转换 irdma 中的所有单一实现间接 .ops 回调 *添加 rsvd 仅用于 irdma ABI 中的对齐 *清理 iw_memreg_type enum v3-->v4： * 修复冰补丁中的 W=1 警告 * 修复由 用于创建用户 AH 和多播的 pyverbs * 修复在 v2 提交 v2-->v3 中移植到 FIELD_PREP 期间引入的快速寄存器的描述符集问题： * rebase rdma for-next。 适应核心更改'1fb7f8973f51（“RDMA：支持超过255个rdma端口”）' * irdma Kconfig更新以符合linux编码风格。 * 修复 0-day 构建问题 * 删除 rdma_resource_limits 选择器 devlink 参数。 按照 Parav 的建议提交补丁以使用 devlink 资源。 * Ice idc 中的缩写大写。 例如 'aux' 到 'AUX' v1-->v2： * 删除 IIDC 通道操作 - 打开、关闭、peer_register 和peer_unregister。 及其所有相关的FSM都在ice PCI核心驱动程序中。 * 在发出 IIDC ops 回调时，在ice PCI 核心驱动程序中使用 device_lock。 * 从共享 IIDC 标头中删除peer_* 措辞，并使用 iidc_core*/iidc_auxiliary* 重命名结构和通道操作。 * 在irdma gen2辅助驱动程序中开始时分配ib_device并在drv.probe()结束时注册它。 * 在大多数驱动程序中广泛使用 ibdev_* 打印删除 idev_to_dev、ihw_to_dev 宏，因为新打印方案中不再需要这些宏。 * 不要修改 ABI 版本。 irdma 为 6。 维护 irdma ABI 版本。 5 表示旧版 i40iw 用户-提供商兼容性。 * 在 irdma_alloc_ucontext 中添加边界检查，以防止与 < 4 用户空间提供程序版本的绑定失败。 * 从 irdma 中删除 devlink。 添加 2 个新的 rdma 相关内容devlink 参数添加到ice PCI 核心驱动程序中。 * 在描述符字段的获取/设置上使用FIELD_PREP/FIELD_GET/GENMASK，而不是自行开发的LS_*/RS_*。 * 在 irdma 中绑定 2 个独立的辅助驱动程序 - 一个用于第 1 代，一个用于第 2 代和未来的设备。 * 其他。 irdma 中的驱动程序修复 [1] https://patchwork.kernel.org/project/linux-rdma/patch/20190215171107.6464-2-shiraz.saleem@intel.com/ [2] https://lore.kernel.org/ linux-rdma/20200520070415.3392210-1-jeffrey.t.kirsher@intel.com/ [3] https://lore.kernel.org/linux-rdma/20210407224631.GI282464@nvidia.com/ Dave Ertman (4)：iidc ：引入iidc.hice：初始化RDMA支持ice：实现iidc操作ice：注册辅助设备以提供RDMA Michael J. Ruhl（1）：RDMA/irdma：为CM Mustafa Ismail添加动态跟踪（13）：RDMA/irdma： 注册辅助驱动程序并实现专用通道 OP RDMA/irdma：实现设备初始化定义 RDMA/irdma：实现硬件管理队列 OP RDMA/irdma：添加 HMC 后备存储设置函数 RDMA/irdma：添加特权 UDA 队列实现 RDMA/irdma：添加 QoS 定义 RDMA/irdma：添加连接管理器 RDMA/irdma：添加 PBLE 资源管理器 RDMA/irdma：实现设备支持的动词 API RDMA/irdma：添加 RoCEv2 UD OP 支持 RDMA/irdma：添加用户/内核共享库 RDMA/irdma：添加杂项 实用程序定义 RDMA/irdma：添加 ABI 定义 Shiraz Saleem (4)：i40e：为 aux 总线转换准备 i40e 标头 i40e：注册辅助设备以提供 RDMA RDMA/irdma：添加 irdma Kconfig/Makefile 并删除 i40iw RDMA/irdma：更新维护者 文件



drivers/net/ethernet/intel/ice/ice_main.c, e810, 
module_init(ice_module_init)
    pr_info("%s\n", ice_driver_string); -> Intel(R) Ethernet Connection E800 Series Linux Driver -> Copyright (c) 2018, Intel Corporation
    ice_adv_lnk_speed_maps_init -> ice：重构查找建议的链路速度，重构ice_get_link_ksettings以使用强制速度到链接模式映射
        ethtool_forced_speed_maps_init(ice_adv_lnk_speed_maps,
            linkmode_set_bit_array -> static inline void linkmode_set_bit_array
    alloc_workqueue
    ice_debugfs_init()
    pci_register_driver


static struct pci_driver ice_driver = {
	.name = KBUILD_MODNAME,
	.id_table = ice_pci_tbl,
	.probe = ice_probe,
	.remove = ice_remove,
#ifdef CONFIG_PM
	.driver.pm = &ice_pm_ops,
#endif /* CONFIG_PM */
	.shutdown = ice_shutdown,
	.sriov_configure = ice_sriov_configure,
	.sriov_get_vf_total_msix = ice_sriov_get_vf_total_msix,
	.sriov_set_msix_vec_count = ice_sriov_set_msix_vec_count,
	.err_handler = &ice_pci_err_handler
};


drivers/net/ethernet/intel/ice/ice_main.c
.probe = ice_probe,
ice_probe(struct pci_dev *pdev, const struct pci_device_id __always_unused *ent)
    struct ice_pf *pf
    struct ice_hw *hw
    is_kdump_kernel -> 当在 kdump 内核下时，在启用设备之前启动重置，以清除任何挂起的 DMA 事务。 这些事务可能会导致某些系统在执行下面的 pcim_enable_device() 时进行机器检查
        pci_save_state
        pci_clear_master
        pcie_flr -> ice：在故障转储内核中首先重置 当系统在发生紧急情况后启动到故障转储内核时，ice 网络设备可能仍然有挂起的事务，这些事务可能会在设备重新启用时导致错误或机器检查。 这可以防止故障转储内核加载驱动程序或收集故障数据。 为了避免此问题，请在崩溃内核上启用之前，通过 PCIe 配置空间在 Ice 设备上执行功能级别重置 (FLR)。 这将清除所有未完成的事务并停止所有队列和中断。 恢复FLR后的配置空间，否则测试时发现驱动加载不成功。 以下序列导致原始问题： - 使用 modprobe ice 加载ice驱动程序 - 使用 2 个 VF 启用 SR-IOV：echo 2 > /sys/class/net/eth0/device/sriov_num_vfs - 使用 echo c > /proc 触发崩溃 /sysrq-trigger - 使用 modprobeice 再次加载 Ice 驱动程序（或让它自动加载） - 系统在 pcim_enable_device() 期间再次崩溃
        pci_restore_state
    pcim_enable_device -> devres 是一种资源管理机制, 类似于一种垃圾收集处理器. 而资源的处理时机在 driver 的 install / remove 时候. 这样我们在为 device 分配相关资源之后, 就不必要关心如何释放它们了. 与 device 相关的资源有 memory / dma / iomap / regmap / interrupt / gpio 等, 这些资源都可以用 devres 机制管理起来, 使用相关资源封闭的 devres 接口, 就可以让这些资源自动销毁, 设备资源管理: https://blog.csdn.net/tiantianhaoxinqing__/article/details/125959030
    pcim_iomap_regions
    ice_allocate_pf -> 分配物理方法, 为该设备分配一个 devlink 实例，并将私有区域作为 PF 结构返回。 通过添加一个操作在展开时将其删除，可以通过 devres 来跟踪 devlink 内存
        devlink_alloc(&ice_devlink_ops
        devm_add_action_or_reset(dev, ice_devlink_free, devlink)
    dma_set_mask_and_coherent
    pci_set_master
    ...
    pcim_iomap_table
    pci_read_config_byte PCI_REVISION_ID
    ice_set_ctrlq_len
    netif_msg_init -> static inline u32 netif_msg_init
    ice_init
        ice_init_dev
            ice_init_hw
                ice_set_mac_type
                FIELD_GET(PF_FUNC_RID_FUNC_NUM_M, rd32(hw, PF_FUNC_RID)) -> 读寄存器
                ice_reset
                    wr32(hw, GLGEN_RTRIG, val)
                    ice_check_reset
                ice_get_itr_intrl_gran -> 带宽
                ice_create_all_ctrlq
                    ice_init_all_ctrlq
                        ice_init_ctrlq(hw, ICE_CTL_Q_ADMIN)
                            ice_adminq_init_regs
                                ICE_CQ_INIT_REGS
                        ice_init_check_adminq
                            ice_aq_get_fw_ver
                                ice_fill_dflt_direct_cmd_desc ice_aqc_opc_get_ver
                                ice_aq_send_cmd
                                    ice_sq_send_cmd_retry
                                        ice_sq_send_cmd -> ATQ
                        ice_shutdown_ctrlq
                            ice_shutdown_sq
                                停止管理队列上的任务
                                ICE_FREE_CQ_BUFS
                                ice_free_cq_ring
                                    dmam_free_coherent
                            ice_shutdown_rq
                        ...
                        ice_init_ctrlq(hw, ICE_CTL_Q_SB)
                        ice_init_ctrlq(hw, ICE_CTL_Q_MAILBOX)
                ice_fwlog_init -> Ice：配置固件日志记录，用户希望能够通过从 E8xx 设备检索固件日志来调试固件问题。 使用 debugfs 允许用户配置固件日志记录的日志级别和消息数量。 如果 E8xx 支持固件日志记录，则将在ice 驱动程序的 PCI 设备 ID 下创建文件“fwlog”。 如果该文件不存在，则 E8xx 不支持固件日志记录或系统上未启用 debugfs。 用户想要做的一件事是控制报告哪些事件。 用户可以读写“fwlog/modules/<模块名称>”来获取/设置日志级别。 固件中的每个模块都支持将 ht 记录为“fwlog/modules”下的文件，支持读取（查看当前日志级别是什么）和写入（更改日志级别）
                    ice_fwlog_set_supported
                        ice_aqc_opc_fw_logs_query
                    ice_fwlog_supported
                    ice_fwlog_get
                    ice_fwlog_alloc_ring_buffs
                    ice_debugfs_fwlog_init -> 创建debugfs所需的目录和文件, 关联相应的函数操作
                        debugfs_create_dir(name, ice_debugfs_root)
                        ...
                ice_clear_pf_cfg -> 清除任何现有 PF 配置（VSI、VSI 列表、交换机规则、端口配置、流量导向器过滤器等）
                    cmd ice_aqc_opc_clear_pf_cfg
                wr32(hw, PFQF_FD_ENA, PFQF_FD_ENA_FD_ENA_M) -> 启用流过滤, Ice：初始化FlowDirector资源，FlowDirector允许基于ntuple规则进行重定向。 规则使用 ethtool set-ntuple 接口进行编程。 支持的操作包括重定向到队列和丢弃。 设置初始框架来处理 Flow Director 过滤器。 创建和分配资源来管理过滤器并将过滤器编程到硬件。 过滤器通过边带接口进行处理； 创建控制VSI来管理通过边带的通信和处理请求。 分配资源后，更新硬件表以接受完美的过滤器
                ice_clear_pxe_mode
                ice_init_nvm
                    无论 NVM 编程模式如何，都会存储 SR 大小，因为工厂生产线中可能会使用空白模式
                    ice_discover_flash_size -> ice：创建flash_info结构和单独的NVM版本，ice_nvm_info结构已经成为与flash版本相关的所有字段的垃圾场。 它包含 NVM 版本和 EETRACK id、OptionROM 信息结构、闪存大小、ShadowRAM 大小等。 未来的更改将添加从非活动 NVM 组读取 NVM 版本和 EETRACK ID 的功能。 为了使这更简单，将这些 NVM 版本信息字段提取到它们自己的结构中非常有用。 将ice_nvm_info重命名为ice_flash_info，并创建一个单独的ice_nvm_info结构，其中将包含eetrack和NVM映射版本。 将netlist_ver结构移动到ice_flash_info中，并重命名为ice_netlist_info以保持一致性。 修改静态ice_get_orom_ver_info以将option rom结构作为指针。 这使得硬件结构的哪一部分被修改更加明显。 对ice_get_netlist_ver_info 执行相同操作。 引入一个新的ice_get_nvm_ver_info函数，该函数将类似于ice_get_orom_ver_info和ice_get_netlist_ver_info，用于保持NVM版本提取代码共置
                        ice_acquire_nvm
                        ice_read_flat_nvm
                    ice_determine_active_flash_banks -> ice：缓存 NVM 模块库信息，ice flash 包含 NVM、Option ROM 和 Netlist 模块各两个副本。 每个存储体都有一个指针字和一个大小字。 为了正确地从活动闪存组中读取数据，驱动程序必须手动计算偏移量。 在 NVM 初始化期间，读取 Shadow RAM 控制字并确定每个 NVM 模块的哪个存储体处于活动状态。 此外，缓存大小和指针值以用于计算正确的偏移量
                    读取 Shadow RAM 控制字并确定 NVM、OROM 和网表模块的哪些存储体处于活动状态。 还读取并计算关联的指针和大小。 然后将这些值缓存到ice_flash_info结构中以供以后使用，以便计算从活动模块读取的正确偏移量
                        ice_read_sr_word
                    ice_get_nvm_ver_info -> ice：引入从闪存模块读取的功能，当从设备的闪存读取时，ice驱动程序有两个可用的接口。 首先，它可以通过允许指定模块 ID 的固件使用中介接口。 这允许从活动闪存组的特定模块读取。 第二个可用的接口是执行平面读取。 这允许对整个闪存的完全访问。 然而，使用它需要软件来处理计算模块位置并解释指针地址。 虽然大多数所需数据都可以通过方便的第一个接口访问，但某些闪存内容却不能。 这包括与选项 ROM 和 NVM 存储体相关的 CSS 标头信息，以及对用作执行闪存更新的暂存空间的“非活动”存储体的任何访问。 为了访问所有相关的闪存内容，软件必须使用平面读取。 不是强制所有流执行平面读取计算，而是引入一个用于从闪存读取的新抽象：ice_read_flash_module。 该函数提供了从请求模块的活动或非活动闪存库中读取数据的抽象。 该接口与通过固件提供的抽象非常相似，但允许访问附加模块，并提供请求访问两个闪存组的机制。 乍一看，这种抽象允许精确指定调用者希望读取的银行（第一或第二）可能是有意义的。 这实现起来更简单，但使用起来更困难。 实际上，大多数呼叫者只知道他们想要活跃的银行还是不活跃的银行。 不是强迫调用者自己确定从哪个存储体读取，而是根据“活动”与“非活动”来实现ice_read_flash_module。 这显着简化了调用者级别的实现，并且是对闪存内容的更有用的抽象。 利用这个新接口重构主要 NVM 版本信息的读取。 不使用固件中介的 ShadowRAM 函数，而是使用ice_read_flash_module 抽象。 为此，请注意 NVM 的大多数读取都将以 2 字节字块的形式进行。 为了简化这种情况下ice_read_flash_module的使用，引入了ice_read_nvm_module。 这是ice_read_flash_module的一个简单包装，它获取NVM存储体的正确指针地址，并将2字节字格式强制传递给调用者。 读取 NVM 版本时，某些字段是从 Shadow RAM 中读取的。 Shadow RAM 是闪存的第一个 64KB，在设备加载期间填充。 大多数字段是从活动 NVM 组内的部分复制的。 为了从活动和非活动 NVM 存储体中读取这些数据，我们需要的不是从闪存的前 64KB 读取，而是从正确的偏移量读取到 NVM 存储体中。 为此引入ice_read_nvm_sr_copy。 该函数包装了ice_read_nvm_module，并具有与ice_read_sr_word相同的接口，不同之处在于允许调用者指定是否读取活动或非活动闪存组。 通过此更改，现在可以轻松重构ice_get_nvm_ver_info以使用软件介导的ice_read_flash_module接口进行读取，而不是依赖于固件介导的接口。 这将在以下更改中使用，以实现对 devlink 信息报告中存储版本的支持。 此外，将使用和扩展整个ice_read_flash_module接口以支持所有三个主要闪存组，并另外支持读取闪存映像安全修订信息
                    ice_get_orom_ver_info -> ice：通过devlink信息显示存储的UNDI固件版本，就像我们最近添加了对其他存储的固件闪存版本的支持一样，支持通过devlink信息显示存储的UNDI选项ROM版本。 为此，我们需要引入一个新的ice_get_inactive_orom_ver函数。 这比其他 Flash 版本有点棘手。 选项 ROM 版本数据是从 NVM 保留字段区域的特殊“引导配置”块中读取的。 该块仅包含*活动*选项 ROM 版本数据。 当设备固件完成更新选项 ROM 时，它会被填充。 此方法在读取存储的选项 ROM 版本数据时无效。 不用从闪存的这一部分读取，而是用从选项 ROM 二进制文件中查找组合版本信息的版本提取替换此版本提取。 该数据以简单的结构化格式存储在选项 ROM 中，偏移量为 512 字节。 该结构使用简单的模 256 校验和进行完整性验证。 扫描选项 ROM 以找到 CIVD 数据部分，并提取 Combo 版本。 重构ice_get_orom_ver_info，使其采用bank select枚举参数。 使用它来实现ice_get_inactive_orom_ver。 尽管所有ice器件在NVM PFA中都有引导配置块，但并非所有器件都有有效的选项ROM。 在这种情况下，旧的ice_get_orom_ver_info将“成功”，但报告全零的版本。 新的实现将无法在选项 ROM 中找到 $CIV 部分并报告错误。 因此，我们必须确保如果ice_get_orom_ver_info失败，ice_init_nvm不会失败。 使用新的ice_get_inactive_orom_ver允许通过devlink信息报告待更新的选项ROM版本
                    ice_get_netlist_info
                        ice_read_netlist_module
                            ice_read_flash_module -> Ice：通过devlink info显示存储的网表版本，添加读取非活动网表库以获取版本信息的功能。 为了支持这一点，重构我们读取网表版本数据的方式。 不使用带有模块 ID 的固件 AQ 接口，而是使用ice_read_flash_module 从闪存中读取作为平面 NVM。 此更改需要对所使用的偏移值进行轻微调整，因为从平面 NVM 读取包括类型字段（之前已被固件剥离）。 清理宏名称并将它们移动到ice_type.h。 为了清楚地说明我们如何计算偏移量，并使程序员可以轻松地将偏移值映射到数据表，请使用包装宏来考虑偏移量调整。 使用新添加的ice_get_inactive_netlist_ver函数从待处理的网表模块更新中提取版本数据。 将存储的“fw.netlist”和“fw.netlist.build”变体添加到信息版本映射数组中。 通过此更改，我们现在将“fw.netlist”和“fw.netlist.build”版本报告到 devlink 信息报告的存储部分。 与主要 NVM 模块版本一样，如果没有挂起的更新，我们会报告存储的当前活动值
                                ice_get_flash_bank_offset
                                ice_acquire_nvm
                                ice_read_flat_nvm
                ice_get_caps -> ice：获取交换机配置、调度程序配置和设备功能，此补丁通过获取交换机配置、调度程序配置和设备功能来添加初始化流程。 交换机配置：启动时，会在每个物理功能的固件中创建一个 L2 交换机元素。 每个物理功能还映射到其交换元件所连接的端口。 换句话说，该交换机可以被视为嵌入式 vSwitch，可以将物理功能的虚拟站接口 (VSI) 连接到出口/入口端口。 最终将创建出口/入口过滤器并将其应用到该开关元件上。 作为初始化流程的一部分，驱动程序从该开关元件获取配置数据并存储它。 调度程序配置：Tx 调度程序是负责设置和实施 QoS 的子系统。 作为初始化流程的一部分，驱动程序查询并存储给定物理功能的默认调度程序配置。 设备功能：作为初始化的一部分，驱动程序必须确定设备的功能（例如最大队列、VSI 等）。 该信息从固件获取并由驱动程序存储
                    ice_discover_dev_caps
                        ice_aq_list_caps
                        ice_parse_dev_caps
                            ice_parse_common_caps
                            ice_parse_valid_functions_cap
                            ice_parse_vsi_dev_caps
                            ice_parse_1588_dev_caps
                            ice_parse_fdir_dev_caps
                            ice_parse_sensor_reading_cap
                            ...
                    ice_discover_func_caps
                        ice_aq_list_caps
                        ice_parse_func_caps
                ice_get_initial_sw_cfg
                    ice_init_port_info
                xa_init_flags(&hw->port_info->sched_node_ids, XA_FLAGS_ALLOC) -> ice：在ice_sched_node中引入新的参数，为了支持新的devlink-rate API，ice_sched_node结构需要存储一些额外的参数。 这包括 tx_max、tx_share、tx_weight 和 tx_priority。 将新字段添加到ice_sched_node结构中。 添加新功能以使用新参数配置硬件。 引入新的xarray来唯一标识节点
                ice_sched_query_res_alloc
                    hw->layer_info = devm_kmemdup -> 复制内存
                ice_sched_get_psm_clk_freq -> ice：使用 PSM 时钟频率来计算 RL 配置文件，核心时钟频率目前硬编码为 446 MHz，用于 RL 配置文件计算。 这会导致问题，因为并非所有设备都使用该时钟频率。 读取 GLGEN_CLKSTAT_SRC 寄存器以确定选择哪个 PSM 时钟频率。 这可确保速率限制器配置文件计算正确
                ice_sched_init_port
                    ice_sched_add_root_node
                    ice_sched_add_node
                ice_aq_get_phy_caps
                ice_aq_get_link_info
                ice_cfg_rl_burst_size
                ice_aq_manage_mac_read
                ice_aq_set_mac_cfg
                ice_alloc_fd_res_cntr
                ice_init_hw_tbls -> ice：初始化DDP包结构，添加函数来初始化、解析和清理表示DDP包的结构。 包下载完成后，读取DDP包内容并将其存储到这些结构中。 此配置用于识别默认行为，稍后用于更新 HW 表条目
            if ice_is_pf_c827
                ice_wait_for_fw
            ice_init_feature_support -> Ice：添加功能位图、帮助程序和 DSCP 检查，DSCP 又名 L3 QoS 仅在某些设备上受支持。 为了强制执行此操作，此补丁引入了功能位图和辅助函数。 功能位图是根据驱动程序初始化时的设备 ID 设置的。 目前，DSCP 是该位图中的唯一功能，但将来会有更多功能。 在 DCB netlink 流程中，在执行 DSCP 之前检查功能位是否已设置
                ice_set_feature_support
                ice_is_phy_rclk_in_netlist
                ice_is_cgu_in_netlist
                ice_gnss_is_gps_present -> Ice：添加管理命令以访问cgu配置，添加固件管理命令以访问时钟生成单元配置，需要在驱动程序中启用扩展PTP和SyncE功能。 添加与时钟生成单元和访问数据的功能相关的输入和输出引脚的可能硬件变化的定义
                ice：为E810T设备的GNSS模块添加TTY，添加新的ice_gnss.c文件用于保存基本的GNSS模块功能。 如果设备支持 GNSS 模块，请在适当的情况下调用新的ice_gnss_init 和ice_gnss_release 函数。 实现使用 TTY 设备从 GNSS 模块读取数据的基本功能。 添加I2C读取AQ命令。 现在需要通过 E810-T 适配器上的外部 I2C 端口扩展器来控制外部物理连接器。 未来的变化将引入写入功能
            ice_request_fw
            ice_init_pf
                timer_setup(&pf->serv_tmr, ice_service_timer, 0)
                INIT_WORK(&pf->serv_task, ice_service_task)
                ice_mbx_init_snapshot
            ice_init_interrupt_scheme
            ice_req_irq_msix_misc
        ice_alloc_vsis
        ice_init_pf_sw
        ice_init_wakeup
        ice_init_link
        ice_send_version
        ice_verify_cacheline_size
        ice_set_safe_mode_vlan_cfg or
        pcie_print_link_status
        mod_timer(&pf->serv_tmr, round_jiffies(jiffies + pf->serv_tmr_period))
    ice_init_eth
        ice_dcbnl_setup
        ice_init_mac_fltr
        ice_devlink_create_pf_port
        ice_register_netdev
        ice_tc_indir_block_register
        ice_napi_add
    ice_init_rdma
        ice_is_rdma_ena
        ice_alloc_rdma_qvectors -> ice：添加单独的中断分配，目前中断分配，根据某个特性是批量分配的。 此外，分配后还有一系列操作，通过该批中断分配每个 irq 设置。 尽管驱动程序尚不支持动态中断分配，但将分配的中断保留在池中并添加分配抽象逻辑以使代码更加灵活。 将每个中断信息保留在ice_q_vector结构中，这会产生ice_vsi::base_vector冗余。 此外，因此有一些功能可以删除
            ice_alloc_irq -> ice：添加动态中断分配，目前驱动程序只能在init阶段通过调用pci_alloc_irq_vectors分配中断向量。 对此进行更改并使用新的 pci_msix_alloc_irq_at/pci_msix_free_irq API，并在启用 MSIX 后启用分配和释放更多中断。 由于并非所有平台都支持动态分配，请使用 pci_msix_can_alloc_dyn 检查。 扩展跟踪器以跟踪最初分配的中断数量，因此当所有此类向量都已使用时，会自动动态分配其他中断。 记住每个中断分配方法，然后适当地释放。 由于某些功能可能需要动态分配的中断，因此添加适当的 VSI 标志并在分配新中断时将其考虑在内
            为给定所有者 ID 分配新的中断向量。 返回包含中断详细信息的 struct msi_map 并适当跟踪分配的中断。 该函数从 irq_tracker 保留新的 irq 条目。 如果根据跟踪器信息，使用ice_pci_alloc_irq_vectors分配的所有中断都已使用并且支持动态分配的中断，则将使用pci_msix_alloc_irq_at分配新中断。 一些调用者可能只支持动态分配的中断。 这由 dyn_only 标志指示。 失败时，返回 .index 为负的映射。 调用者应该检查返回的map索引
                ice_get_irq_res
                pci_msix_can_alloc_dyn
                pci_msix_alloc_irq_at or
                pci_irq_vector
        ice_plug_aux_dev -> 在每个 PCIe 设备功能的辅助总线上注册ice客户端辅助 RDMA 设备，以便辅助驱动程序 (irdma) 附加到。 它允许实现单个 RDMA 驱动程序 (irdma)，该驱动程序能够通过支持 RDMA 的多代 Intel 硬件与多个 netdev 驱动程序配合使用。 ice 和 irdma 之间不存在加载顺序依赖性
            auxiliary_device_init
            auxiliary_device_add
    ice_init_devlink
    ice_init_features
        ice_hwmon_init


send msg:
ice_start_xmit
    ice_xmit_frame_ring
        ice_xmit_desc_count
        ...
        ice_tx_map
            dma_map_single -> 线性区的 skb->data 做 dma 映射，得到 硬件可以读取操作 dma 地址
            skb_frag_dma_map
            ...
            wmb()
            __netdev_tx_sent_queue

    


e1000_intr



readl/writel

filter:
drivers/net/ethernet/intel
drivers/net/ethernet/mellanox/mlx5



dpu driver:
drivers/net/ethernet/mellanox/mlx5/core/sf/devlink.c
mlx5_sf_add

$ devlink dev eswitch set pci/0000:06:00.0 mode switchdev

$ devlink port show
pci/0000:06:00.0/65535: type eth netdev ens2f0np0 flavour physical port 0 splittable false

$ devlink port add pci/0000:06:00.0 flavour pcisf pfnum 0 sfnum 88
pci/0000:06:00.0/32768: type eth netdev eth6 flavour pcisf controller 0 pfnum 0 sfnum 88 external false splittable false
function:
hw_addr 00:00:00:00:00:00 state inactive opstate detached

$ devlink port show ens2f0npf0sf88
pci/0000:06:00.0/32768: type eth netdev ens2f0npf0sf88 flavour pcisf controller 0 pfnum 0 sfnum 88 external false splittable false
function:
hw_addr 00:00:00:00:00:00 state inactive opstate detached




mlx5 driver:
drivers/net/ethernet/mellanox/mlx5/core/main.c
static int probe_one
    mlx5_devlink_alloc
        ida_alloc -> 其中ida_destory是释放所有和IDA关联的资源。IDA结构体是一个树状结构体，是内核工作的一个机制。　  这里先介绍一下IDR，IDR机制是内核中将一个整数ID号和指针关联在一起的机制。 如果使用数组进行索引，当ID号很大时，数组索引会占据大量的存储空间，如果使用链表，在总线上设备特别多的情况下，链表的查询效率不高。而IDR机制内部采用红黑树，可以很方便的将整数和指针关联起来，并且有很高的搜索效率。  IDA只是用来分配id，并不将某数据结构和id关联起来。 例如sd设备的设备名，如sda，驱动在生成设备文件的时候会向系统申请一个ida，也就是唯一id，然后把id映射成设备文件名。在nvme-core中有使用到ida，所以在最后中需要释放。static DEFINE_IDA(nvme_subsystems_ida);
    mlx5_mdev_init
        mutex_init
        INIT_LIST_HEAD
        mlx5_cmd_init
            cmd->wq = create_singlethread_workqueue(cmd->wq_name)
                alloc_workqueue
            mlx5_cmdif_debugfs_init
                debugfs_create_dir("commands", dev->priv.dbg.dbg_root)
                ...
        mlx5_tout_init -> set default timeout
            tout_def_sw_val
        mlx5_health_init
        mlx5_pagealloc_init
            create_singlethread_workqueue("mlx5_page_allocator")
            xa_init(&dev->priv.page_root_xa)
            mlx5_pages_debugfs_init -> net/mlx5：添加页面 debugfs 添加页面 debugfs 以公开以下计数器以实现可调试性： fw_pages_total - 已向固件提供但尚未返回的页面数。 vfs_pages - 对于 SRIOV，为 FW 提供了多少页供虚拟功能使用。 host_pf_pages - 对于 ECPF，为外部主机物理功能使用提供给 FW 的页数。
        mlx5_adev_init -> 在新的虚拟总线下创建辅助设备。 这将取代定制的 mlx5 ->add()/->remove() 接口，下一个补丁将填充缺失的回调并删除旧的接口逻辑。 辅助驱动程序与设备的连接只能以一对一的方式进行，并且需要我们为每个协议创建设备，以便设备（模块）能够连接到它。
            kcalloc(ARRAY_SIZE(mlx5_adev_devices) -> 
        mlx5_hca_caps_alloc -> net/mlx5：分配单个功能当前 mlx5_core_dev 包含功能数组。 它包含设备的 19 个有效功能、2 个保留条目和 12 个孔。 因此，对于 14 个未使用的条目，mlx5_core_dev 分配了 14 * 8K = 112K 字节的从未使用过的内存。 由于这个 mlx5_core_dev 结构大小为 270Kbytes 奇数。 此分配进一步与 2 的下一个幂到 512Kbytes 对齐
            for (i = 0; i < ARRAY_SIZE(types); i++)
                kzalloc(sizeof(*cap)
        ida_alloc_range -> struct ida sw_vhca_ida
    mlx5_pci_init
        pci_set_drvdata
        mlx5_pci_enable_device
        request_bar
            pci_request_regions
        pci_set_master -> pci_set_master() 将通过设置 PCI_COMMAND 寄存器中的总线主控位来启用 DMA。 如果 BIOS 设置为虚假值，它还会修复延迟计时器值。 pci_clear_master() 将通过清除总线主控位来禁用 DMA
        set_dma_caps
        pci_enable_atomic_ops_to_root
        ...
        mlx5_pci_vsc_init
    mlx5_init_one
        mlx5_init_one_devl_locked -> net/mlx5：轻探测本地 SF 如果用户想要配置 SF，例如：仅使用 vdpa 功能，则他需要完全探测 SF，配置他想要的内容，然后重新加载 SF。 为了节省重新加载的时间，本地SF将在没有任何辅助子设备的情况下进行探测，从而可以在其完全探测之前对SF进行配置。 这些 SF 的 enable_* devlink 参数的默认值设置为 false
        vdpa: https://www.redhat.com/en/blog/introduction-vdpa-kernel-framework, cx6 vdpa 虚拟io硬件卸载: https://wangzheng422.github.io/docker_env/notes/2021/2021.10.cx6dx.vdpa.offload.html
            mlx5_dev_is_lightweight
            mlx5_function_setup
                mlx5_function_enable -> net/mlx5：拆分 function_setup() 以启用和打开函数 mlx5_cmd_init_hca() 大约需要 0.2 秒。 如果用户希望禁用某些 SF aux 设备，例如对于大规模 1K SF，该用户将在 mlx5_cmd_init_hca() 上浪费超过 3 分钟的时间，而该阶段并不需要该功能。 下游补丁将更改通过 E-switch 进行探测的 SF、本地 SF，以便在没有任何辅助开发的情况下进行探测。 为了支持这一点，请拆分 function_setup() 以避免执行 mlx5_cmd_init_hca()
                    wait_fw_init
                    mlx5_cmd_enable
                        cmdif_rev
                        sema_init
                        dma_pool_create("mlx5_cmd", mlx5_core_dma_dev(dev), size, align, 0)
                        alloc_cmd_page
                            dma_alloc_coherent
                        iowrite32be
                        wmb()
                        create_msg_cache
                            for * 2
                                mlx5_alloc_cmd_msg
                                    mlx5_calc_cmd_blocks
                                    alloc_cmd_box
                                        mailbox->buf = dma_pool_zalloc
                                list_add_tail(&msg->list, &ch->head)
                        create_debugfs_files
                             debugfs_create_dir("cmd"
                    mlx5_tout_query_iseg -> net/mlx5：从 init 段读取超时值 用存储在固件 init 段中的值替换硬编码超时。 在驱动程序加载期间从 init 段读取超时。 如果不支持 init 段超时，则回退到硬编码默认值。 还将无法从固件读取的预初始化超时移至新机制
                        ...
                        tout_convert_reg_field_to_ms -> 时间寄存器由两个字段to_multiplier（超时乘数）和to_value（超时值）组成。 to_value 是时间单位的数量，to_multiplier 是类型，应该是这四个值之一
                            int_pow - 计算给定底数和指数的幂
                    wait_fw_init
                    mlx5_read_embedded_cpu
                    mlx5_cmd_set_state
                    mlx5_start_health_poll
                        timer_setup(&health->timer, poll_health, 0)
                            mlx5_health_check_fatal_sensors
                    mlx5_core_enable_hca
                        mlx5_cmd_exec_in(dev, enable_hca, in)
                            ...
                            cmd_exec
                                u16 opcode = in_to_opcode(in) -> const char *mlx5_command_str(int command) -> 命令转可读字符串
                                mlx5_cmd_invoke
                                    cmd_alloc_ent
                                    init_completion
                                    cb_timeout_handler
                                    cmd_work_handler -> Mellanox ConnectX-6-dx智能网卡 openvswitch 流表卸载源码分析: https://blog.csdn.net/qq_20679687/article/details/131632198
                                        ...
                                    wait_func
                                    xa_load
                                    cmd_ent_put
                    mlx5_core_set_issi -> net/mlx5：扩展 mlx5_core 以支持 ConnectX-4 以太网功能 这是 Mellanox ConnectX(R)-4 单/双端口适配器驱动程序的以太网部分，通过 VPI 支持 100Gb/s。 该驱动程序通过以太网功能扩展了现有的 mlx5 驱动程序。 该补丁包含驱动程序入口点，但不包括发送和接收（请参阅本系列中的上一个补丁）例程。 它还向 Kconfig 添加了选项 MLX5_CORE_EN 以启用/禁用以太网功能。 目前，Kconfig 被编程为使以太网和 Infiniband 功能相互排斥。 还将 MLX5_INFINIBAND 更改为依赖于 MLX5_CORE，而不是选择它，因为可以在不选择 MLX5_INFINIBAND 的情况下选择 MLX5_CORE
                        MLX5_CMD_OP_QUERY_ISSI
                    mlx5_satisfy_startup_pages -> mlx5_core：实现新的初始化序列引入enbale_hca和disable_hca命令来表示驱动程序何时启动或停止在设备上运行。 此外，驱动程序将使用引导和初始化页面计数； 需要引导页来允许固件完成引导命令，而另一个则完成 init hca。 命令接口版本已增加到 4，以强制使用支持的固件。 该补丁破坏了与旧版本固件（< 4）的兼容性； 但是，我们将发布的第一个 GA 固件将支持版本 4，因此这应该不是问题
                        mlx5_cmd_query_pages -> net/mlx5_core：支持 MANAGE_PAGES 和 QUERY_PAGES 固件命令更改 在之前的 QUERY_PAGES 命令版本中，我们使用一个命令来获取所需数量的引导、初始化和启动后页面。 新版本使用 op_mod 字段来指定查询是否针对所需数量的引导、初始化或后初始化页面。 此外，所需页面数量的输出字段大小从 16 位增加到 32 位。 在 MANAGE_PAGES 命令中，input_num_entries 和 output_num_entries 字段大小从 16 位更改为 32 位，并且 PAS 表偏移量更改为 0x10。 在页面请求事件中，num_pages 字段也更改为 32 位。 在 HCA-capability-layout 中，max_qp_mcg 字段的大小和位置已更改为支持 24 位。 该补丁与固件版本<5不兼容； 然而，事实证明我们将发布的第一个 GA 固件将不支持以前的版本，所以这应该没问题
                        give_pages -> net/mlx5：引入 Mellanox SmartNIC 并修改页面管理逻辑 Mellanox 的 SmartNIC 将嵌入式 CPU（例如 ARM）处理能力与高级网络卸载相结合，以加速多种安全、网络和存储应用程序。 随着SmartNIC的推出，出现了一种新的PCI功能，称为嵌入式CPU物理功能(ECPF)。 PF 可以从 ECPF PCI 功能获取其 ICM 页面。 驱动程序应通过读取初始化段中的位来识别它是否正在运行此类函数。 当固件请求页面时，它将发出页面请求事件，指定其请求多少页面以及针对哪个功能。 该驱动程序使用manage_pages命令进行响应，提供所请求的页面以及它正在提供这些页面的功能的指示。 此补丁之前的编码如下： function_id == 0：为接收 EQE 的函数请求页面。 function_id != 0：为由 function_id 值标识的 VF 请求页面 EQE 中新的一位字段标识为 ECPF 请求页面。 这里可以引入 page_supplier 的概念，为了支持这一点，修改了管理页面和查询页面，以便固件可以区分以下情况： 1. 函数为其自身提供页面 2. PF 为其 VF 提供页面 3. ECPF 为其自身提供页面 4. ECPF 为另一个函数提供页面 这种区别可以通过在 query_pages、manage_pages 和页面请求 EQE 中引入“embedded_cpu_function”位来实现
                            mlx5：为 Mellanox Connect-IB 适配器添加驱动程序 该驱动程序由两个内核模块组成：mlx5_ib 和 mlx5_core。 此分区类似于 mlx4 的分区，不同之处在于 mlx5_ib 是 pci 设备驱动程序，而不是 mlx5_core。 mlx5_core 本质上是一个提供通用功能的库，旨在供将来推出的其他 Mellanox 设备使用。 mlx5_ib 与 drivers/infiniband/hw 下的任何硬件设备具有类似的作用
                            kvzalloc
                            alloc_4k
                            alloc_system_page
                            mlx5_cmd_do
                                cmd_exec
                                op_mod = MLX5_GET(mbox_in, in, op_mod)
                                opcode = in_to_opcode(in)
                            mlx5_cmd_check
                    mlx5_tout_query_dtor -> default timeouts register (DTOR)
                        mlx5_core_access_reg
                            mlx5_access_reg
                mlx5_function_open
                    set_hca_ctrl
                        ...
                        MLX5_REG_HOST_ENDIANNESS
                    set_hca_cap -> 将所有 HCA 功能设置器合并到一个函数下，并编译出 ODP 相关函数，以防编译内核时不支持 ODP
                        handle_hca_cap
                        ...
                        handle_hca_cap_roce -> net/mlx5：启用软件定义的 RoCEv2 UDP 源端口 启用此选项后，RoCEv2 数据包的 UDP 源端口由软件而不是固件定义
                        handle_hca_cap_port_selection -> net/mlx5：检测并启用旁路端口选择流表 使用端口选择功能 port_select_flow_table_bypass 位来检测并启用显式端口关联，即使在链路聚合哈希模式下也是如此
                            mlx5_core_get_caps MLX5_CAP_PORT_SELECTION
                            set_caps MLX5_SET_HCA_CAP_OP_MOD_PORT_SELECTION
                    mlx5_satisfy_startup_pages
                    mlx5_cmd_init_hca -> net/mlx5：在 init HCA 期间设置软件所有者 ID 为每个主机生成唯一的 128 位标识符，并在 INIT_HCA 命令中将该值传递给固件（如果报告了 sw_owner_id 功能）。 绑定到 mlx5_core 驱动程序的每个设备都将具有相同的软件所有者 ID。 在后续补丁中，mlx5_core 设备将通过新的 VPort 命令进行绑定，以便它们可以在单个 InfiniBand 设备下一起运行。 只能绑定具有相同软件所有者 ID 的设备，以防止发往一台主机的流量到达另一台主机。 INIT_HCA 命令长度扩展了 128 位。 命令长度作为输入 FW 命令提供。 较旧的固件以新的较长形式接收此命令没有问题
                        MLX5_CMD_OP_INIT_HCA
                    mlx5_set_driver_version
                        MLX5_CMD_OP_SET_DRIVER_VERSION
                    mlx5_query_hca_caps
                        mlx5_core_get_caps_mode
                    mlx5_start_health_fw_log_up
                        queue_delayed_work(health->wq -> mlx5_health_log_ts_update
            mlx5_init_once
                mlx5_devcom_register_device -> net/mlx5：Devcom，基础设施更改将 devcom 基础设施更新为更通用，不依赖于最大支持端口定义或设备 GUID，并且封装程度更高，因此调用者无需在每次事件调用时传递注册 devcom 组件 ID
                mlx5_register_hca_devcom_comp
                    mlx5_devcom_register_component MLX5_DEVCOM_HCA_PORTS
                mlx5_query_board_id
                    MLX5_CMD_OP_QUERY_ADAPTER
                mlx5_irq_table_init -> net/mlx5：将 IRQ 数据与 EQ 表数据分开 IRQ 表应该仅存在于 mlx5_core_dev（仅适用于 PF 和 VF）。 中断设备的 EQ 表应保存指向父 PCI 设备的 IRQ 表的指针
                net/mlx5：为 SF 分配 MSI-X 矢量池 SF（子功能）当前使用其父物理功能所具有的全局 IRQ 表中的 IRQ。 为了更好地扩展，我们需要分配更多的IRQ并在不同的SF之间共享它们。 驱动程序将维护 3 个独立的 irq 池： 1. 为 PF 使用者提供服务的池（PF 的 netdev、rdma 堆栈），类似于此补丁之前的驱动程序。 即，该池将在 rdma 和 netev 之间共享 irq，并将保留 irq 索引和分配顺序。 最后一个对于 PF netdev rmap (aRFS) 很重要。 2. SF 的控制 IRQ 池。 该池的大小是可以创建的 SF 数量除以 SFS_PER_IRQ。 该池将服务于 SF 的控制路径 EQ。 3. SF 传输队列的完成数据路径 IRQ 池。 该池的大小为：num_irqs_alulated - pf_pool_size - sf_ctrl_pool_size。 该池将为 netdev 和 rdma 堆栈提供服务。 此外，SF 不支持 rmap。 SF 池的共享方法将在下一个补丁中解释。 重要提示：SF 不支持 rmap，因为 rmap 映射无法为不同 core/netdev RX 环共享的 IRQ 正常工作
                mlx5_eq_table_init
                    mlx5_eq_debugfs_init
                mlx5_events_init
                    INIT_WORK(&events->pcie_core_work, mlx5_pcie_event)
                    BLOCKING_INIT_NOTIFIER_HEAD(&events->sw_nh)
                mlx5_fw_reset_init
                    INIT_WORK mlx5_fw_live_patch_event
                    ...
                    init_completion -> 完成：使用简单的等待队列完成使用 wait_queue_head_t 将等待者排队。 wait_queue_head_t 包含一个 spinlock_t 来保护等待者列表，从而排除它在启用 PREEMPT_RT 的内核上的真正原子上下文中使用。 等待队列头中的自旋锁不能被 raw_spinlock 替换，因为： - 等待队列可以有自定义唤醒回调，它获取其他 spinlock_t 锁并且执行时间可能很长 -wake_up() 在唤醒期间遍历无限数量的列表条目 并可能唤醒无数的服务员。 出于简单性和性能原因，complete() 应该可在启用 PREEMPT_RT 的内核上使用。 完成不使用自定义唤醒回调，并且通常是单个等待者，除了一些极端情况。 将完成中的等待队列替换为简单的等待队列（swait），该队列使用 raw_spinlock_t 来保护等待列表，因此可以安全地在 PREEMPT_RT 上的真正原子区域内使用。 没有语义或功能上的变化： - 完成使用 swait 提供的独占等待模式 -complete() 唤醒一个独占等待者 -complete_all() 唤醒所有等待者，同时持有锁，以保护等待队列免受新传入等待者的影响。 转换为 swait 保留了此行为。 complete_all() 可能会导致大量等待者同时被唤醒，从而导致未绑定的延迟，但大多数complete_all() 使用站点要么在测试或初始化代码中，要么只有很少数量的并发等待者，目前不会导致延迟 问题。 现在保持简单。 USB 小工具驱动程序中警告检查的修复只是无锁等待检查从一种等待队列类型到另一种等待队列类型的直接转换
                mlx5_cq_debugfs_init
                mlx5_init_reserved_gids
                mlx5_vxlan_create
                    mlx5_vxlan_add_port -> net：将 IANA_VXLAN_UDP_PORT 定义添加到 vxlan 头文件 将 IANA_VXLAN_UDP_PORT (4789) 定义添加到 vxlan 头文件，以便驱动程序可以使用它而不是本地定义。 更新了本地定义为 4789 的驱动程序以使用它
                mlx5_geneve_create
                mlx5_init_rl_table -> net/mlx5：速率限制表支持配置和管理硬件速率限制表。 硬件保存一个速率限制表，每个速率都与该表中的一个索引相关联。 稍后发送队列使用该索引来设置速率限制。 多个发送队列可以具有相同的速率限制，这由该表中的单个条目表示。 尽管可以共享速率，但每个队列都受到独立于其他队列的速率限制。 该表的 SW 影子保存速率本身、HW 表中的索引以及使用该速率的引用计数（队列数）。 导出的函数为 mlx5_rl_add_rate 和 mlx5_rl_remove_rate。 不同速率的数量及其值源自硬件功能
                    MLX5_CAP_QOS
                mlx5_mpfs_init -> net/mlx5：当启用多 PF 配置以允许将用户配置的单播 MAC 地址传递到请求的 PF 时，需要将 E-Switch 和 MPFS 多物理功能交换机 (MPF) 分开。 在此补丁 eswitch.c 用于管理 HW MPFS L2 表之前，E-Switch 始终（无论 sriov）启用 vport(0) (NIC PF) vport 的上下文在单播 mac 地址列表更改时更新，以填充 PF 的 MPFS L2 表 因此。 在下游补丁中，我们希望允许编译没有 E-Switch 功能的驱动程序，为此，我们将 MPFS l2 表逻辑从 eswitch.c 移至其自己的文件中，并提供 Kconfig 标志 (MLX5_MPFS) 以允许为那些需要编译 MPFS 的人 不想要多 PF 支持。 NIC PF netdevice 现在将通过新的 MPFS API 直接更新 MPFS l2 表。 VF netdevice 无权访问 MPFS L2 表，因此 E-Switch 将继续负责代表其 VF 更新其 MPFS L2 表。 由于此更改，当未启用 SRIOV 时，我们也不再需要启用 vport(0)（PF vport）单播 mac 更改事件。 这意味着 E-Switch 现在仅在 SRIOV 激活时激活，否则不需要
                    mpfs->bitmap = bitmap_zalloc(l2table_size, GFP_KERNEL)
                mlx5_sriov_init -> net/mlx5_core：添加基本 sriov 支持 此补丁为 mlx5 支持的设备添加了 SRIOV 基本支持。 PF 和 VF 使用相同的驱动程序； VF 由驱动程序通过添加到 pci 表条目的标志 MLX5_PCI_DEV_IS_VF 来识别。 像往常一样，通过将值写入 PF 设备的 sriov_numvs sysfs 文件来创建虚拟函数。 实例化 VF 后，虚拟机管理程序上的驱动程序将探测它们。 人们可以通过 /sys/bus/pci/drivers/mlx5_core/unbind 优雅地解除它们的绑定。 添加 mlx5_wait_for_vf_pages() 是为了确保当 VF 在没有执行正确拆卸的情况下死亡时，虚拟机管理程序驱动程序会等待，直到返回在虚拟机管理程序中分配的用于维持其操作的所有页面。 为了使 VF 能够运行，PF 需要为其调用enable_hca。 这可以在通过调用 pci_enable_sriov 创建 VF 之前完成。 如果卸载 PF 的驱动程序时有分配给 VM 的 VF，则所有 VF 都会出现系统错误，并且 PF 驱动程序卸载干净； 在这种情况下，不会调用 pci_disable_sriov，并且运行 lspci 时将显示设备。 重新加载 PF 驱动程序后，它将同步其数据结构，以维护其 VF 上的状态
                    pci_sriov_get_totalvfs
                    mlx5_get_max_vfs
                    pci_num_vf
                    mlx5_core_ec_sriov_enabled
                mlx5_eswitch_init -> net/mlx5：介绍 E-Switch 和 l2 表 E-Switch 是代表和管理 ConnectX4 HCA 间以太网 l2 交换的软件实体。 E-Switch有自己的虚拟端口，每个Vport/vNIC/VF都可以通过e-switch的vport连接到设备。 每个 e-switch 由 HCA_CAP.vport_group_manager 标识的一个 vNIC（通常是 PF/vport[0]）管理，其主要职责是将每个数据包转发到正确的 vport。 e-Switch需要管理自己的l2表和FDB表。 L2 表是由 FW 管理的流表，多主机（多 PF）配置需要它以在 PF 之间进行 HCA 间切换。 FDB表是完全由e-Switch驱动程序管理的流表，其主要职责是在属于同一e-Swtich内部vport和上行链路vport之间交换数据包。 此补丁仅引入 e-Swtich l2 表管理，FDB 管理将在稍后启用以太网 SRIOV/VF 时提供。 以太网 sriov 和 l2 表管理的准备
                    devl_params_register
                    mlx5_esw_vports_init
                    esw_offloads_init
                        esw_offloads_init_reps
                        devl_params_register
                mlx5_fpga_init -> net/mlx5：FPGA，添加对 Innova Mellanox 的基本支持 Innova 是在同一板上具有 ConnectX 和 FPGA 的 NIC。 FPGA 是线上凸块，因此会影响 ConnectX ASIC 上 mlx5_core 驱动程序的运行。 在 mlx5_core 中添加对 Innova 的基本支持。 这允许通过检测 FPGA 功能位并在初始化 ConnectX 接口之前验证其负载状态，将 Innova 卡用作常规 NIC。 还可以检测 FPGA 致命运行时故障并在发生时进入错误状态。 所有新的 FPGA 相关逻辑都放置在其自己的子目录“fpga”中，可以通过选择 CONFIG_MLX5_FPGA 来构建该子目录。 这为以后的补丁集中进一步支持各种 Innova 功能做好了准备。 随着更多功能的提交，将提供有关硬件架构的更多详细信息
                    mlx5_fpga_device_alloc
                mlx5_vhca_event_init
                    MLX5_NB_INIT(&notifier->nb, mlx5_vhca_state_change_notifier, VHCA_STATE_CHANGE)
                mlx5_sf_hw_table_init -> net/mlx5：SF，添加端口添加删除功能为了将 eswitch 之外的 SF 端口管理作为独立的软件层进行处理，请引入 eswitch 通知程序 API，以便希望在 switchdev 模式下支持 sf 端口管理的 mlx5 上层可以在 eswitch 时执行其任务 mode 设置为 switchdev 或在 eswitch 禁用之前。 在此类 eswitch 事件上初始化 sf 端口表。 在switchdev模式下添加SF端口添加和删除功能。 禁用 eswitch 时销毁所有 SF 端口。 通过 devlink 命令向用户公开 SF 端口添加和删除
                    mlx5_sf_hw_table_hwc_init
                mlx5_sf_table_init
                    ...
                    blocking_notifier_chain_register
                mlx5_fs_core_alloc
                    mlx5_init_fc_stats -> net/mlx5_core：流计数器基础结构 如果计数器在创建时设置了老化标志，则会将其添加到将从工作队列定期查询的计数器列表中。 查询结果和上次使用时间戳被缓存。 添加/删除计数器必须非常高效，因为一秒钟可能会发出数千个此类操作。 只有一个对计数器的引用，没有老化，因此不需要锁。 但是，启用老化的计数器存储在列表中。 为了使代码尽可能无锁，所有列表操作和对硬件的访问都是从单个上下文（周期性计数器查询线程）完成的。 硬件支持每个 FTE 使用多个计数器，但目前我们为每个 FTE 使用一个计数器
                        mlx5_fc_stats_work
                        mlx5_fc_pool_init -> net/mlx5：添加流量计数器池 根据流量计数器批量添加流量计数器池，从而无需在流量创建过程中通过昂贵的 FW 命令分配新计数器。 获取/释放流量计数器所需的时间从约 50 [us] 缩短至约 50 [ns]。 该池是 mlx5 驱动程序实例的一部分，并为老化流提供流量计数器。 mlx5_fc_create() 已修改为默认为池中的老化流提供计数器，并且 mlx5_destroy_fc() 已修改为将计数器释放回池以供以后重用。 如果批量分配不受支持或失败，并且对于非老化流，后备行为是分配并释放各个计数器。 该池由流量计数器批量的三个列表组成：完全使用的批量之一、部分使用的批量之一和未使用的批量之一。 首先从部分使用的块中提供计数器，以帮助限制块碎片。 该池维护一个阈值，并努力将可用计数器的数量维持在该阈值以下。 当发出计数器获取请求且没有可用计数器时，池的大小会增加；当批量释放最后一个计数器且可用计数器多于阈值时，池的大小会减小。 所有池大小的更改都是在获取/释放过程的上下文中完成的。 阈值与池提供的已用计数器数量直接相关，同时受到硬性最大值的限制，并且每次分配/释放批量时都会重新计算。 这可确保池仅在大量使用时才为可用计数器消耗大量内存。 当完全填充且处于硬最大值时，可用计数器的缓冲区消耗约 40 [MB]
                    mlx5_ft_pool_init -> 固件目前支持 4 个 4 种大小的池 (FT_POOLS)，以及 16M 的虚拟内存区域 (MLX5_FT_SIZE)，该区域为每个流表池复制。 我们可以为每个池分配最多 	16M 的空间，并通过 mlx5_ft_pool_get_avail_sz 跟踪我们使用了多少空间。 固件目前不会报告任何此类情况。 ESW_POOL预计从大到小排序并匹配固件池
                    kmem_cache_create -> kernel里分配一些小内存用到的是slab分配器, kmem_cache_create()只是分配size大小的缓存，并不会调用对象的构造函数，只有当再调用kmem_cache_alloc()时才会构造对象，另外调用kmem_cache_create()并没有分配slab，是在创建对象的时候发现没有空闲对象，调用cache_grow()分配一个slab，然后再分配对象
                mlx5_dm_create -> net/mlx5：将设备内存管理移至 mlx5_core 将设备内存分配和释放命令 SW ICM 内存移至 mlx5_core，以向所有 mlx5_core 用户公开此 API。 这是为支持内核中的软件控制做准备，其中需要分配和注册设备内存以进行直接规则插入。 此外，还引入了一个 API，用于使用 create_mkey 命令注册此设备内存以供将来的远程访问操作
                    bitmap_zalloc
                mlx5_fw_tracer_create -> 实现固件跟踪器逻辑和寄存器访问、初始化和清理流程。 初始化跟踪器将是加载一个流程的一部分，因为多个 PF 将尝试获取所有权，但只有一个会成功并成为跟踪器所有者
                    INIT_WORK mlx5_fw_tracer_ownership_change
                    ...
                    mlx5_query_mtrc_caps
                    mlx5_fw_tracer_create_log_buf -> net/mlx5：固件跟踪器，创建跟踪缓冲区并复制字符串数据库 对于每个 PF，执行以下操作： 1- 为跟踪器字符串数据库分配内存，并将字符串从固件读取到软件。 这些字符串稍后将用于解析跟踪。 2- 分配和 DMA 映射跟踪器缓冲区。 将写入缓冲区的跟踪将被解析为一组一个或多个跟踪，称为跟踪消息。 跟踪消息表示类似 C 语言的 printf 字符串。 消息的第一个跟踪保存了指向字符串数据库中正确字符串的指针。 以下跟踪保存消息的变量
                        mlx5_core_dma_dev
                        dma_map_single
                    mlx5_fw_tracer_allocate_strings_db
                    mlx5_fw_tracer_init_saved_traces_array
                mlx5_hv_vhca_create -> net/mlx5：添加 HV VHCA 基础设施 HV VHCA 是一个基于 HyperV PCI 配置通道提供 PF 到 VF 通信通道的层。 它实现了 Mellanox 的 Inter VHCA 控制通信协议。 该协议包含用于在 PF 和 VF 驱动程序之间传递消息的控制块，以及用于传递实际数据的数据块。 基础设施是基于代理的。 每个代理将负责 VHCA 配置空间中的连续缓冲区块。 该基础设施将代理绑定到它们的块，并且这些代理只能访问读/写分配给它们的缓冲区块。 每个代理将提供三个回调（控制、无效、清理）。 当使用与此代理相关的命令使 block-0 无效时，将调用控制。 如果分配给该代理的块之一无效，则将调用无效回调。 在释放代理之前将调用清理，以清理其所有开放资源或延迟的工作。 Block-0 用作控制块。 来自 PF 的所有执行命令都将由 PF 写入该块。 VF 也会通过在 block-0 上写入来解决这些问题。 其格式由 struct mlx5_hv_vhca_control_block 布局描述
                    create_singlethread_workqueue("mlx5_hv_vhca")
                mlx5_rsc_dump_create -> net/mlx5：添加对资源转储的支持在驱动程序加载时： - 初始化资源转储数据结构和内存访问工具（mkey 和 pd）。 - 读取包含固件段标识符的资源转储菜单。 每条记录均由段名称 (ASCII) 标识。 在驾驶员的一生中，用户（例如记者）可能会请求每个路段的转储。 用户应创建一个提供段标识符（SW 枚举）和命令键的命令。 作为回报，用户收到命令上下文。 为了接收转储，用户应提供命令上下文和将在其上写入转储内容的内存（与页对齐）。 由于转储可能大于给定内存，因此用户可以重新提交命令，直到收到转储结束的指示。 用户有责任销毁该命令
            mlx5_load -> net/mlx5：将 load_one 分为三个阶段 使用先前补丁的基础将 mlx5_load_one 流程分解为三个阶段： 1. mlx5_function_setup() 从先前补丁到设置函数 2. mlx5_init_once() 从先前补丁到根据硬件上限 3 初始化软件对象 新的 mlx5_load() 用于加载 mlx5 组件 这为 mlx5 核心设备初始化流程提供了更好的逻辑分离，并将有助于无缝支持创建不同的 mlx5 设备类型，例如 PF、VF 和 SF mlx5 子功能虚拟设备。 此补丁不会更改任何功能
                mlx5_get_uars_page -> net/mlx5：添加接口以获取对 UAR 的引用 需要对 UAR 的引用才能生成 CQ 或 EQ 门铃。 由于 CQ 或 EQ 门铃都可以使用相同的 UAR 区域生成，而不会对性能产生任何影响，因此我们只是获取对任何可用 UAR 的引用，如果一个不可用，我们会分配它，但我们不会浪费蓝色火焰寄存器 可以提供，我们将使用它们进行后续分配。 我们获取对此类 UAR 的引用并将其放入 mlx5_priv 中，以便任何内核使用者都可以使用它
                    alloc_uars_page
                mlx5_events_start
                mlx5_pagealloc_start
                mlx5_eq_table_create
                    create_async_eqs
                    alloc_rmap
                mlx5_fw_tracer_init
                mlx5_fw_reset_events_start
                mlx5_hv_vhca_init
                mlx5_rsc_dump_init
                mlx5_fpga_device_start
                mlx5_fs_core_init
                mlx5_core_set_hca_defaults
                mlx5_vhca_event_start
                mlx5_sf_hw_table_create
                mlx5_ec_init
                    mlx5_host_pf_init
                        mlx5_cmd_host_pf_enable_hca
                            MLX5_CMD_OP_ENABLE_HCA
                mlx5_lag_add_mdev -> net/mlx5：更改链路聚合的所有权模型 链路聚合用于将同一 HCA 的两个 PCI 功能组合到单个逻辑单元中。 这是核心功能，因此应由核心驱动程序管理。 目前情况并非如此。 当我们将链路聚合软件结构存储在较低设备内时，其生命周期（创建/销毁）由 mlx5e 部分决定。 更改所有权模型，使延迟与较低级别驱动程序的生命周期相关，而不是与 mlx5e 部分相关
                    __mlx5_lag_dev_add_mdev -> net/mlx5：链路聚合，如果需要，请正确锁定 eswitch 目前，在进行硬件链路聚合时，我们会检查 eswitch 模式，但由于这不是在锁定下完成的，因此检查无效。 由于代码需要在两个不同设备之间同步，因此需要格外小心。 - 当要更改 eswitch 模式时，如果硬件链路聚合处于活动状态，则销毁它。 - 更改 eswitch 模式时会阻止任何硬件绑定创建。 - 延迟处理绑定事件，直到没有正在进行的模式更改。 - 当附加一个新的 mdev 到 lag 时，阻塞直到没有正在进行的模式改变。 为了完成模式更改，必须锁定界面。 释放锁定并休眠 100 毫秒以允许前进。 由于这是一种非常罕见的情况（如果用户取消绑定和绑定 PCI 功能，同时更改其他 PCI 功能的 eswitch 模式，则可能会发生），因此它对现实世界没有影响。 由于现在需要采用多个 eswitch 模式锁定，lockdep 会抱怨可能的死锁。 为每个 eswitch 注册一把钥匙，让 Lockdep 满意
                        mlx5_devcom_get_next_peer_data
                        mlx5_ldev_get
                        mlx5_ldev_add_mdev
                    mlx5_ldev_add_debugfs
                mlx5_sriov_attach -> net/mlx5：实现轻量级和模块化内部/pci 错误处理所需的 SRIOV 连接/分离流程。 实现 sriov Attach 功能，该功能可以在设备端预先保存 vfs 的数量。 实现 sriov detach 功能，禁用设备端当前的 vfs。 初始化/清理函数仅处理 sriov 软件上下文分配和销毁
                    mlx5_device_enable_sriov
                        mlx5_eswitch_enable -> net/mlx5：E-switch，保护 eswitch 模式更改 目前，eswitch 模式更改是从以下 2 个不同的执行上下文中发生的。 1. sriov sysfs 启用/禁用 2. devlink eswitch set 命令 两者都需要以同步方式访问 eswitch 相关数据结构。 在没有任何同步的情况下，存在以下竞争条件。 通过 devlink eswitch 模式更改启用/禁用 SR-IOV：
                        mlx5_get_default_msix_vec_count
                        mlx5_set_msix_vec_count
                        sriov_restore_guids
                mlx5_sf_dev_table_create
                mlx5_devlink_traps_register
            set_bit(MLX5_INTERFACE_STATE_UP, &dev->intf_state)
            mlx5_register_device(dev)
                mlx5_rescan_drivers_locked
    mlx5_crdump_enable -> net/mlx5：添加 Crdump 支持，Crdump 允许驱动程序检索 FW PCI crspace 的转储。 这在发生可能需要重置固件的灾难性问题时非常有用。 crspace 转储可用于以后的调试
        ...
    mlx5_hwmon_dev_register -> net/mlx5：通过硬件监控内核 API 暴露 NIC 温度 通过实现 hwmon 内核 API 暴露 NIC 温度，这会将当前热区内核 API 变为冗余。 对于每个受支持和公开的热二极管传感器，公开以下属性： 1) 输入温度。 2) 最高温度。 3) 温度标签：取决于固件功能，如果固件不支持传感器命名，则后备命名约定为：“sensorX”，其中 X 是硬件规格（MTMP 寄存器）传感器索引。 4) 温度临界最大值：指警告事件的高阈值。 将公开为 `tempY_crit` hwmon 属性（RO 属性）。 例如，对于 ConnectX5 HCA，该温度值为 105 摄氏度，比硬件关闭温度低 10 度。 5) 温度重置历史记录：重置最高温度。 例如，对于具有单个 IC 热二极管传感器的双端口 ConnectX5 NIC，将在“/sys/class/hwmon/hwmon[X,Y]”下有 2 个 hwmon 目录（每个 PCI 功能一个）。 列出上面的目录之一 (hwmonX/Y) 会生成以下相应的输出：grep -H -d skip . /sys/class/hwmon/hwmon0/*, sensors
    pci_save_state
    devlink_register
    mlx5_devlink_alloc
    mlx5_adev_idx_alloc
    mlx5_mdev_init



init debugfs, wq, Workqueue
/sys/kernel/debug/mlx5/
tree -L 2 /sys/kernel/debug/mlx5/

probe flow ref:
.probe()
  |-init_one(struct pci_dev *pdev, pci_device_id id)
      |-mlx5_devlink_alloc()
      |   |-devlink_alloc(ops)        // net/core/devlink.c
      |       |-devlink = kzalloc()
      |       |-devlink->ops = ops
      |       |-return devlink
      |
      |-mlx5_mdev_init(dev, prof_sel)
      |   |-debugfs_create_dir
      |   |-mlx5_pagealloc_init(dev)
      |       |-create_singlethread_workqueue("mlx5_page_allocator")
      |           |-alloc_ordered_workqueue
      |               |-alloc_workqueue     // kernel/workqueue.c
      |
      |-mlx5_pci_init(dev, pdev, id);
      |   |-mlx5_pci_enable_device(dev);
      |   |-request_bar(pdev);             // Reserve PCI I/O and memory resources
      |   |-pci_set_master(pdev);          // Enables bus-mastering on the device
      |   |-set_dma_caps(pdev);            // setting DMA capabilities mask, set max_seg <= 1GB
      |   |-dev->iseg = ioremap()
      |
      |-mlx5_load_one(dev, true);
      |   |-if interface already STATE_UP
      |   |   return
      |   |
      |   |-dev->state = STATE_UP
      |   |-mlx5_function_setup       // Init firmware functions
      |   |-if boot:
      |   |   mlx5_init_once
      |   |     |-mlx5_irq_table_init // Allocate IRQ table memory
      |   |     |-mlx5_eq_table_init  // events queue
      |   |     |-dev->vxlan  = mlx5_vxlan_create
      |   |     |-dev->geneve = mlx5_geneve_create
      |   |     |-mlx5_sriov_init
      |   | else:
      |   |   mlx5_attach_device
      |   |-mlx5_load
      |   |   |-mlx5_irq_table_create     // 初始化硬中断
      |   |   |  |-pci_alloc_irq_vectors(MLX5_IRQ_VEC_COMP_BASE + 1, PCI_IRQ_MSIX);
      |   |   |  |-request_irqs
      |   |   |      for i in vectors:
      |   |   |        request_irq(irqn, mlx5_irq_int_handler) // 注册中断处理函数
      |   |   |-mlx5_eq_table_create      // 初始化事件队列（EventQueue）
      |   |      |-create_comp_eqs(dev)   // Completion EQ
      |   |          for ncomp_eqs:
      |   |            eq->irq_nb.notifier_call = mlx5_eq_comp_int;
      |   |            create_map_eq()
      |   |            mlx5_eq_enable()
      |   |-set_bit(MLX5_INTERFACE_STATE_UP, &dev->intf_state);
      |
      |-pci_save_state(pdev);
      |
      |-if (!mlx5_core_is_mp_slave(dev))
          devlink_reload_enable(devlink);


init pci:
mlx5_pci_init -> mlx5：为 Mellanox Connect-IB 适配器添加驱动程序 该驱动程序由两个内核模块组成：mlx5_ib 和 mlx5_core。 此分区类似于 mlx4 的分区，不同之处在于 mlx5_ib 是 pci 设备驱动程序，而不是 mlx5_core。 mlx5_core 本质上是一个提供通用功能的库，旨在供将来推出的其他 Mellanox 设备使用。 mlx5_ib 与 drivers/infiniband/hw 下的任何硬件设备具有类似的作用
    ioremap(dev->iseg_base, sizeof(*dev->iseg)) -> mapping initialization segment


MSI-X 中断是比较推荐的方式，尤其是对于支持多队列的网卡。 因为每个 RX 队列有独立的 MSI-X 中断，因此可以被不同的 CPU 处理（通过 irqbalance 方式，或者修改/proc/irq/IRQ_NUMBER/smp_affinity）。后面会看到 ，处理中断的 CPU 也是随后处理这个包的 CPU。这样的话，从网卡硬件中断的层面就可 以设置让收到的包被不同的 CPU 处理


mlx5e_nic
  |-mlx5e_ipsec_build_inverse_table();
  |-mlx5e_build_ptys2ethtool_map();
  |-mlx5_register_interface(&mlx5e_interface)
     |-list_add_tail(&intf->list, &intf_list);
     |
     |-for priv in mlx5_dev_list
         mlx5_add_device(intf, priv)
          /
         /
mlx5_add_device(intf, priv)
 |-if !mlx5_lag_intf_add
 |   return // if running in InfiniBand mode, directly return
 |
 |-dev_ctx = kzalloc()
 |-dev_ctx->context = intf->add(dev)
     |-mlx5e_add
        |-netdev = mlx5e_create_netdev(mdev, &mlx5e_nic_profile, nch);
        |  |-mlx5e_nic_init
        |     |-mlx5e_build_nic_netdev(netdev);
        |        |-netdev->netdev_ops = &mlx5e_netdev_ops; // 注册 ethtool_ops, poll
        |-mlx5e_attach
        |  |-mlx5e_attach_netdev
        |      |-profile->init_tx()
        |      |-profile->init_rx()
        |      |-profile->enable()
        |          |-mlx5e_nic_enable
        |              |-mlx5e_init_l2_addr
        |              |-queue_work(priv->wq, &priv->set_rx_mode_work)
        |              |-mlx5e_open(netdev);
        |              |  |-mlx5e_open_locked
        |              |     |-mlx5e_open_channels
        |              |     |  |-mlx5e_open_channel
        |              |     |     |-netif_napi_add(netdev, &c->napi, mlx5e_napi_poll, 64);
        |              |     |     |-mlx5e_open_queues
        |              |     |         |-mlx5e_open_cq
        |              |     |         |   |-mlx5e_alloc_cq
        |              |     |         |       |-mlx5e_alloc_cq_common
        |              |     |         |           |-mcq->comp = mlx5e_completion_event;
        |              |     |         |-napi_enable(&c->napi)
        |              |     |-mlx5e_activate_priv_channels
        |              |        |-mlx5e_activate_channels
        |              |            |-for ch in channels:
        |              |                mlx5e_activate_channel
        |              |                  |-mlx5e_activate_rq
        |              |                     |-mlx5e_trigger_irq
        |              |-netif_device_attach(netdev);


thtool 是一个命令行工具，可以查看和修改网卡配置，常用于收集网卡统计数据。 内核实现了一个通用 ethtool 接口，网卡驱动只要实现这些接口，就可以使用 ethtool 来查看或修改网络配置； 在底层，它是通过 ioctl 和设备驱动通信的


mlx5e_init_nic_rx
    mlx5e_create_q_counters -> net/mlx5e：移动 Q 计数器分配并将 RQ 删除到 init_rx 并非所有配置文件都会在 update_stats() 回调中查询 HW Q 计数器。 每个设备的 HW Q 计数器都是有限的，对于表示器，它们的所有 Q 计数器都分配在父 PF 设备上。 通过将分配移动到 init_rx 配置文件回调来避免硬件 Q 计数器的重复分配
        MLX5_CMD_OP_ALLOC_Q_COUNTER
    mlx5e_open_drop_rq
        struct mlx5e_cq -> net/mlx5：扩展 mlx5_core 以支持 ConnectX-4 以太网功能，这是 Mellanox ConnectX(R)-4 单/双端口适配器驱动程序的以太网部分，支持带 VPI 的 100Gb/s。 该驱动程序通过以太网功能扩展了现有的 mlx5 驱动程序。 该补丁包含驱动程序入口点，但不包括发送和接收（请参阅本系列中的上一个补丁）例程。 它还向 Kconfig 添加了选项 MLX5_CORE_EN 以启用/禁用以太网功能。 目前，Kconfig 被编程为使以太网和 Infiniband 功能相互排斥。 还将 MLX5_INFINIBAND 更改为依赖于 MLX5_CORE，而不是选择它，因为可以在不选择 MLX5_INFINIBAND 的情况下选择 MLX5_CORE
        mlx5e_build_drop_rq_param -> net/mlx5e：允许在通道上下文之外进行 CQ，为了能够在通道上下文之外创建 CQ，请删除 cq->channel 直接指针。 这需要添加指向通道统计信息、netdevice、priv 和 mlx5_core 的直接指针，以支持属于 mlx5e_channel 一部分的 CQ。 此外，以前从通道派生的参数（如 napi、NUMA 节点、通道统计信息和索引）现在组装在 struct mlx5e_create_cq_param 中，该结构被赋予 mlx5e_open_cq() 而不是通道指针。 通用化 mlx5e_open_cq() 允许在通道上下文之外打开 CQ，该通道上下文将在补丁集中的后续补丁中使用
            mlx5e_get_rqwq_log_stride
                order_base_2 -> 计算参数以 2 为底的对数（向上舍入）
        mlx5e_alloc_drop_cq -> mlx5e_alloc_cq_common
            mlx5_cqwq_create
            mcq->cqe_sz     = 64
            mcq->comp       = mlx5e_completion_event -> napi_schedule(cq->napi)
            mcq->event      = mlx5e_cq_error_event -> net/mlx5：以太网数据路径文件，en_[rt]x.c 包含特定于 tx 或 rx 的数据路径相关代码。 en_txrx.c 包含 rx 和 tx 通用的数据路径代码，这主要是 napi 相关代码。 以下是数据路径中硬件和驱动程序使用的对象： 通道 - 每个 IRQ 一个通道。 每个通道对象包含： RQ - 描述接收队列 TIR - 每种流类型一个 TIR（传输接口接收）对象。 TIR 包含接收流类型的属性（例如 IPv4、IPv6 等）。 流在流表中定义。 目前，TIR 描述了 RSS 哈希参数（如果存在）和 LRO 属性。 SQ - 描述 tx 队列。 每个TC（流量类别）有一个SQ（发送队列）。 TIS - 每个 TC 有一个 TIS（传输接口发送）。 它描述了 TC，稍后可能会扩展以描述更多传输属性。 RQ和SQ都继承自对象WQ（工作队列）。 描述 CQE 的 WQE 在内存中的布局的通用代码位于文件 wq 中。[cj] 对于每个通道，都有一个用于 RX 和 TX 的 NAPI 上下文。 驱动程序正在使用 netdev_alloc_skb() 来分配 skb
            cqe->validity_iteration_count = 0xff
        mlx5e_create_cq
            mlx5_comp_eqn_get -> net/mlx5：动态分配完成 EQ，此提交支持在运行时动态分配 EQ，从而可以更灵活地管理完成 EQ 并减少驱动程序负载的内存开销。 每当为给定向量索引创建 CQ 时，驱动程序都会查找该向量是否已映射完成 EQ，如果有，则使用它。 否则，根据需要分配新的 EQ，然后将其用于 CQ 完成事件。 向 EQ 表添加保护锁，以防止并发 EQ 创建尝试。 在此期间，将 mlx5_vector2irqn()/mlx5_vector2eqn() 替换为 mlx5_comp_eqn_get() 和 mlx5_comp_irqn_get()，如果给定向量没有找到 EQ，则将按需分配 EQ
                create_comp_eq
                    lockdep_assert_held
                    comp_irq_request
                        comp_irq_request_sf -> net/mlx5：重构 EQ 层中的完成 IRQ 请求/释放处理程序，将完成 IRQ 请求/释放函数分解为 EQ 层中 PCI 设备和 SF 的每个向量处理程序。 在创建 EQ 表时，循环遍历所有向量并使用新的每向量函数为每个向量请求 IRQ。 在 EQ 表清理中释放 IRQ 时执行对称更改
                            struct mlx5_irq_pool *pool
                            cpumask_copy
                            cpumask_andnot
                            mlx5_irq_affinity_request -> 根据给定的掩码请求 IRQ
                                irq_pool_find_least_loaded
                                irq_pool_request_irq
                                    mlx5_irq_alloc
                                        pci_msix_can_alloc_dyn
                                        irq->map.virq = pci_irq_vector(dev->pdev, i)
                                        irq->map = pci_msix_alloc_irq_at
                                        err = request_irq(irq->map.virq, irq_int_handler, 0, irq->name, -> atomic_notifier_call_chain(nh, 0, NULL)
                                        irq_set_affinity_and_hint(irq->map.virq, irq->mask)
                            cpumask_or mlx5_irq_get_affinity_mask
                        or comp_irq_request_pci
                            mlx5_eq_table_get_pci_rmap -> net/mlx5：在没有 SF IRQ 池的情况下处理 SF IRQ 请求，如果 SF IRQ 池由于设置限制而不可用，则 SF 目前依赖已分配的 PF IRQ 来满足其 IRQ 矢量请求。 然而，随着下一个补丁中引入的动态EQ分配，驱动程序加载后可能不会分配PF的所有IRQ。 在这种情况下，如果SF在没有自己的独立IRQ池的情况下请求完成IRQ，则SF将缺乏PF IRQ可利用。 为了解决这种情况，请根据需要从 PF 的 IRQ 池中为 SF 分配 IRQ。 新的 IRQ 将在 SF 和它的 PF 之间共享
                            mlx5_cpumask_default_spread -> net/mlx5：引入mlx5_cpumask_default_spread，为了在完成IRQ请求代码中获得更好的代码可读性，在单独的函数中定义每个完成向量逻辑的CPU查找。 给定向量索引“n”的新方法 mlx5_cpumask_default_spread() 将返回“第 n”个 cpu。 这个新方法也将在下一个补丁中使用
                                for_each_numa_hop_mask
                                    for_each_cpu_andnot
                            mlx5_irq_request_vector -> 为mlx5设备绑中断, 每个中断至少绑到1个CPU核上
                                cpumask_clear(&af_desc.mask)
                                cpumask_set_cpu(cpu, &af_desc.mask)
                                mlx5_irq_request -> 为 mlx5 PF/VF 设备请求 IRQ -> net/mlx5：基于 IRQ 的循环 EQ，每当用户为 EQ 创建请求提供亲和力时，将 EQ 映射到匹配的 IRQ。 将 IRQ=IRQ 与所创建的 EQ 具有相同亲和力和类型（完成/控制）进行匹配。 这种映射是在积极的专用 IRQ 分配方案中完成的，如下所述。 首先，我们检查是否存在匹配的IRQ，其最小阈值未耗尽。 - min_eqs_threshold = 3 用于控制 EQ。 - min_eqs_threshold = 1 用于完成 EQ。 如果未找到匹配的 IRQ，请尝试请求新的 IRQ。 如果我们无法请求新的 IRQ，请重用最少使用的匹配 IRQ
                                    irq = irq_pool_request_vector(pool, vecidx, af_desc, rmap) -> net/mlx5：使用动态 msix 向量分配，当前实现计算可用中断向量的数量和分区，然后分配所有中断向量。 在这里，每当支持动态 msix 分配时，我们都会将其更改为动态使用 msix 向量，以便实际上仅在需要时分配向量。 当前的池逻辑保持不变，以负责在消费者之间划分向量并负责引用计数。 但是，仅在需要时才分配向量。 后续补丁将利用它为 VDPA 分配向量
                                        mlx5_irq_alloc
                    comp_eq_depth_devlink_param_get -> net/mlx5：让用户配置io_eq_size参数，目前每个I/O EQ占用128KB内存。 并非所有用例都需要此大小，并且对于大规模来说至关重要。 因此，允许用户配置 I/O EQ 的大小。 例如，要将 I/O EQ 大小减少到 64，请执行： $ devlink dev param set pci/0000:00:0b.0 name io_eq_size value 64 \ cmode driverinit $ devlink dev reload pci/0000:00:0b
                        devl_param_driverinit_value_get DEVLINK_PARAM_GENERIC_ID_IO_EQ_SIZE -> 获取驱动程序初始化的配置参数值 @devlink: devlink @param_id: 参数 ID @val: 存储 driverinit 配置模式下参数值的指针 该函数应该由驱动程序用来获取 driverinit 配置，以便在 reload 命令后进行初始化。 请注意，此函数的无锁调用依赖于驱动程序来维护以下基本理智行为： 1) 驱动程序确保对此函数的调用不会与使用相同参数 ID 注册/注销参数竞争。 2) 驱动程序确保对此函数的调用不能与具有相同参数 ID 的 devl_param_driverinit_value_set() 调用竞争。 3) 驱动程序确保对此函数的调用不会与重新加载操作竞争。 如果驱动程序无法遵守，则在调用此函数时必须获取 devlink->lock
                            devlink_param_find_by_id
                    tasklet_setup(&eq->tasklet_ctx.task, mlx5_cq_tasklet_cb) -> net/mlx5：实现单个完成 EQ 创建/销毁方法，目前，create_comp_eqs() 函数处理驱动程序加载上所有向量的所有完成 EQ 的创建。 在驱动程序卸载时，destroy_comp_eqs() 执行等效的工作。 在准备动态 EQ 创建时，请将 create_comp_eqs() / destroy_comp_eqs() 替换为 create_comp_eq() / destroy_comp_eq() 函数，该函数将接收向量索引并为该特定向量分配/销毁 EQ。 因此，完成情商的管理具有更大的灵活性 -> net: mlx: 将tasklet转换为使用新的tasklet_setup() API，为了准备无条件地将struct tasklet_struct指针传递给所有tasklet回调，请切换到使用新的tasklet_setup()和from_tasklet()来显式传递tasklet指针
                        list_splice_tail_init(&ctx->list, &ctx->process_list)
                        mcq->tasklet_ctx.comp(mcq, NULL)
                        tasklet_schedule(&ctx->task)
                    eq->irq_nb.notifier_call = mlx5_eq_comp_int
                    create_map_eq
                        u8 log_eq_size = order_base_2(param->nent + MLX5_NUM_SPARE_EQE)
                        INIT_RADIX_TREE(&cq_table->tree, GFP_ATOMIC) -> 初始化基数树1
                        mlx5_frag_buf_alloc_node -> net/mlx5：对 EQ 使用 order-0 分配，目前我们正在为 EQ 分配高阶页面。 在碎片系统的情况下，例如虚拟机中的 VF 热删除/添加，没有足够的连续内存用于 EQ 分配，这会导致虚拟机崩溃。 因此，请改用 0 阶片段进行 EQ 分配。 性能测试：ConnectX-5 100Gbps，CPU：Intel(R) Xeon(R) CPU E5-2697 v3 @ 2.60GHz 性能测试显示没有明显下降 -> net/mlx5e：实现分段工作队列 (WQ)，添加新类型的 struct mlx5_frag_buf，用于分配分段缓冲区而不是连续缓冲区，并使完成队列 (CQ) 使用它，因为它们很大（默认情况下每个 CQ 为 2MB） 跨越RQ）。 这修复了当用户尝试设置更多或更大的环时由于 dma_zalloc_coherent 没有足够的连续一致内存来满足驱动程序的请求而导致的类型失败：“mlx5e_open_locked：mlx5e_open_channels 失败，-12” -> commit: https://github.com/ssbandjl/linux/commit/1c1b522808a18402f043c1418b4e48c7355480cc
                            buf->npages = DIV_ROUND_UP(size, PAGE_SIZE)
                            mlx5_dma_zalloc_coherent_node -> net/mlx5e：在读卡器NUMA节点上分配DMA相干内存，通过亲和性提示和XPS，为每个mlx5e通道分配一个CPU核心。 由 NIC 写入并由 SW 读取的通道 DMA 相干内存（例如 CQ 缓冲区）分配在分配给该通道的 CPU 核心的 NUMA 节点上。 由SW写入并由NIC读取的通道DMA相干存储器（例如SQ/RQ缓冲区）分配在NIC的NUMA节点上。 门铃记录（由SW写入并由NIC读取）是一个例外，因为它被SW更频繁地访问 -> 队列缓冲区的处理——我们分配一堆内存并将其注册到 HCA 虚拟地址 0 的内存区域中
                                cpu_handle = dma_alloc_coherent(device, size, dma_handle, -> net/mlx5：将 dma 设备与 pci 设备分离并通用，mlx5 子功能 (SF) 子设备将在后续补丁中引入。 它将被创建为中介设备并属于 mdev 总线。 有必要以统一的方式处理 PF、VF 和 SF 上的 dma 操作，从而减少对 pdev pci dev struct 的依赖，并直接使用之前补丁中新引入的“struct device”进行工作
                        mlx5_init_fbc -> net/mlx5：重构分段缓冲区结构字段和初始化流程，从 mlx5_frag_buf_ctrl 中取出 struct mlx5_frag_buf，因为不需要管理和控制分段缓冲区 API 的数据路径。 struct mlx5_frag_buf 包含用于管理分段缓冲区的分配和取消分配的控制信息。 它的字段与数据路径无关，因此这里我将它们从 struct mlx5_frag_buf_ctrl 中取出，除了片段数组本身。 此外，还修改了 mlx5_fill_fbc 以初始化 frags 指针。 这意味着必须在调用函数之前分配缓冲区。 一组特定于类型的 *_get_byte_size() 函数被替换为通用函数
                            mlx5_init_fbc_offset
                                fbc->log_frag_strides = PAGE_SHIFT - fbc->log_stride
                        init_eq_buf
                            eqe = get_eqe(eq, i)
                        mlx5_irq_get_index
                        in = kvzalloc(inlen, GFP_KERNEL)
                        mlx5_fill_page_frag_array -> net/mlx5：支持设置dma地址的访问权限，mlx5_fill_page_frag_array()用于将dma地址填充到需要它的资源中，例如QP、RQ等。使用资源时，PA列表权限将被忽略。 对于使用MTT列表的资源，用户需要提供访问权限。 后续补丁使用需要 MTT 列表的资源，因此修改 API 和实现以支持该资源
                            mlx5_fill_page_frag_array_perm
                                pas[i] = cpu_to_be64(buf->frags[i].map | perm)
                        mlx5_cmd_exec MLX5_CMD_OP_CREATE_EQ
                        eq->irqn = pci_irq_vector(dev->pdev, vecidx)
                        mlx5_debug_eq_add(dev, eq) -> net/mlx5：将中断处理程序更改为调用链通知程序，多个 EQ 可能在后续补丁中共享相同的 IRQ。 EQ 将注册到原子链通知器，而不是直接调用 IRQ 处理程序。 不使用 Linux 内置共享 IRQ，因为它强制调用者在调用 free_irq() 之前禁用 IRQ 并清除关联性。 该补丁是 IRQ 和 EQ 逻辑分离的第一步
                            add_res_tree(dev, MLX5_DBG_RSC_EQ, dev->priv.dbg.eq_debugfs,
                                d->root = debugfs_create_dir(resn,  root)
                                debugfs_create_file(field[i], 0400, d->root, &d->fields[i],
                    mlx5_eq_enable
                        mlx5_irq_attach_nb -> net/mlx5：为 SF 分配 MSI-X 矢量池，SF（子功能）当前使用其父物理功能所具有的全局 IRQ 表中的 IRQ。 为了更好地扩展，我们需要分配更多的IRQ并在不同的SF之间共享它们。 驱动程序将维护 3 个独立的 irq 池： 1. 为 PF 使用者提供服务的池（PF 的 netdev、rdma 堆栈），类似于此补丁之前的驱动程序。 即，该池将在 rdma 和 netev 之间共享 irq，并将保留 irq 索引和分配顺序。 最后一个对于 PF netdev rmap (aRFS) 很重要。 2. SF 的控制 IRQ 池。 该池的大小是可以创建的 SF 数量除以 SFS_PER_IRQ。 该池将服务于 SF 的控制路径 EQ。 3. SF 传输队列的完成数据路径 IRQ 池。 该池的大小为：num_irqs_alulated - pf_pool_size - sf_ctrl_pool_size。 该池将为 netdev 和 rdma 堆栈提供服务。 此外，SF 不支持 rmap。 SF 池的共享方法将在下一个补丁中解释。 重要提示：SF 不支持 rmap，因为 rmap 映射无法为不同 core/netdev RX 环共享的 IRQ 正常工作
                            ret = irq_get(irq)
                            atomic_notifier_chain_register
                            mlx5_irq_put
                        eq_update_ci
                            __be32 __iomem *addr = eq->doorbell + (arm ? 0 : 2)
                            u32 val = (eq->cons_index & 0xffffff) | (eq->eqn << 24)
                            __raw_writel((__force u32)cpu_to_be32(val), addr) -> write register
                            mb()
            mlx5_fill_page_frag_array
            mlx5_core_create_cq -> net/mlx5：在核心 create_{cq,dct} 中使用 mlx5_cmd_do()，mlx5_core_create_{cq/dct} 函数是重要的 mlx5 命令函数。 他们自己检查命令执行状态并隐藏有价值的固件故障信息。 对于 mlx5_core/eth 内核用户，这是我们真正想要的，但对于 devx/rdma 用户，隐藏信息至关重要，应该传播给调用者，因此我们将这些命令转换为使用 mlx5_cmd_do 返回 FW/驱动程序和命令 发件箱状态保持不变，并让呼叫者决定如何处理它。 对于 mlx5_core_create_{cq/dct} 的内核调用者或那些只关心二进制状态 (FAIL/SUCCESS) 的调用者，他们必须通过 mlx5_cmd_check() 自行检查状态以恢复当前行为。 err = mlx5_create_cq(in, out) err = mlx5_cmd_check(err, in, out) if (err) // 处理错误 对于 DEVX 用户和那些关心完全可见性的人来说，他们只会将错误传播到用户空间，应用程序可以 检查 err == -EREMOTEIO 是否有效，则 outbox.{status,syndrome} 是否有效。 API 注意：mlx5_cmd_check() 必须由内核用户使用，因为它允许驱动程序拦截命令执行状态并在驱动程序引发错误处理或重置/恢复流程时返回驱动程序模拟状态
                mlx5_create_cq
                    eq = mlx5_eqn2comp_eq(dev, eqn)
                    mlx5_cmd_do MLX5_CMD_OP_CREATE_CQ
                    init_completion(&cq->free)
                    cq->comp = mlx5_add_cq_to_tasklet
                    mlx5_eq_add_cq -> net/mlx5：EQ，不同的 EQ 类型，在 mlx5 中，EQ 的用法有三种， 1. 异步 EQ，由 mlx5 核心内部使用。 FW 命令完成 b． FW 页面请求 c. 一个 EQ 用于所有其他异步事件 2. 完成 EQ，用于 CQ 完成（我们为每个核心创建一个） 3. *用于 RDMA 按需寻呼 (ODP) 的特殊类型 EQ（页面错误）。 *第三种类型至少在mlx5核心中不应该是特殊的，它是另一个具有特定用例的异步事件EQ，它将在接下来的两个补丁中删除，并将其逻辑完全移动到mlx5_ib，因为它是rdma 具体的。 在此补丁中，我们将 struct mlx5_eq 中的用例（eq 类型）特定字段删除为新的 eq 类型特定结构。 结构mlx5_eq_async； 结构mlx5_eq_comp； 结构mlx5_eq_pagefault； 区分特定类型的流程。 将来我们将允许用户创建自己的通用均衡器。 目前，我们将在下一个补丁中只允许 ODP 使用一个。 我们将为那些想要接收 mlx5 异步事件的人引入事件侦听器注册 API。 之后，mlx5 eq 处理将从功能/用户特定处理中清除
                        radix_tree_insert(&table->tree, cq->cqn, cq)
                    mlx5_get_async_eq -> net/mlx5：EQ，私有化 eq_table 和朋友，将不必要的 EQ 表结构和声明从公共 include/linux/mlx5/driver.h 移动到 mlx5_core 的私有区域和 eq.c/eq.h 中。 引入新的 mlx5 EQ API：mlx5_comp_vectors_count(dev)； mlx5_comp_irq_get_affinity_mask(dev, 矢量); 并从 mlx5_ib 或 mlx5e netdevice 使用它们，而不是直接访问 mlx5_core 内部结构
                    mlx5_debug_cq_add -> add_res_tree(dev, MLX5_DBG_RSC_CQ
                mlx5_cmd_check -> net/mlx5：cmdif，添加用于命令执行的新 api，添加 mlx5_cmd_do。 与 mlx5_cmd_exec 不同，此函数不会修改或转换 outbox.status。 该函数将返回： return = 0：命令已执行，outbox.status == MLX5_CMD_STAT_OK。 返回 = -EREMOTEIO：已执行，outbox.status！= MLX5_CMD_STAT_OK。 return < 0：固件或驱动程序无法执行命令。 并记录其他 mlx5_cmd_exec 函数
                    u16 opcode = in_to_opcode(in) -> net/mlx5：cmdif、cmd_check 重构，不要破坏内部低级 cmd_exec 和 cmd_invoke 函数中的命令发件箱。 相反，返回正确的唯一错误代码并将驱动程序错误检查移至 mlx5_cmd_exec() 中的更高级别
                    mlx5_internal_err_ret_value
                    cmd_status_to_err
                    cmd_status_print -> mlx5_core_err_rl cmd_status_str(status), status, syndrome, cmd_status_to_err(status)
            mlx5e_cq_arm -> mlx5_cq_arm
                sn = cq->arm_sn & 3
                ci = cons_index & 0xffffff
                *cq->arm_db = cpu_to_be32(sn << 28 | cmd | ci)
                doorbell[0] = cpu_to_be32(sn << 28 | cmd | ci)
                doorbell[1] = cpu_to_be32(cq->cqn)
                wmb()
                mlx5_write64(doorbell, uar_page + MLX5_CQ_DOORBELL) -> write register
        mlx5e_alloc_drop_rq
            mlx5_wq_cyc_create -> net/mlx5e: RX，在旧版 RQ 中使用循环 WQ，由于旧版 RQ 不支持 LRO，因此 WQ 中没有乱序完成的来源，我们可以使用循环完成。 这具有多个优点： - 减少 WQE 大小（较小的 PCI 事务）。 - 数据路径的开销较低（不处理“下一个”指针）。 - 没有为 WQ 头保留 WQE（链表中需要）。 - 允许在下游补丁中使用 frag 和 dma_info 结构之间的常量映射。 性能测试：ConnectX-4、单核、单 RX 环。 单环 XDP 丢弃的数据包速率大幅提高。 瓶颈从 HW（16Mpps）转移到 SW（20Mpps
                mlx5_db_alloc_node
                mlx5_frag_buf_alloc_node
                mlx5_init_fbc
            xdp_rxq_info_unused -> xdp/mlx5：设置 xdp_rxq_info，mlx5 驱动程序有一个特殊的 drop-RQ 队列（每个接口一个），可以简单地丢弃所有传入流量。 它可以帮助驱动程序在向下/向上操作时保持其他硬件对象（流转向）处于活动状态。 在接口设置期间以及接口关闭时，流量控制对象临时指向它。 它缺少常规 RQ 中设置的许多字段（例如，其状态永远不会切换到 MLX5_RQC_STATE_RDY）。 （感谢 Tariq Toukan 的解释）。 此 drop-RQ 的 XDP RX 队列信息标记为未使用，这允许我们使用与其他 RX 队列相同的删除/释放代码路径。 xdp_rxq_info 的驱动程序挂钩点： * reg ：mlx5e_alloc_rq() * 未使用：mlx5e_alloc_drop_rq() * unreg ：mlx5e_free_rq() 使用示例/bpf 程序在实际硬件上进行测试 -> xdp：新的 XDP rx-queue info 概念的基础 API，此补丁仅介绍核心数据结构和 API 函数。 所有启用 XDP 的驱动程序都必须先使用 API，然后才能使用此信息。 XDP 需要了解有关给定 XDP 帧到达的 RX 队列的更多信息。 对于 XDP bpf-prog 和内核端。 该补丁不是在每次需要新信息时扩展 xdp_buff，而是创建一个单独的主要读取结构 xdp_rxq_info，其中包含此信息。 我们强调此数据/缓存行用于只读信息。 这不适用于动态的每个数据包信息，请使用 data_meta 来处理此类用例。 性能优势是该信息可以在 RX 环初始化时设置，而不是更新 xdp_buff 中的 N 成员。 一个可能的（驱动程序级别）微优化是，每个 XDP/NAPI 循环可以执行一次 xdp_buff->rxq 分配。 额外的指针 deref 仅发生在需要访问此信息的程序中（因此，不会减慢现有用例）
                xdp_rxq->reg_state = REG_STATE_UNUSED
        mlx5e_create_rq
            MLX5_SET(rqc,  rqc, cqn,		rq->cq.mcq.cqn)
            MLX5_RQC_STATE_RST
            mlx5_fill_page_frag_array
            mlx5_core_create_rq
                MLX5_CMD_OP_CREATE_RQ
        mlx5e_modify_rq_state -> net/mlx5e：添加接口关闭丢弃的数据包统计信息，添加了以下数据包丢弃计数器： Rx 接口关闭丢弃的数据包 - 对 ETH 接口关闭时收到的数据包进行计数。 该计数器将在 ethtool 上显示为名为 rx_if_down_packets 的新计数器。 该实现为 drop rq 分配一个 q_counter，它在接口关闭时获取所有接收到的流量 -> net/mlx5e：引入mlx5e_flush_rq函数，添加刷新RQ的函数：清理描述符，释放页面并重置RQ。 此过程由恢复流程使用，并且还将在以下提交中使用，以在将通道切换到 XSK 模式时释放一些内存
            mlx5e_rqwq_reset -> net/mlx5e：在将 RQ 状态从 RST 移动到 RDY 之前重置 RQ 门铃计数器，在将 RQ 从 RST 移动到 RDY 状态之前将 RQ 门铃计数器初始化为零。 根据硬件规范，当 RQ 返回 RDY 状态时，完成时的描述符 ID 会被重置。 门铃记录必须符合
                mlx5_wq_ll_reset
                    mlx5_wq_ll_init_list
                    mlx5_wq_ll_update_db_record
                mlx5_wq_cyc_reset
            mlx5_core_modify_rq
    mlx5_tunnel_inner_ft_supported -> net/mlx5e：不缓存隧道卸载功能，当 mlx5e 在设备运行状况恢复后再次连接时，设备功能可能已被 eswitch 管理器更改。 例如，在一个流中，当 ECPF 在传统模式和 switchdev 之间更改 eswitch 模式时，它会更新流表隧道功能。 缓存的值仅在一处使用，因此只需检查该处的功能即可
        mlx5_tunnel_any_rx_proto_supported
            mlx5_tunnel_proto_supported_rx
    mlx5e_rx_res_create
        mlx5e_rx_res_rss_init_def -> net/mlx5e: 支持多个 RSS 上下文，添加对多个 RSS 上下文的支持。 非默认RSS上下文的资源是按需分配和创建的。 每个 RSS 上下文都可以通过实现的 ethtool 操作单独控制和配置。 这里我们将上下文总数限制为 16。我们不对间接表内容强制执行任何类型的新限制。 更具体地，两个单独的上下文可以被配置为完全或部分指向同一组接收环。 默认 RSS 上下文（索引 0）是使用其完整的 TIR 集创建的。 所有其他上下文均使用空集创建，然后在添加转向规则时在首次使用时添加 TIR。 我们使用引用计数机制来确保 RSS 上下文在规则指向它之前不会被删除。 当存在多个 RSS 上下文时阻止 ethtool set_channels 操作，因为当前内核无法防止不一致的通道配置破坏非默认 RSS 上下文
            mlx5e_rss_init -> net/mlx5e：重构 mlx5e_rss_init() 和 mlx5e_rss_free() API，引入以下代码重构： 1) 引入用于创建和销毁 rss 对象的单个 API，分别为 mlx5e_rss_create() 和 mlx5e_rss_destroy()。 2) mlx5e_rss_create() 构造并初始化 RSS 对象取决于函数 new param enum mlx5e_rss_create_type。 调用者（如 rx_res.c）将不再需要通过 mlx5e_rss_alloc() 分配 RSS 对象并通过 mlx5e_rss_init_no_tirs() 或 mlx5e_rss_init() 立即初始化它，这将通过对 mlx5e_rss_create() 的单次调用来完成。 因此，mlx5e_rss_alloc() 和 mlx5e_rss_init_no_tirs() 已从 rss.h 文件中删除并成为静态函数
                mlx5e_rss_params_indir_init
                    indir->table = kvmalloc_array -> net/mlx5e：为支持更多通道数做准备，数据中心服务器CPU数量随着时间的推移不断变大。 目前，我们的驱动程序将通道数限制为 128。最大通道数是由硬编码定义 (en.h/MLX5E_MAX_NUM_CHANNELS) 强制执行和限制的，即使设备和机器 (CPU 数) 可以允许更多通道数。 重构当前的实现以处理更多通道。 后续补丁中将增加最大支持通道数。 下面介绍 RQT 大小计算/分配方案： 1) 保留当前 RQT 大小 256，通道数最多为 128（旧限制）。 2) 对于更大的通道数，RQT 大小的计算方法是将通道数乘以 2，并将结果四舍五入到最接近的 2 次方。如果计算出的 RQT 大小超过 NIC 支持的最大大小，则回退到此最大 RQT 大小 (1 << log_max_rqt_size)。 由于 RQT 大小不再是静态的，因此可以动态分配和释放间接表 SW 影子
                mlx5e_rss_init_no_tirs
                    mlx5e_rss_params_init
                        rss->hash.hfunc = ETH_RSS_HASH_TOP
                        netdev_rss_key_fill -> net：提供每主机 RSS 密钥通用基础设施，RSS（接收方缩放）通常使用 Toeplitz 哈希和 40 或 52 字节的 RSS 密钥。 有些驱动程序使用常量（且众所周知的密钥），有些驱动程序每个端口使用随机密钥，使得绑定设置难以调整。 考虑到队列数量通常是 2 的幂，众所周知的密钥会增加攻击面。 该补丁提供了基础设施来帮助驾驶员做正确的事情。 驱动程序应使用 netdev_rss_key_fill() 来初始化其 RSS 密钥，即使它们提供 ethtool -X 支持以让用户稍后重新定义密钥。 新的 /proc/sys/net/core/netdev_rss_key 文件可用于获取主机 RSS 密钥，即使驱动程序不提供 ethtool -x 支持，以防某些应用程序想要精确设置流以匹配某些 RX 队列。 测试： myhost:# cat /proc/sys/net/core/netdev_rss_key 11:63:99:bb:79:fb:a5:a7:07:45:b2:20:bf:02:42:2d:08: 1a:dd:19:2b:6b:23:ac:56:28:9d:70:c3:ac:e8:16:4b:b7:c1:10:53:a4:78:41:36:40: 74:b6:15:ca:27:44:aa:b3:4d:72 myhost:# ethtool -x eth0 具有 8 个 RX 环的 eth0 的 RX 流哈希间接表：0: 0 1 2 3 4 5 6 7 RSS 哈希密钥：11:63:99:bb:79:fb:a5:a7:07:45:b2:20:bf:02:42:2d:08:1a:dd:19:2b:6b:23 :ac:56:28:9d:70:c3:ac:e8:16:4b:b7:c1:10:53:a4:78:41
                            net_get_random_once -> get_random_bytes
                        mlx5e_rss_get_default_tt_config -> static const struct mlx5e_rss_params_traffic_type rss_default_config[MLX5E_NUM_INDIR_TIRS]
                            u8 l3_prot_type
                            u8 l4_prot_type
                            u32 rx_hash_fields
                    mlx5e_rqt_init_direct -> mlx5e_rqt_init
                        mlx5_core_create_rqt -> MLX5_CMD_OP_CREATE_RQT
                mlx5e_rss_create_tirs
                    mlx5e_rss_create_tir
                        rss_get_tirp
                        mlx5e_tir_builder_alloc
                        mlx5e_tir_builder_build_rqt
                            mlx5e_tir_builder_get_tirc
                        mlx5e_tir_builder_build_packet_merge
                            const unsigned int rough_max_l2_l3_hdr_sz = 256
                            MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ - rough_max_l2_l3_hdr_sz) >> 8 -> net/mlx5e：为 SHAMPO 功能添加控制路径，此提交引入了 SHAMPO 功能的控制路径基础设施。 SHAMPO 功能通过将数据包拆分为标头和有效负载来实现数据包拼接，标头放置在专用缓冲区上，有效负载放置在 RX 环上，这允许在接收缓冲区中将流的数据部分连续拼接在一起。 SHAMPO 功能被实现为链表跨步 RQ 功能。 为了支持数据包分割和有效负载拼接： - 放大ICOSQ 和相应的CQ 以支持报头缓冲存储器区域。 - 添加支持在 open_rq 函数中使用 SHAMPO 功能集创建链表跨步 RQ。 - 添加释放函数和 SHAMPO 标头缓冲区的相应调用。 - 添加 mlx5e_create_umr_klm_mkey 以支持标头缓冲区的 KLM mkey。 - 将 mlx5e_create_umr_mkey 重命名为 mlx5e_create_umr_mtt_mkey
                        mlx5e_rss_get_tt_config
                        mlx5e_tir_builder_build_rss
                        mlx5e_tir_init
                            mlx5_core_create_tir -> MLX5_CMD_OP_CREATE_TIR
                            list_add(&tir->list, &res->td.tirs_list)
                        mlx5e_tir_builder_free
                            kvfree
            mlx5e_rss_set_indir_uniform
                indir->table[i] = i % num_channels
        mlx5e_rx_res_channels_init
            mlx5e_tir_builder_alloc -> net/mlx5e：隐藏 mlx5e_rx_res 的所有实现细节，此提交将 struct mlx5e_rx_res 的所有实现细节移至 en/rx_res.c 下。 现在，所有对 RX 资源的访问都是使用方法完成的。 将 RX 资源封装到一个对象中可以实现更好的可管理性，因为所有实现细节现在都位于一个位置，外部代码只能使用一组有限的 API 方法来初始化/拆卸整个事物、重新配置 RSS 和 LRO 参数、连接 TIR 用于流量控制和激活/停用 TIR。 mlx5e_rx_res 是独立的，不依赖于 struct mlx5e_priv 或 include en.h
            mlx5e_rqt_init_direct
            mlx5e_tir_builder_build_rqt
            mlx5e_tir_builder_build_packet_merge
            mlx5e_tir_builder_build_direct
            mlx5e_tir_init
            mlx5e_tir_builder_clear
        mlx5e_rx_res_ptp_init
            mlx5e_tir_builder_alloc
            mlx5e_rqt_init_direct
            mlx5e_tir_builder_build_rqt
            mlx5e_tir_builder_build_direct
            mlx5e_tir_init
    mlx5e_create_flow_steering
        mlx5_get_flow_namespace -> net/mlx5：使用mlx5_en的流量控制基础设施，公开新的流量控制API并删除旧的。 需要进行的更改很少： 1. 以太网流量控制遵循现有实现，但使用新的控制 API。 旧的流量控制实现已被删除。 2. 将 E-switch FDB 管理移至使用新 API。 3. 加载驱动程序时，调用 mlx5_init_fs 初始化流控制树结构，为 NIC 接收和 E-switch FDB 打开命名空间。 4.驱动卸载时调用mlx5_cleanup_fs
            enum mlx5_flow_namespace_type
        mlx5e_fs_set_ns
        mlx5e_arfs_create_tables
            arfs->wq = create_singlethread_workqueue("mlx5e_arfs")
            arfs_create_table
                mlx5_create_flow_table -> net/mlx5：流量控制，添加 vport ACL 支持，更新相关流量控制设备结构和命令以支持 vport。 更新流量控制核心 API 以接收 vport 号。 添加入口和出口 ACL 流表名称空间。 添加ACL流表支持： * ACL（访问控制列表）流表是仅包含允许/丢弃转向规则的表。 * 我们有两种类型的 ACL 流表 - 入口和出口。 * ACL 处理从 E-Switch FDB 表发送/到 E-Switch FDB 表的流量，入口是指从 Vport 发送到 E-Switch 的流量，Egress 是指从 E-Switch 发送到 vport 的流量。 * 根据从 VF 发送的流量检查入口 ACL 流表允许/丢弃规则。 * 根据发送到 VF 的流量检查出口 ACL 流表允许/丢弃规则
                    __mlx5_create_flow_table -> net/mlx5：重构创建流表方法以接受底层QP，IB流表需要底层QP来执行流控制。 这里我们更改流表创建的 API 以接受底层 QP 编号作为参数，以支持 IB (IPoIB) 流控制
                        fs_prio = find_prio(ns, ft_attr->prio)
                        alloc_flow_table
                        tree_init_node(&ft->node, del_hw_flow_table, del_sw_flow_table) -> net/mlx5：支持并行更新导向规则，添加新的流量导向规则大部分时间花在执行固件命令上。 最常见的操作是添加新的流量引导条目。 为了提高更新率，我们通过执行以下操作并行化命令：1）用读写器信号量替换互斥锁，并仅在必要时才获取写锁（例如，分配新的流表条目索引或向流表条目添加节点） 父母的子女名单）。 当我们尝试在父级的子级列表中找到合适的子级时（例如，搜索具有相同规则 match_criteria 的流组），那么我们只获取读锁。 2）添加版本控制机制——每个转向实体（FT、FG、FTE、DST）都会有一个增量版本。 当实体更改时，版本会增加（例如，当新的 FTE 添加到 FG 时 - FG 的版本会增加）。 使用版本控制来确定实体的子实体的最后一次遍历是否有效或需要在写锁定下重新扫描。 此支持将转向规则的插入速率从 ~5k/秒提高到 ~40k/秒 -> net/mlx5_core：添加流转向基础数据结构，介绍将代表 ConnectX-4 Flow Steering 的基础数据结构及其操作，该数据结构基本上是一棵树和所有流转向对象，例如（流表/流组） /FTE/etc ..) 表示为 fs_node(s)。 fs_node 是描述基本树节点的基础对象，具有以下额外信息： type：描述节点（Object）的运行时类型。 lock：锁定该节点子树。 ref_count：子级数+当前引用数。 remove_func：通用析构函数。 一旦在以下补丁中添加用法，fs_node 类型将被使用和解释
                            INIT_LIST_HEAD(&node->list)
                arfs_create_groups -> net/mlx5e：创建 aRFS 流表，创建以下四个流表以供 aRFS 使用： 1. IPv4 TCP - 过滤 IPv4 TCP 数据包的 4 元组。 2. IPv6 TCP - 过滤 IPv6 TCP 数据包的 4 元组。 3. IPv4 UDP - 过滤 IPv4 UDP 数据包的 4 元组。 4. IPv6 UDP - 过滤 IPv6 UDP 数据包的 4 元组。 每个流表有两个流组：一个用于四元组过滤（完全匹配），另一个包含 * 规则作为未命中规则。 完全匹配规则意味着 aRFS 命中，数据包将被转发到专用 RQ/Core，未命中规则数据包将被转发到默认 RSS 哈希
                    ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in) -> net/mlx5_core: 引入流控制自动分组流表，当用户向自动分组流表添加规则时，我们会搜索具有相同匹配条件的流组，如果没有找到这样的组，则我们会创建具有所需匹配条件的新流组 并将规则插入到该组中。 我们将流表分为 required_groups + 1，以便为与任何现有组都不匹配的规则保留一部分流表
                        down_write_ref_node -> net/mlx5：向节点删除函数添加锁定标志，向节点删除函数添加锁定标志，以指示父级是否已从调用者函数锁定，作为外部锁定的预处理。 当前始终使用 false 且没有功能更改
                        alloc_insert_flow_group -> net/mlx5：重构FTE和FG创建代码，将创建代码拆分为两部分：1）对象分配-分配转向节点并初始化其资源。 2）固件命令执行。 向每个节点添加活动标志 - 该标志指示该对象是否存在于硬件中，如果不存在，我们不会在错误流中释放硬件资源。 此更改将使我们能够仅在第一部分上对父节点（例如用于 FTE 创建的 FG）进行写锁定
                            struct mlx5_flow_steering *steering = get_steering(&ft->node) -> net/mlx5：添加FG和FTE内存池，添加流组和流表条目的内存池分配。 它很有用，因为这些对象并不小，并且可以多次分配/释放
                            alloc_flow_group
                                fg = kmem_cache_zalloc
                                rhashtable_init
                                ida_init(&fg->fte_allocator)
                                fg->node.type =  FS_TYPE_FLOW_GROUP
                            rhltable_insert
                            tree_init_node(&fg->node, del_hw_flow_group, del_sw_flow_group)
                            tree_add_node(&fg->node, &ft->node)
                        trace_mlx5_fs_add_fg
                arfs_add_default_rule
                    dest.type = MLX5_FLOW_DESTINATION_TYPE_TIR
                    tt = arfs_get_tt(type) -> net/mlx5e：使用函数将aRFS映射到流量类型，为了更好的代码重用和可读性，使用现有函数arfs_get_tt()将arfs_type映射到mlx5e_traffic_types，而不是重复switch-case逻辑
                    mlx5e_rx_res_get_tirn_rss -> mlx5e_rss_get_tirn -> tir = rss_get_tir(rss, tt, inner)
                        rss_get_tirp -> inner ? &rss->inner_tir[tt] : &rss->tir[tt]
                    mlx5_add_flow_rules
            mlx5e_fs_set_arfs
        mlx5e_create_inner_ttc_table
            mlx5_tunnel_inner_ft_supported
            mlx5e_set_inner_ttc_params
                mlx5_get_flow_namespace
                mlx5e_rx_res_get_tirn_direct
                mlx5e_rx_res_get_tirn_rss_inner
            mlx5_create_inner_ttc_table
            return PTR_ERR_OR_ZERO(fs->inner_ttc)
        mlx5e_create_ttc_table
            mlx5e_set_ttc_params
            mlx5_create_ttc_table -> net/mlx5：嵌入 mlx5_ttc_table，mlx5_ttc_table 结构不应暴露给用户，因此此补丁使其成为 ttc 的内部结构。 另外添加一个getter函数来获取TTC流表，方便需要添加指向其的规则的用户
                mlx5_create_flow_table
                mlx5_create_ttc_table_groups
                    ttc->g[ttc->num_groups] = mlx5_create_flow_group(ttc->t, in) -> net/mlx5_core: 引入流控制自动分组流表，当用户向自动分组流表添加规则时，我们会搜索具有相同匹配条件的流组，如果没有找到这样的组，则我们会创建具有所需匹配条件的新流组 并将规则插入到该组中。 我们将流表分为 required_groups + 1，以便为与任何现有组都不匹配的规则保留一部分流表
                        struct mlx5_flow_root_namespace *root = find_root(&ft->node) -> net/mlx5：在 fs 和 cmd 之间添加填充层，填充层允许每个命名空间为添加/删除/更新命令定义可能不同的功能。 这里介绍的垫片层将用于支持 FPGA 的流量控制
                        alloc_insert_flow_group
                        err = root->cmds->create_flow_group(root, ft, fg_in, fg) -> mlx5_cmd_create_flow_group -> net/mlx5：将流控制对象传递给 fs_cmd，将流控制对象而不是其属性传递给 fs_cmd 以减少参数数量，此外它将用于更新对象字段。 传递流控制根命名空间而不是设备，因此将具有 fs_cmd 层中的命名空间的上下文
                            MLX5_CMD_OP_CREATE_FLOW_GROUP
                mlx5_generate_ttc_table_rules
                    mlx5_generate_ttc_rule
                        MLX5_CAP_FLOWTABLE_NIC_RX
                        mlx5_etype_to_ipv
                        mlx5_add_flow_rules
                    mlx5_tunnel_inner_ft_supported
                    mlx5_tunnel_proto_supported_rx
        mlx5e_create_l2_table
            mlx5_create_flow_table
            mlx5e_create_l2_table_groups
                eth_zero_addr(mc_dmac) -> Assign zero address
        mlx5e_fs_create_vlan_table
            mlx5e_create_vlan_table_groups -> __mlx5e_create_vlan_table_groups
            mlx5e_fs_add_vlan_rules
                mlx5e_add_vlan_rule
                    mlx5e_vport_context_update_vlans
                        mlx5_modify_nic_vport_vlans -> net/mlx5：引入访问函数来修改/查询 vport vlan，这些函数需要通知即将到来的 L2 表和 SR-IOV E-Switch（FDB）管理器（PF）、NIC vport（vf）vlan 表更改。 以太网 sriov 和 l2 表管理的准备
                            MLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT
                    __mlx5e_add_vlan_rule
                        dest.ft = fs->l2.ft.t
                        *rule_p = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1) -> net/mlx5：设置新的转向条目时支持 encap id，为了支持添加封装标头的转向规则，需要 encap_id 参数。 添加新的 mlx5_flow_act 结构，其中包含与操作相关的参数：action、flow_tag 和 encap_id。 添加新的转向规则时使用 mlx5_flow_act 结构。 此补丁不会改变任何功能
                for_each_set_bit(i, fs->vlan->active_cvlans
                for_each_set_bit(i, fs->vlan->active_svlans
                mlx5e_fs_add_any_vid_rules
                    mlx5e_add_vlan_rule
        mlx5e_ptp_alloc_rx_fs
            mlx5e_profile_feature_cap
            mlx5e_fs_set_ptp
        mlx5e_ethtool_init_steering
    mlx5e_tc_nic_init -> net/mlx5e：对卸载的 TC eswitch 流使用共享表，目前，每个表示器 netdev 使用自己的哈希表来保留从 TC 流 (f->cookie) 到驱动程序卸载实例的映射。 该表最初是为了卸载 TC NIC（而非 eswitch）规则而添加的。 当核心 TC 代码要求我们添加相同的流两次时（例如在 egdev 用例下），此方案就会中断，因为我们没有发现这一点，并且使用错误的源 vport 将第二个流卸载到硬件中。 作为解决此问题的前期步骤，我们转而使用单个表来保存所有卸载的 TC eswitch 流。 该表位于 eswitch 上行链路表示器对象
        mlx5e_mod_hdr_tbl_init
            hash_init(tbl->hlist)
        hash_init(tc->hairpin_tbl)
        lockdep_set_class -> 自行创建一种新的class。很多复杂的子系统都自己设置自己的class，比如inode，各种文件系统等
        lockdep_init_map
        mlx5_query_nic_system_image_guid -> net/mlx5：缓存系统映像 GUID，系统映像 GUID 是一个只读字段，TC 卸载代码使用它来确定两个 mlx5 设备在添加流时是否属于同一 ASIC。 读取一次并将其保存在核心设备上，而不是每次添加卸载流时都进行查询
            mlx5_query_nic_vport_system_image_guid
                mlx5_query_nic_vport_context -> net/mlx5：更新查询/修改 vport MAC 地址的访问功能，为了准备 SR-IOV，我们在此处添加一个 API，使每个 e-switch 客户端 (PF/VF) 能够配置其 L2 MAC 地址并为 e-switch 管理器（通常是 PF）访问它们，以便能够将它们配置到 e-switch 中。 因此，我们现在将 vport num 参数传递给 mlx5_query_nic_vport_context，以便 PF 可以访问其他 vport 上下文。 以太网 sriov 和 l2 表管理的准备
                    MLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT
            mlx5_query_hca_vport_system_image_guid -> net/mlx5_core：添加新的查询 HCA vport 命令，添加了以下命令的实现： 1. QUERY_HCA_VPORT_GID 2. QUERY_HCA_VPORT_PKEY 3. QUERY_HCA_VPORT_CONTEXT 当我们在 IB 驱动程序中使用 ISSI > 0 时也将需要它们
                MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT
                rep->port_guid ...
        mapping_create_for_id
            mapping_create -> net/mlx5：引入映射基础设施，用于将唯一 id 映射到数据，添加一个新接口，用于将数据映射到给定 id 范围 (max_id)，然后再映射回来。 它使用 xarray 作为 id 分配器并查找给定的 id。 对于锁定，它使用 xa_lock (spin_lock) 进行 add()/del()，使用 rcu_read_lock 进行 find()。 该映射接口还支持通过工作队列延迟映射删除。 这是针对我们需要映射有一些宽限期以便再次找到它的情况，例如，来自硬件的数据包被规则标记为不再存在的旧映射
                INIT_DELAYED_WORK(&ctx->dwork, mapping_work_handler)
                xa_init_flags
        mlx5e_tc_nic_create_miss_table -> net/mlx5e：TC网卡模式，修复tc链miss表，引用的commit更改了按需创建的promisc表，网卡表中的最高优先级替换了vlan表，这导致tc NIC表miss流跳过prmoisc表 因为它使用 vlan 表作为 miss 表。 NIC 模式下的 OVS 卸载默认使用 promisc，因此由 tc NIC 表未命中流处理的任何单播数据包都将跳过 promisc 规则并被丢弃。 通过在新的 tc 级别中添加低优先级的新空表并将 nic tc 链未命中指向它来修复此问题，新表受到管理，因此如果禁用 promisc，它将指向 vlan 表；如果启用，它将指向 promisc 表
            mlx5_get_flow_namespace
            mlx5_create_auto_grouped_flow_table
                mlx5_create_flow_table
        mlx5_chains_create -> net/mlx5：重构多链和 prio 支持，将链基础设施与 eswitch 分离，并使其通用以支持其他转向命名空间。 该更改定义了一个不可知的数据结构，以保留用于在任何转向命名空间中维护流表链接的所有相关信息。 每个需要表链接的命名空间都需要分配这样的数据结构。 链创建代码将从调用者处接收转向命名空间和流表参数，因此在创建维护表链接功能所需的资源时，它将以不可知的方式进行操作，同时与 eswitch 特定功能相关的部分代码将移动到 eswitch 文件中
            mlx5_chains_init
                rhashtable_init(&chains_ht(chains), &chain_params)
                rhashtable_init(&prios_ht(chains), &prio_params)
        mlx5_chains_print_info
        mlx5e_tc_post_act_init -> net/mlx5e：引入后操作基础设施，一些 tc 操作在硬件中使用多个表进行建模，导致 tc 操作列表拆分。 例如，CT 动作是通过跳转到由 nf flowtable 控制的 ct 表来建模的。 sFlow 在硬件中跳转到示例表，该示例表继续到“默认表”，并应在其中继续处理操作列表。 多表操作使用唯一的 fte_id 在硬件中建模。 fte_id 在跳转到表之前设置。 拆分操作继续到操作后表，其中匹配的 fte_id 值继续执行 tc 操作列表。 目前动作后设计仅通过ct动作实现。 引入后操作基础设施作为通过 sFlow 卸载功能重用它的前置步骤。 初始化和销毁公共后操作表。 重构 ct 卸载以在下一个补丁中使用通用的帖子表基础设施
            mlx5_chains_create_global_table
                mlx5_chains_create_global_table
                chain = mlx5_chains_get_chain_range(chains)
                prio = mlx5_chains_get_prio_range(chains)
                level = mlx5_chains_get_level_range(chains)
                mlx5_chains_create_table
                    mlx5_chains_get_nf_ft_chain
                    mlx5_create_auto_grouped_flow_table
            xa_init_flags(&post_act->ids, XA_FLAGS_ALLOC1)
        register_netdevice_notifier_dev_net -> __register_netdevice_notifier_net
            raw_notifier_chain_register
        mlx5e_tc_debugfs_init
            tc->dfs_root = debugfs_create_dir("tc"
            debugfs_create_file("hairpin_num_active"
            debugfs_create_file("hairpin_table_dump"
        mlx5e_tc_act_stats_create -> net/mlx5e：TC，将 tc 操作 cookie 映射到硬件计数器，当前硬件计数器与流 cookie 关联。 这不适用于使用分支操作的流，这些操作需要返回每个操作的统计信息。 单个计数器可以应用于多个操作。 反向扫描流程操作（从最后一个操作到第一个操作），同时缓存最后一个计数器。 将所有流属性 tc action cookie 与当前缓存的计数器相关联
            rhashtable_init
    mlx5e_accel_init_rx -> net/mlx5e：kTLS，添加 kTLS RX 硬件卸载支持，实现对 kTLS RX 硬件卸载功能的驱动程序支持。 下游补丁中添加了重新同步支持。 新的卸载上下文通过每通道异步 ICOSQ 发布其静态/进度参数 WQE，并受到自旋锁的保护。 通道/RQ 根据套接字的 rxq 索引进行选择。 该功能默认处于关闭状态。 可以通过以下方式打开： $ ethtool -K <if> tls-hw-rx-offload on 新的 TLS-RX 工作队列用于允许在 NAPI 上下文之外异步添加转向规则。 它还将在重新同步过程中的下游补丁中使用
        mlx5e_ktls_init_rx
            mlx5e_is_ktls_rx
            priv->tls->rx_wq = create_singlethread_workqueue("mlx5e_tls_rx")
            mlx5e_accel_fs_tcp_create
                mlx5e_fs_set_accel_tcp
                accel_fs_tcp_create_table
                    accel_fs_tcp_create_groups
                    accel_fs_tcp_add_default_rule
                accel_fs_tcp_enable
                    mlx5_ttc_fwd_dest -> mlx5_modify_rule_destination
                        _mlx5_modify_rule_destination -> net/mlx5：添加多目标支持，当前在调用 mlx5_add_flow_rule 时我们仅接受一个流目标，此提交允许传递多个目标。 这一变化迫使我们将回报结构改为更灵活的结构。 我们引入一个流句柄（struct mlx5_flow_handle），它在内部保存创建的规则的编号，并保存一个数组，其中每个单元格都指向一个流规则。 从消费者（mlx5_add_flow_rule）的角度来看，此更改只是装饰性的，只需要更改它们存储的返回值的类型。 从核心角度来看，我们现在需要在分配和删除规则时使用循环（例如给我们一个流处理程序）
                            err = root->cmds->update_fte(root, ft, fg,



queue and queue depth(descriptor)


hash:
ethtool -x eth0

内核有一种称为 NAPI（New API）的机制，允许网卡注册自己的 poll() 方法，执行这个方法就会从相应的网卡收包。 关于 NAPI 后面会有更详细介绍，这里只看一下注册时的调用栈


mlx5e_open(netdev);
 |-mlx5e_open_locked
    |-mlx5e_open_channels
    |  |-mlx5e_open_channel
    |     |-netif_napi_add(netdev, &c->napi, mlx5e_napi_poll, 64); // 注册 NAPI
    |     |-mlx5e_open_queues
    |         |-mlx5e_open_cq
    |         |   |-mlx5e_alloc_cq
    |         |       |-mlx5e_alloc_cq_common
    |         |           |-mcq->comp = mlx5e_completion_event;
    |         |-napi_enable(&c->napi)                              // 启用 NAPI
    |-mlx5e_activate_priv_channels
       |-mlx5e_activate_channels
           |-for ch in channels:
               mlx5e_activate_channel                              // 启用硬中断（IRQ）
                 |-mlx5e_activate_rq
                    |-mlx5e_trigger_irq
                        mlx5_wq_cyc_ctr2ix
                        mlx5e_post_nop
                        mlx5e_notify_hw

中断方式针对高吞吐场景的改进是 NAPI 方式，简单来说它结合了轮询和中断两种方式。 绝大部分网卡都是这种模式，本文所用的 mlx5_core 就属于这一类



4 触发硬件中断（IRQ）
DMA 将包复制到 ring buffer（内核内存）之后，网卡发起对应的中断（在 MSI-X 场景，中断和 RX 队列绑定）。 来个具体例子，下面是台 40 核的机器，
cat /proc/interrupts



4.1 中断处理函数（ISR）注册
这个过程其实是在网卡驱动初始化（第一章）时完成的，但是第一章的内容太多了，所以我们放到这里看一下：

mlx5_load
 |-mlx5_irq_table_create
 |  |-table->irq = kcalloc()
 |  |-pci_alloc_irq_vectors(dev->pdev, MLX5_IRQ_VEC_COMP_BASE + 1, nvec, PCI_IRQ_MSIX);
 |  |-request_irqs
 |     |-for i in vectors:
 |         irq  = mlx5_irq_get(dev, i);
 |         irqn = pci_irq_vector(dev->pdev, i);
 |         irq_set_name(sprintf("mlx5_comp%d", vecidx-MLX5_IRQ_VEC_COMP_BASE), i);
 |         snprintf(irq->name, "%s@pci:%s", name, pci_name(dev->pdev));
 |         request_irq(irqn, mlx5_irq_int_handler, 0, irq->name, &irq->nh); // 注册中断处理函数
 |
 |-mlx5_eq_table_create      // 初始化事件队列（EventQueue）
    |-create_comp_eqs(dev)   // Completion EQ
        for ncomp_eqs:
          eq->irq_nb.notifier_call = mlx5_eq_comp_int; // 每个 EQ 事件完成时的回调函数
          create_map_eq()
          mlx5_eq_enable()


驱动的硬中断处理函数做的事情很少，但软中断将会在和硬中断相同的 CPU 上执行。这就 是为什么给每个 CPU 一个特定的硬中断非常重要：这个 CPU 不仅处理这个硬中断，而且通 过 NAPI 处理接下来的软中断来收包



5.1 内核网络设备子系统初始化
网络设备（netdev）的初始化在 net_dev_init()，在系统启动期间执行：

// net/core/dev.c
static int __init net_dev_init(void)
    dev_proc_init();        // 注册 /proc/net/{dev,softnet_stat,ptytpe}


内核的软中断系统是一种在硬中断处理上下文（驱动中）之外执行代码的机制。  可以把软中断系统想象成一系列内核线程（每个 CPU 一个）， 这些线程执行针对不同事件注册的处理函数（handler）。  如果用过 top 命令，可能会注意到 ksoftirqd/0 这个内核线程，其表示这个软中断线程跑在 CPU 0 上。  内核子系统（比如网络）能通过 open_softirq() 注册软中断处理函数。


5.2 内核调度器与调用栈概览
5.2.1 调用栈
调度执行到某个特定线程的调用栈：

smpboot_thread_fn
  |-while (1) {
      set_current_state(TASK_INTERRUPTIBLE); // 设置当前 CPU 为可中断状态

      if !thread_should_run {                // 无 pending 的软中断
          preempt_enable_no_resched();
          schedule();
      } else {                               // 有 pending 的软中断
          __set_current_state(TASK_RUNNING);
          preempt_enable();
          thread_fn(td->cpu);                // 如果此时执行的是 ksoftirqd 线程，
            |-run_ksoftirqd                  // 那会执行 run_ksoftirqd() 回调函数
                |-local_irq_disable();       // 关闭所在 CPU 的所有硬中断
                |
                |-if local_softirq_pending() {
                |    __do_softirq();
                |    local_irq_enable();      // 重新打开所在 CPU 的所有硬中断
                |    cond_resched();          // 将 CPU 交还给调度器
                |    return;
                |-}
                |
                |-local_irq_enable();         // 重新打开所在 CPU 的所有硬中断
      }
    }
如果此时调度到的是 ksoftirqd 线程，那 thread_fn() 执行的就是 run_ksoftirqd()。



cat /proc/net/ptype

如今大部分网卡都在硬件层支持多队列。这意味着收进来的包会被通过 DMA 放到 位于不同内存的队列上，而不同的队列有相应的 NAPI 变量管理软中断 poll()过程。因此， 多个 CPU 同时处理从网卡来的中断，处理收包过程。 这个特性被称作 RSS（Receive Side Scaling，接收端水平扩展


I/O 加速技术( I/OAT ) 是Intel与高端服务器主板捆绑在一起的DMA 引擎（嵌入式DMA 控制器） ，它通过执行直接内存访问(DMA) 从主处理器卸载内存副本。它通常用于加速网络流量，但支持任何类型的复制。


pci_request_regions

req irq:
pci_alloc_irq_vectors



mlx5_send:
xmit
mlx5e_xmit



code struct:
net/mlx5：以太网数据路径文件
en_[rt]x.c 包含特定于 tx 或 rx 的数据路径相关代码。
en_txrx.c 包含 rx 和 tx 通用的数据路径代码，这主要是 napi 相关代码。

以下是数据路径中硬件和驱动程序正在使用的对象：
通道 - 每个 IRQ 一个通道。 每个通道对象包含：
RQ - 描述接收队列
TIR - 每种流类型一个 TIR（传输接口接收）对象。 TIR 包含接收流类型的属性（例如 IPv4、IPv6 等）。
流在流表中定义。 目前，TIR 描述了 RSS 哈希参数（如果存在）和 LRO 属性。
SQ - 描述 tx 队列。 每个TC（流量类别）有一个SQ（发送队列）。
TIS - 每个 TC 有一个 TIS（传输接口发送）。 它描述了 TC，稍后可能会扩展以描述更多传输属性。
RQ和SQ都继承自对象WQ（工作队列）。 描述 CQE 的 WQE 在内存中的布局的通用代码位于文件 wq.[cj]
对于每个通道，都有一个用于 RX 和 TX 的 NAPI 上下文。
驱动程序正在使用 netdev_alloc_skb() 来分配 skb。


通过netdev_alloc_skb()函数分配一个足够大的缓冲区来包含一个数据包和以太网头: · 第二步通过减少尾部空间为头部保留对齐的内存


操作码:
enum {
    MLX5_OPCODE_NOP			= 0x00,
    MLX5_OPCODE_SEND_INVAL		= 0x01,
    MLX5_OPCODE_RDMA_WRITE		= 0x08,
    MLX5_OPCODE_RDMA_WRITE_IMM	= 0x09,
    MLX5_OPCODE_SEND		= 0x0a,
    MLX5_OPCODE_SEND_IMM		= 0x0b,
    MLX5_OPCODE_LSO			= 0x0e,
    MLX5_OPCODE_RDMA_READ		= 0x10,
    MLX5_OPCODE_ATOMIC_CS		= 0x11,
    MLX5_OPCODE_ATOMIC_FA		= 0x12,
    MLX5_OPCODE_ATOMIC_MASKED_CS	= 0x14,
    MLX5_OPCODE_ATOMIC_MASKED_FA	= 0x15,
    MLX5_OPCODE_BIND_MW		= 0x18,
    MLX5_OPCODE_CONFIG_CMD		= 0x1f,
    MLX5_OPCODE_ENHANCED_MPSW	= 0x29,

    MLX5_RECV_OPCODE_RDMA_WRITE_IMM	= 0x00,
    MLX5_RECV_OPCODE_SEND		= 0x01,
    MLX5_RECV_OPCODE_SEND_IMM	= 0x02,
    MLX5_RECV_OPCODE_SEND_INVAL	= 0x03,

    MLX5_CQE_OPCODE_ERROR		= 0x1e,
    MLX5_CQE_OPCODE_RESIZE		= 0x16,

    MLX5_OPCODE_SET_PSV		= 0x20,
    MLX5_OPCODE_GET_PSV		= 0x21,
    MLX5_OPCODE_CHECK_PSV		= 0x22,
    MLX5_OPCODE_DUMP		= 0x23,
    MLX5_OPCODE_RGET_PSV		= 0x26,
    MLX5_OPCODE_RCHECK_PSV		= 0x27,

    MLX5_OPCODE_UMR			= 0x25,

    MLX5_OPCODE_FLOW_TBL_ACCESS	= 0x2c,

    MLX5_OPCODE_ACCESS_ASO		= 0x2d,
};




ndo: struct net_device_ops {


opa_netdev_start_xmit
ndo_start_xmit
.ndo_start_xmit          = mlx5e_xmit
当要更改的队列被禁用时，对 txq2sq 的所有更改都与 mlx5e_xmit 同步执行，并且 smp_wmb 保证在 mlx5e_xmit 尝试从 txq2sq 读取之前更改可见。 它保证当 mlx5e_xmit 在队列号 qid 上运行时 txq2sq[qid] 的值不会更改。 smb_wmb 与 ndo_start_xmit 周围的 HARD_TX_LOCK 配对，用作 ACQUIRE
skb_get_queue_mapping
mlx5e_accel_tx_begin -> net/mlx5e：将 TX 加速卸载分为两个阶段经过之前的修改，卸载不再一一调用，在 TLS 和 IPSEC 卸载之间计算 pi 并清除 wqe，这不太符合 mlx5e_accel_handle_tx 的目的 。 此补丁将 mlx5e_accel_handle_tx 拆分为两个函数，对应于运行卸载的两个逻辑阶段： 1. 在获取 WQE 之前。 这里运行的代码可以在获取主 WQE 之前自行发布 WQE。 它是 TLS 卸载的主要部分。 2. 获取 WQE 后。 这里运行更新 WQE 字段的代码，但无法再发布其他 WQE。 这是 TLS 卸载的一小部分，它在 cseg 中设置 tisn 字段，以及基于 eseg 的卸载（当前是 IPSEC，后续补丁也将 GENEVE 和校验和卸载移到那里）。 它允许 mlx5e_xmit 处理按正确顺序传输数据包所需的所有操作，改进代码结构并减少不必要的操作。 该结构将在后续补丁中得到进一步改进（所有基于 eseg 的卸载将移动到一个位置，并且为主 WQE 保留空间将在卸载的第 1 阶段和第 2 阶段之间进行，以消除不必要的数据移动）。
mlx5e_sq_xmit_prepare
mlx5e_tx_skb_supports_mpwqe -> net/mlx5e：使用 MACsec skb_metadata_dst 实现 MACsec Tx 数据路径 MACsec 驱动程序使用保存 64 位 SCI 编号的专用 skb_metadata_dst 标记用于设备卸载的 Tx 数据包。 先前设置的规则将匹配该号码，因此正确的 SA 用于 MACsec 操作。 由于设备驱动程序只能向流表提供 32 位元数据，因此需要使用从 64 位到 32 位标记或 id 的映射，这可以通过在控制路径中提供 32 位唯一流 id 来实现，并使用 哈希表将 64 位映射到数据路径中的唯一 ID
    mlx5e_txwqe_build_eseg
    mlx5e_sq_xmit_mpwqe -> net/mlx5e：SKB 的增强型 TX MPWQE 此提交添加了对常规 (SKB) 数据路径中的增强型 TX MPWQE 功能的支持。 MPWQE（多数据包工作队列元素）可以服务多个数据包，从而减少控制流量上的 PCI 带宽。 添加了两个新的统计数据（tx*_mpwqe_blks 和 tx*_mpwqe_pkts）。 该功能默认开启，并由 skb_tx_mpwqe 私有标志控制。 在 MPWQE 中，eseg 在所有数据包之间共享，因此基于 eseg 的卸载（IPSEC、GENEVE、校验和）在单独的 eseg 上运行，该 eseg 与当前 MPWQE 会话的 eseg 进行比较，以确定是否可以将新数据包添加到 同一次会议。 MPWQE 与某些卸载和功能不兼容，例如 TLS 卸载、TSO、非线性 SKB。 如果使用此类不兼容的功能，驱动程序会正常回退到非 MPWQE。 此更改对 TCP 单流测试和 XDP_TX 单流测试没有性能影响。
    mlx5e_tx_mpwqe_ensure_complete
mlx5e_sq_calc_wqe_attr
mlx5e_txqsq_get_next_pi -> net/mlx5e：统一为 WQE 保留空间 在我们的快速路径设计中，WQE（工作队列元素）不得跨越页面边界。 为了强制执行这一点，对于由多个 BB（基本块）组成的 WQE，驱动程序会提前检查 WQ 中的可用连续空间，如果不够，则用 NOP 填充。 此补丁修改了计算下一个 WQE 位置的代码，考虑填充，并准备 WQE。 此代码对于所有 SQ 类型都是通用的。 在此补丁中，它进行了重新组织，使所有 SQ 类型的使用模式统一，并使实现独立且看起来几乎相同，准备重复代码以进一步尝试对其进行重复数据删除。 保留一个地方：里面有mlx5e_sq_xmit和mlx5e_fill_sq_frag_edge调用，因为它的特殊之处在于它在保留空间时也可能复制WQE的cseg和eseg。 这将在以下补丁之一中消除，并且该位置也将转换为新方法。
mlx5e_accel_tx_finish
mlx5e_txwqe_build_eseg
mlx5e_sq_xmit_wqe -> send wqe
    ihs -> mlx5：支持 BIG TCP 数据包 mlx5 支持 LSOv2。 IPv6 gro/tcp 堆栈为大数据包插入带有 JUMBO TLV 的临时逐跳标头。 当填充 TX 描述符时，我们需要忽略/跳过这个 HBH 标头。 请注意，ipv6_has_hopopt_jumbo() 仅识别非常具体的数据包布局，因此 mlx5e_sq_xmit_wqe() 仅处理此布局。 v7：采用 unsafe_memcpy() 和 MLX5_UNSAFE_MEMCPY_DISCLAIMER v2：清除 mlx5e_tx_get_gso_ihs() 中的 hopbyhop v4：修复 CONFIG_MLX5_CORE_IPOIB=y 的编译错误
    hopbyhop -> IPv6 BIG TCP 允许网络协议栈准备更大的 GSO（发送）和 GRO（接收）数据包，以减少协议栈的遍历次数，从而提高性能和延迟。它可减少 CPU 负载，有助于实现更高的速度（即 100Gbit/s 及以上）。为了让这些数据包通过协议栈，BIG TCP 在 IPv6 头之后添加了一个临时的 "逐跳"（Hop-By-Hop）头，并在通过线路传输数据包之前将其剥离。BIG TCP 可在双协议栈设置中运行，IPv4 数据包将使用旧的下限（64k），IPv6 数据包将使用新的较大下限（192k）。请注意，Cilium 假定 GSO 和 GRO 的默认内核值为 64k，只有在必要时才会进行调整，也就是说，如果启用了 BIG TCP，而当前的 GSO/GRO 最大值小于 192k，那么 Cilium 会尝试增加这些值；如果禁用了 BIG TCP，而当前的最大值大于 64k，那么 Cilium 会尝试减少这些值。BIG TCP 不需要更改网络接口 MTU
    mlx5e_insert_vlan
    mlx5e_txwqe_build_dsegs -> net/mlx5e：Xmit 流分解 将当前的 mlx5e xmit 流分解为更小的块（辅助函数），以便将它们重新用于 IPoIB SKB 传输
        dma_map_single
        mlx5e_dma_push
        for (i = 0; i < skb_shinfo(skb)->nr_frags; i++)
            mlx5e_dma_push
mlx5e_txwqe_complete -> net/mlx5e：使 tx_port_ts 逻辑能够适应无序 CQE 使用映射结构将包含端口时间戳信息的 CQE 与适当的 skb 相关联。 跟踪使用 FIFO 提交的 WQE 的顺序。 检查 FIFO 中查找值中的相应端口时间戳 CQE 是否被视为由于时间流逝而被丢弃。 使用 skb 后将查找值返回到空闲列表。 在未来的 WQE 提交迭代中重用释放的查找。 Map 结构使用整数标识符作为键，并返回与该标识符对应的 skb。 当 SQ 是 PTP（端口时间戳）SQ 时，将整数标识符嵌入提交给传输路径 WQ 的 WQE 中。 然后可以使用相应端口时间戳CQ的CQE中的字段来查询嵌入的标识符。 在端口时间戳napi_poll上下文中，从CQ轮询的CQE中查询标识符，并用于从WQE提交路径查找相应的skb。 skb 引用从映射中删除，然后嵌入来自 CQE 的端口硬件时间戳信息并最终被消耗。 元数据空闲列表 FIFO 是一个包含整数标识符的数组，可以在 FIFO 中压入和弹出这些整数标识符。 此结构的目的是记录哪些标识符值可以在后续 WQE 提交中安全使用，并且不应包含尚未通过在端口时间戳 CQ 上处理相应 CQE 完成而收获的标识符。 ts_cqe_pending_list 结构是数组和链表的组合。 该数组预先填充了将在链表头部添加和删除的节点。 每个节点都包含与在 WQE 中提交并在端口时间戳 CQE 中检索的值关联的唯一标识符值。 当提交WQE时，数组中与从元数据空闲列表中弹出的标识符相对应的节点被添加到CQE挂起列表的末尾，并被标记为“使用中”。 在两种情况下，节点会从链表中删除。 第一个条件是在 PTP napi_poll 上下文中轮询相应的端口时间戳 CQE。 第二个条件是自 WQE 提交对应的 DMA 时间戳值以来已经过去了一秒以上。 当第一个条件发生时，链表节点中的“使用中”位被清零，然后释放WQE提交对应的资源。 然而，第二个条件表明端口时间戳 CQE 可能永远不会被传递。 设备在无限长的时间后发布 CQE 并非不可能，尽管可能性极小。 为了应对这种不可能的情况，与相应的 WQE 提交相关的资源仍然保留，标识符值不会返回到空闲列表，并且节点上的“正在使用”位被清除以指示它不再 “可能交付”端口时间戳 CQE 标识符链接列表的一部分。 维护被认为极有可能永远不会被设备传送的端口时间戳 CQE 的数量的计数。 如果在 PTP napi_poll 上下文中轮询被认为不太可能交付的端口时间戳 CQE，则此计数会减少。
    mlx5e_tx_skb_update_hwts_flags
    mlx5e_tx_check_stop
    mlx5e_skb_cb_hwtstamp_init -> net/mlx5e：添加 TX 端口时间戳支持 使用来自端口的时间戳（而不是数据包 CQE 创建时间戳）时，可以提高传输数据包时间戳的准确性，因为它可以更好地反映数据包传输的实际时间。 从 ConnectX6-DX 硬件开始支持 TX 端口时间戳。 尽管在原始完成时，只能附加 CQE 时间戳，但我们可以通过与 SQ 关联的特殊 CQ（除了常规 CQ 之外）上的附加完成来获取 TX 端口时间戳。 驱动程序忽略原始数据包完成时间戳，并报告特殊 CQ 完成的时间戳。 如果两次完成之间的绝对时间戳差异大于 1 / 128 秒，请忽略 TX 端口时间戳，因为它的抖动太大。 额外的补全不会生成任何 skb。 为每个 ptpsq 分配额外的 CQ，以接收 TX 端口时间戳。 驱动程序保存 skb FIFO，以便将传输的 skb 映射到两个预期完成。 使用 ptpsq 时，在 skb 上保留双引用计数，以保证在两个完成到达之前它不会被释放。 公开 ptp 附加 CQ 的专用计数器并将其连接到 TX 运行状况报告器。 该补丁将 TX 硬件时间戳偏移改进为在 100Gbps 线路速率下小于 40ns，而之前为 600ns。 这样，我们的硬件就符合 G.8273.2 C 类标准，并允许 Linux 系统部署在 5G 电信边缘，而该标准是必须的。
    mlx5e_ptp_metadata_map_put
    mlx5e_ptpsq_track_metadata -> net/mlx5e：填充元数据映射后跟踪 xmit 提交到 PTP WQ 在跟踪元数据索引以检测未传递的 CQE 之前，确保 skb 在映射到 skb 的元数据中可用。 如果在将 skb 放入映射之前将元数据索引放入跟踪列表中，则元数据索引可能会用于在相关 skb 在映射中可用之前检测未传递的 CQE，这可能导致 null-ptr-deref。
    mlx5e_ptpsq_track_metadata -> net/mlx5e：扩展 SKB 空间检查以包括 PTP-SQ 设置 tx_port_ts 时，驱动程序将 PTP 端口上的所有 UPD 流量转移到专用 PTP-SQ。 SKB 会被缓存，直到有线 CQE 到达。 当数据包大小大于 MTU 时，固件可能会丢弃它，并且数据包不会传输到线路，因此线路 CQE 将无法到达驱动程序。 在这种情况下，SKB 累积在 SKB fifo 中。 添加房间检查以考虑 PTP-SQ SKB fifo，当 SKB fifo 已满时，驱动程序会停止队列，导致 TX 超时。 Devlink TX-reporter 可以从中恢复。
    send_doorbell = __netdev_tx_sent_queue(sq->txq, attr->num_bytes, xmit_more)
        netdev_tx_sent_queue
    mlx5e_notify_hw(wq, sq->pc, sq->uar_map, cseg)
        dma_wmb()
        wmb()
        mlx5_write64((__be32 *)ctrl, uar_map)

then:
mlx5e_poll_tx_cq




send:
dev_queue_xmit

.send		= dev_queue_xmit
    ...
    ndo_start_xmit



struct mlx5e_priv {



net/mlx5e: refactor xmit send function:
一个庞大的函数mlx5e_sq_xmit被拆分成几个来实现多个
目标：
1. 重用IPoIB中的代码。
2. 更好地与 TLS、IPSEC、GENEVE 和校验和卸载集成。 现在可以在运行基于 eseg 的卸载之前在 WQ 中预留空间，因此：
2.1. mlx5e_fill_sq_frag_edge 之后不再需要复制 cseg 和 eseg。
2.2. 将使用 mlx5e_txqsq_get_next_pi 代替旧版 mlx5e_fill_sq_frag_edge，以实现更好的代码可维护性和重用性。
3. 为即将到来的 SKB TX MPWQE 做好准备。 之后就会介入
mlx5e_sq_calc_wqe_attr 检查是否可以使用 MPWQE，以及
代码流将分为两条路径：MPWQE 和非 MPWQE。
提供了两个高级函数来发送数据包：
* mlx5e_xmit 由网络堆栈调用，运行卸载并发送数据包。 在以下补丁之一中，MPWQE 支持将添加到此流程中。
* mlx5e_sq_xmit_simple 由 TLS 卸载调用，仅运行校验和卸载并发送数据包。
此更改对 TCP 单流测试和 XDP_TX 单流测试没有性能影响。
当使用最新的 GCC 编译时，此更改显示不可见
对 UDP pktgen（突发 32）单流测试的性能影响：
数据包速率：16.86 Mpps (±0.15 Mpps) -> 16.95 Mpps (±0.15 Mpps)
每包指令：434 -> 429
每包周期：158 -> 160
每个周期指令数：2.75 -> 2.69
CPU：Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz (x86_64)
网卡：Mellanox ConnectX-6 Dx
gcc 10.2.0

gso:
skb_is_gso
GSO用来扩展之前的TSO，目前已经并入upstream内核。TSO只能支持tcp协议，而GSO可以支持tcpv4, tcpv6, udp等协议


RX Multi-packet WQE, MPWQE:
net/mlx5e：SKB 的增强型 TX MPWQE
此提交添加了对常规 (SKB) 数据路径中的增强型 TX MPWQE 功能的支持。 MPWQE（多数据包工作队列元素）可以服务多个数据包，从而减少控制流量上的 PCI 带宽。



mlx5e_sq_calc_wqe_attr -> net/mlx5e：添加缺少的最大 TX WQE 大小的完整性检查下面引用的提交开始使用最大 TX WQE 大小的固件功能。 此提交添加了一项重要的检查，以验证驱动程序不会尝试超出此功能，并且还恢复在引用的提交中错误删除的另一项检查（WQE 不得超过页面大小）。


struct mlx5e_txqsq


net/mlx5e：避免在配置更改时重置 netdev 统计信息 将所有 RQ、SQ 和通道计数器从通道对象移至 priv 结构中。 通过此更改，计数器将不会在通道配置更改时重置。 与高于零的 TC 关联的 SQ 的通道统计信息将在 ethtool -S 中显示，仅适用于自模块加载以来至少打开一次的 SQ（无论其打开/关闭当前状态如何）。 这样做是为了减少为常见的开箱即用（无 QoS）而呈现和计算的统计总量。 mlx5e_channel_stats 是 CH、RQ、SQ 统计数据的组合，以便在处理同一通道的 TX 和 RX 时为 NAPI 创建局部性。 对齐每个环的新统计结构，以避免多个通道同时更新到同一缓存行。 测试了数据包速率，没有感觉到降级。

mlx5：支持 BIG TCP 数据包 mlx5 支持 LSOv2。 IPv6 gro/tcp 堆栈为大数据包插入带有 JUMBO TLV 的临时逐跳标头。 当填充 TX 描述符时，我们需要忽略/跳过这个 HBH 标头。 请注意，ipv6_has_hopopt_jumbo() 仅识别非常具体的数据包布局，因此 mlx5e_sq_xmit_wqe() 仅处理此布局。 v7：采用 unsafe_memcpy() 和 MLX5_UNSAFE_MEMCPY_DISCLAIMER v2：清除 mlx5e_tx_get_gso_ihs() 中的 hopbyhop v4：修复 CONFIG_MLX5_CORE_IPOIB=y 的编译错误

skb send/receive:
TX 方向
用户态应用程序基于socket系统调用接口，传送需要TX 的HTTP应用层数据（如 Ngnix产生）
内核态socket 层读取用户态数据，并按照应用层的协议类型，将数据发送到对应的传输层（如HTTP对应TCP）
传输层申请 skb 数据结构，并填充数据到skb，然后skb 会向下传送到网络层和链路层（链路层在内核对应网络设备层），继续添加 IP 和 MAC header到skb中
最后skb 到达网络设备驱动，其从skb 中获取到packet data 数据的虚拟地址（skb->data)，并映射出dma总线地址给 网卡进行DMA读取（如对虚拟地址和总线地址有疑问，请参考另一篇文章“一文读懂 内存DMA 及 设备内存控制”）
RX 方向
如高速网卡收到从光纤上传入的数据包后，基于网卡内DMA控制器 和 PCIe 总线，将数据包送入设备驱动层
设备驱动（Device Driver）收到数据包后，申请SKB，并将数据放入SKB 结构指向的数据空间（位于 skb结构 的head 和 end 指针之间）注：驱动放数据到skb 有两种方式，一种方式是dev_alloc_skb + memcpy；第二种是 page + build_skb 实现零拷贝，效率更高
驱动调用 NAPI Schedule 将RX数据送入TCP/IP Stack, 到达 IP 层则去除 SKB 指向数据的 IP Header，到达TCP 层去除 TCP Head
最后在内核基于IP等路由信息，查找到对应的socket，将数据基于socket 送入用户态应用程序



static inline struct sk_buff *dev_alloc_skb(unsigned int length)



send complete:
mlx5e_napi_poll
    mlx5e_poll_tx_cq
        mlx5_cqwq_get_cqe
        ...
        mlx5e_txqsq_wake
            mlx5_cqwq_update_db_record
                *wq->db = cpu_to_be32(wq->cc & 0xffffff)
            netif_tx_wake_queue



IB/mlx5：实现分段完成队列（CQ）
目前create CQ的实现需要连续的内存，这样的要求是有问题的，一旦内存碎片或者系统内存不足，就会导致dma_zalloc_coherent()失败。
该补丁实现了分段 CQ 的新方案，通过引入新类型“struct mlx5_frag_buf_ctrl”来分配分段缓冲区（而不是连续缓冲区）来克服此问题。 完成队列（CQ）基于这个新的分段缓冲区。
它修复了以下崩溃：
kworker/29:0：页面分配失败：顺序：6，模式：0x80d0
CPU：29 PID：8374 通讯：kworker/29:0 受污染：G OE 3.10.0
工作队列：ib_cm cm_work_handler [ib_cm]
调用轨迹：
[<>] 转储堆栈+0x19/0x1b
[<>] warn_alloc_failed+0x110/0x180
[<>] __alloc_pages_slowpath+0x6b7/0x725
[<>] __alloc_pages_nodemask+0x405/0x420
[<>] dma_generic_alloc_coherent+0x8f/0x140
[<>] x86_swiotlb_alloc_coherent+0x21/0x50
[<>] mlx5_dma_zalloc_coherent_node+0xad/0x110 [mlx5_core]
[<>]？ mlx5_db_alloc_node+0x69/0x1b0 [mlx5_core]
[<>] mlx5_buf_alloc_node+0x3e/0xa0 [mlx5_core]
[<>] mlx5_buf_alloc+0x14/0x20 [mlx5_core]
[<>] create_cq_kernel+0x90/0x1f0 [mlx5_ib]
[<>] mlx5_ib_create_cq+0x3b0/0x4e0 [mlx5_ib]


我们说过，Linux在硬中断里只完成简单必要的工作，剩下的大部分的处理都是转交给软中断的。通过上面代码可以看到，硬中断处理过程真的是非常短。只是记录了一个寄存器，修改了一下下CPU的poll_list，然后发出个软中断。就这么简单，硬中断工作就算是完成了
trigger soft_irq:
__raise_softirq_irqoff
or_softirq_pending(1UL << nr)
...
deal_with irq:
static void run_ksoftirqd(unsigned int cpu)
{
    local_irq_disable();
    if (local_softirq_pending()) {
        __do_softirq();
        rcu_note_context_switch(cpu);
        local_irq_enable();
        cond_resched();
        return;
    }
    local_irq_enable();
}

net_rx_action



# LKMM 相关术语的简要定义

# 参考

tools/memory-model/Documentation/glossary.txt

tools/memory-model/Documentation/explanation.txt
ib_drain_qp 排空队列


rdma driver:
mlx5_ifc.h

e1000
e1000_hw.h
static int __init e1000_init_module(void)
drivers/net/ethernet/intel/e1000/e1000_main.c

struct net_device_ops e1000_netdev_ops 

ndo_start_xmit e1000_xmit_frame

现在的中断驱动程序都采用的是NAPI方式，需要提供poll函数，本驱动中是e1000_netpoll轮询函数
当有新数据包要发送时候，首先上层协议调用e1000_xmit_frame函数，然后在该函数中调用e1000_tx_queue来根据相应的参数找到缓冲块存放，缓冲块中有dma成员，表示该数据包所在的总线地址，控制总线会把内容映射到总线地址，然后由网卡传送出去。

当有新数据包达到时，首先触动中断处理函数e1000_intr，该中断函数会将数据包放在buffer_info的缓冲块中()，就是讲总线地址指向的内容复制到skb中，然后根据skb中的协议将其传给上层协议的接收函数

netif_napi_add(netdev, &adapter->napi, e1000e_poll);


drivers/net/ethernet/intel/


kernel source code:
https://elixir.bootlin.com/linux/v6.8-rc1/source/drivers/net/ethernet/intel/e1000/e1000_main.c


mlx5 driver:
drivers/net/ethernet/mellanox/mlx5/core/main.c
module_init(mlx5_init); -> net: mlx5: 消除匿名 module_init 和 module_exit ，消除匿名 module_init() 和 module_exit()，这可能会在读取 System.map、崩溃/oops/bug 或 initcall_debug 日志时导致混乱或歧义
get_random_bytes -> void get_random_bytes -> 这将返回任意数量的随机字节。 随机字节的质量与 /dev/urandom 一样好。 为了确保该函数提供的随机性良好，应调用函数 wait_for_random_bytes() 并在之前的任何时刻至少返回一次 0
static u32 sw_owner_id[4] -> net/mlx5：在 init HCA 期间设置软件所有者 ID，为每个主机生成唯一的 128 位标识符，并在 INIT_HCA 命令中将该值传递给固件（如果报告了 sw_owner_id 功能）。 绑定到 mlx5_core 驱动程序的每个设备都将具有相同的软件所有者 ID。 在后续补丁中，mlx5_core 设备将通过新的 VPort 命令进行绑定，以便它们可以在单个 InfiniBand 设备下一起运行。 只能绑定具有相同软件所有者 ID 的设备，以防止发往一台主机的流量到达另一台主机。 INIT_HCA 命令长度扩展了 128 位。 命令长度作为输入 FW 命令提供。 较旧的固件以新的较长形式接收此命令没有问题
mlx5_core_verify_params -> net/mlx5：验证模块参数 验证 mlx5_core 模块参数，确保它们在预期范围内，如果未将其恢复为默认值。
    profile -> static struct mlx5_profile profile[] -> 默认配置文件 -> mlx5：将 pci 设备处理从 mlx5_ib 移至 mlx5_core 在为 VPI 的新 mlx5 设备（即端口可以是 IB 或 ETH）做准备时，请将 pci 设备功能从 mlx5_ib 移至 mlx5_core。 这涉及以下更改： 1. 将 mlx5_core_dev 结构移出 mlx5_ib_dev。 mlx5_core_dev 现在是由 mlx5_core 维护的独立结构。 mlx5_ib_dev 现在有一个指向该结构的指针。 这需要更改通过 mlx5_ib_dev 访问 core_dev 结构的很多地方（现在，这需要是指针取消引用）。 2. 所有 PCI 初始化现在都在 mlx5_core 中完成。 因此，现在是 mlx5_core 执行 pci_register_device （而不是像以前那样的 mlx5_ib）。 3. mlx5_ib 现在将自身注册为 mlx5_core 作为“接口”驱动程序。 这与 mlx4 (ConnectX) 驱动程序采用的机制非常相似。 一旦 HCA 初始化（由 mlx5_core），它就会调用接口驱动程序来进行初始化。 4. 核心注册了一个新的事件处理程序：mlx5_core_event()。 该事件处理程序调用接口注册的事件处理程序
    {net，RDMA}/mlx5：修复其他设备对 log_max_qp 的覆盖，mlx5_core_dev 保存指向静态配置文件的指针，因此当配置文件的 log_max_qp 被某些设备覆盖时，它会影响共享相同配置文件的所有其他 mlx5 设备。 通过为每个 mlx5 设备提供一个配置文件实例来修复此问题
    index为3的配置文件是, net/mlx5：为 SF 创建新的配置文件，为 SF 创建新的配置文件以禁用命令缓存。 每个功能命令缓存消耗约 500KB 的内存，当使用大量 SF 时，这种节省在内存受限的系统上非常显着。 使用新的配置文件来提供 SF 和 PF 之间未来的差异。 mr_cache 不用于非 PF 函数，因此从新配置文件中排除
mlx5_register_debugfs
    mlx5_debugfs_root = debugfs_create_dir("mlx5", NULL) -> 第一个参数是目录的名称，第二个参数用来指定这个目录的上级目录，如果是NULL，则表示是放在debugfs的根目录里,  /sys/kernel/debug/
mlx5e_init -> net/mlx5e：将以太网部分连接到辅助总线，重用辅助总线对mlx5驱动程序的以太网部分进行设备管理 -> 目前，删除和重新加载流程可以与模块清理并行运行。 这种设计很容易出错。 例如：从具有不同锁定的清理和删除流中调用 aux_drivers 回调，这可能会导致死锁[1]。 因此，通过重新加载和删除来序列化模块清理
    mlx5e_build_ptys2ethtool_map -> net/mlx5e：使用新的 ethtool 获取/设置链接 ksettings API，使用新的获取/设置链接 ksettings 并删除获取/设置设置旧回调。 这允许我们为支持和通告的链接模式使用超过 32 位的位掩码，并使用以前不支持的模式
        __ETHTOOL_DECLARE_LINK_MODE_MASK
            DECLARE_BITMAP(name, __ETHTOOL_LINK_MODE_MASK_NBITS) -> 定义一个位图变量，本质就是一个unsigned long类型的数组, 宏的参数：name是变量名，bits是位图有多少个位
        MLX5_BUILD_PTYS2ETHTOOL_CONFIG
        ...
    auxiliary_driver_register(&mlx5e_driver) -> __auxiliary_driver_register
    mlx5e_rep_init -> net/mlx5e：首先取消注册 eth-reps 设备 当我们清理所有接口（即重新扫描或重新加载模块）时，我们需要先清理 eth-reps 设备，然后再清理 eth 设备。 我们将重新使用本机 NIC 端口网络设备实例作为上行链路表示器。 更改 eswitch 模式将跳过销毁 eth 设备，因此网络设备不会被销毁，而只会更改配置文件。 创建上行eth-rep将初始化representor相关资源。 从这个意义上说，当我们销毁所有设备时，我们首先需要销毁 eth-rep 设备，因此上行链路 eth-rep 将清除所有与表示器相关的资源，然后才销毁 eth 设备，这将销毁其余资源和网络设备
        auxiliary_driver_register(&mlx5e_rep_driver)
mlx5_sf_driver_register -> static struct auxiliary_driver
    auxiliary_driver_register(&mlx5_sf_driver)
pci_register_driver(&mlx5_core_driver)


static struct auxiliary_driver mlx5e_rep_driver = {
    .name = "eth-rep",
    .probe = mlx5e_rep_probe,
    .remove = mlx5e_rep_remove,
    .id_table = mlx5e_rep_id_table,
};


mlx5e_rep_probe
    mlx5_eswitch_register_vport_reps(esw, &rep_ops, REP_ETH) -> net/mlx5：E-Switch，将代表 reg/unreg 集中到 eswitch 驱动程序，Eswitch 有两个用户：IB 和 ETH。 它们都在添加 mlx5 接口时注册代表器，并在删除 mlx5 接口时取消注册代表器。 理想情况下，每个驱动程序应该只处理其独有的实体。 但是，当前的 IB 和 ETH 驱动程序必须执行以下 eswitch 操作： 1. 注册时，指定要注册的 vport 数量。 对于两个驱动程序来说，这个数字是相同的，即可用 vport 总数。 2. 取消注册时，指定要取消注册的已注册 vport 的数量。 另外，卸载已经加载的代表器。 eswitch 驱动程序没有必要将上述操作的控制权交给各个驱动程序用户，因为它们对于每个驱动程序来说并不是唯一的。 相反，此类操作应集中到 eswitch 驱动程序。 这整合了 eswitch 控制流程，并简化了 IB 和 ETH 驱动程序
        mlx5_esw_for_each_rep
            atomic_set(&rep_data->state, REP_REGISTERED

辅助设备驱动
static struct auxiliary_driver mlx5e_driver = {
    .name = "eth",
    .probe = mlx5e_probe,
    .remove = mlx5e_remove,
    .suspend = mlx5e_suspend,
    .resume = mlx5e_resume,
    .id_table = mlx5e_id_table,
};

mlx5e_probe -> static int _mlx5e_probe
    const struct mlx5e_profile *profile = &mlx5e_nic_profile
    mlx5e_dev = mlx5e_create_devlink(&adev->dev, mdev)
        devlink_alloc_ns
        devl_nested_devlink_set -> net/mlx5e：将辅助 devlink 实例设置为嵌套，受益于之前引入 devlink 实例关系公开的提交，并为辅助设备设置嵌套实例 -> 嵌套的 devlink 信息通过 devlink netlink 的对象特定属性暴露给用户空间 -> https://docs.kernel.org/networking/devlink/
        devlink_register
    auxiliary_set_drvdata
    mlx5e_devlink_port_register -> net/mlx5e：使用交换机 ID 注册 nic devlink 端口，我们将重新使用本机 NIC 端口网络设备实例作为上行链路表示器。 由于当我们使用 switchdev 模式时，netdev 将保持注册状态，因此 devlink 也将保持注册状态。 使用交换机 ID 注册 nic devlink 端口，以便在更改配置文件时可用
        mlx5_esw_vport_to_devlink_port_index
        devlink_port_attrs_set -> 扩展 devlink_port_attrs_set() 以传递属于交换机一部分的端口的交换机 ID，并将其存储在端口 attrs 中。 对于其他端口，该值为 NULL。 请注意，这允许驱动程序根据实际拓扑将 devlink 端口分组到一个或多个交换机中
        devlink_port_register -> devlink-port是设备上存在的端口。它具有逻辑上独立的设备入口/出口点。 devlink 端口可以是多种风格中的任何一种。 devlink 端口风格和端口属性描述了端口代表的内容。  打算发布 devlink 端口的设备驱动程序设置 devlink 端口属性并注册 devlink 端口, https://docs.kernel.org/networking/devlink/devlink-port.html
    mlx5e_create_netdev -> net/mlx5e：添加 PTP 和 QOS HTB 功能的配置文件指示，让配置文件指示支持 PTP 和 HTB (QOS) 功能。 这统一了计算功能所需的 netdev 队列数量的逻辑，并允许简化 mlx5e_create_netdev()，不再需要 rx/tx 队列数量作为参数
        mlx5e_get_max_num_txqs -> net/mlx5e：允许对最大通道数进行特定于配置文件的限制，让 SF/VF 表示器的 netdev 对 max_nch 使用特定于配置文件的限制，以减少其内存和硬件资源消耗。 这对于内存有限和 SF 数量较多的环境尤其重要
            mlx5e_profile_max_num_channels
                max_nch_limit
        mlx5e_get_max_num_rxqs
        alloc_etherdev_mqs -> 分配并设置以太网设备 @sizeof_priv：要为此以太网设备分配的附加驱动程序私有结构的大小 @txqs：该设备具有的 TX 队列数。 @rxqs：该设备拥有的 RX 队列数。 使用以太网通用值填充设备结构的字段。 基本上可以完成除注册设备之外的所有操作。 构造一个新的网络设备，并包含大小为 (sizeof_priv) 的私有数据区域。 此私有数据区域强制执行 32 字节（而非位）对齐 -> net/mlx5e：netdev 对象和 mlx5e 配置文件初始化之间分开，1) 在 netdevice 分配上和 mlx5e 配置文件外部初始化 netdevice 功能和结构。 2) 由于现在只有在设置了 netdevice 功能之后才会在配置文件 init 上设置 mlx5e netdevice 私有参数，因此我们添加对 netde_update_features() 的调用来解决任何冲突。 这很好，因为如果配置文件需要不同的默认功能，我们会重用 fix_features ndo 代码，而不是在配置文件初始化时重复功能冲突解决代码。 3) 这样，我们就实现了 mlx5e 配置文件和网络设备之间的完全分离，并且允许动态替换 mlx5e 配置文件，以便为多个配置文件重复使用相同的网络设备。 例如 对于上行链路表示器配置文件，如以下补丁所示 4) 配置文件回调不再允许直接触及 netdev->features，因为在下游补丁中，我们将动态分离/附加 netdev 到配置文件，因此我们移动处理 netdev-> 的代码 从 profile->init() 到 fix_features ndo 的功能，我们将在 mlx5e_attach_netdev(profile, netdev) 上调用 netdev_update_features()；
        mlx5e_priv_init -> net/mlx5e：保持最大通道数的值同步，最大通道数的值首先根据 netdev 的配置文件和当前函数资源（具体来说，MSIX 向量的数量，这取决于其他因素）计算 系统中在线核心的数量）。 然后使用该值来计算 netdev 的 rxqs/txqs 数量。 一旦创建（通过 alloc_etherdev_mqs ），netdev 的 rxqs/txqs 数量是恒定的，我们不能超过它。 为了实现这一点，请在任何网络设备重新连接时保持最大数量的通道同步。 使用 mlx5e_get_max_num_channels() 计算 netdev 的 rxqs/txqs 数量。 创建 netdev 后，使用 mlx5e_calc_max_nch()（它创建核心设备资源、配置文件和 netdev）来初始化或更新 priv->max_nch。 在此补丁之前，priv->max_nch 的值可能会不同步，从而错误地允许访问越界对象，从而导致系统崩溃。 跟踪在单独字段中使用的通道统计结构的数量，因为它们持续挂起/恢复操作。 应保留曾经存在的每个通道索引的所有收集的统计数据。 仅当 struct mlx5e_priv 在 mlx5e_priv_cleanup()（配置文件更改流程的一部分）中时，它们才会重置。 由于 mlx5e_netdev_change_profile() 中的 max_nch 不匹配，阻止配置文件更改已没有任何意义。 解除限制
            mlx5e_calc_max_nch -> net/mlx5e：通过在 netdev priv 中使用动态分配来节省内存，priv 中的许多数组都是使用预定义的最大值（对于 num 个通道、num TC 等）进行静态分配，在某些情况下明显大于 实际最大值。 示例： - 支持的 VF 越多，每个 VF 可以拥有的 MSIX 向量就越少。 这限制了每个的 max_nch 。 - 内核或 MSIX 数量有限 (< 64) 的系统。 - 不支持的 Netdev 配置文件：QoS (DCB / HTB)、PTP TX 端口时间戳。 在这里，我们通过移动几个结构和数组来遵循实际的最大值来节省一些内存。 此补丁还准备了代码，以实现更多节省。 例如，在最大通道数为 8 的系统上，仅通道统计结构就会从每个接口的 3648*64 = 228 KB 下降到 3648*8 = 28.5 KB。 这对于具有大量 VF/SF 或内存有限的环境非常重要
            alloc_cpumask_var -> cpuset子系统为cgroup 中的任务分配独立 CPU（在多核系统）和内存节点。Cpuset子系统为定义了一个叫cpuset的数据结构来管理cgroup中的任务能够使用的cpu和内存节点 -> net/mlx5e：修复了极端情况下 XPS cpumask 和 netdev 队列的配置，目前，mlx5e 会通知内核有关队列数量的信息，并在激活通道时设置默认 XPS cpumask。 此实现有几个极端情况，其中内核可能无法按时更新，或者 XPS cpumasks 可能在用户未直接接触时重置。 此提交修复了这些极端情况，以匹配以下预期行为： 1. 队列数量始终与配置的通道数量相对应。 2. XPS cpumasks 在 netdev Attach 上设置为驱动程序的默认值。 3. 用户设置的 XPS cpumasks 不会重置，除非通道数发生变化。 如果通道数量发生变化，它们将重置为驱动程序的默认值。 （一般情况下，当通道数增加或减少时，不可能猜测如何转换当前的 XPS cpumasks 以适应新的通道数，因此如果用户更改通道数，我们让用户重新配置它。 ) XPS cpumask 不再按通道存储。 仅使用一个临时 cpumask。 旧的存储的 cpumasks 没有反映用户的更改，并且在应用它们后没有被使用。 结构体 mlx5e_priv 中添加了暂存器区域。 由于 cpumask_var_t 需要分配，并且 preactivate hook 不能失败，因此我们需要提前预分配临时 cpumask。 它存储在暂存器中
            mlx5e_selq_init -> net/mlx5e：引入select队列参数，ndo_select_queue可以随时调用，并且没有办法阻止内核调用它来同步配置更改（real_num_tx_queues、num_tc）。 此提交引入了 mlx5e 中的一种内部方法，用于将 mlx5e_select_queue() 与这些更改同步。 该函数所需的配置存储在 struct mlx5e_selq_params 中，可以使用 RCU 方法以原子方式修改和访问该结构。 整个 ndo_select_queue 在 RCU 锁下调用，提供必要的保证。 存储在新结构 mlx5e_selq_params 中的参数只能在 mlx5e_select_queue 内部使用。 这是 mlx5e_select_queue 有效完成其工作所需的最小参数集，源自存储在其他地方的参数。 这意味着当配置更改时，mlx5e_selq_params 可能需要更新。 在这种情况下，应使用 mlx5e_selq_prepare/mlx5e_selq_apply API。 struct mlx5e_selq 包含两个参数槽：活动和备用。 mlx5e_selq_prepare 更新备用插槽，mlx5e_selq_apply 使用 RCU API 以安全原子方式交换插槽。 它与配置更改流程的打开/激活阶段很好地集成
                rcu_assign_pointer
            INIT_WORK(&priv->update_carrier_work, mlx5e_update_carrier_work);
            INIT_WORK(&priv->set_rx_mode_work, mlx5e_set_rx_mode_work);
            INIT_WORK(&priv->tx_timeout_work, mlx5e_tx_timeout_work);
            INIT_WORK(&priv->update_stats_work, mlx5e_update_stats_work);
            priv->wq = create_singlethread_workqueue("mlx5e")
        netif_carrier_off -> 网络适配器硬件电路可以检测出链路上是否有载波，载波反映了网络的连接是否正常。网络设备驱动可以通过 netif_carrier_on() 和 netif_carrier_off() 函数改变设备的连接状态，如果驱动检测到连接状态发生变化，也应该以 netif_carrier_on() 和 netif_carrier_off() 函数显式地通知内核
        netif_tx_disable
        dev_net_set
    mlx5e_build_nic_netdev
        netdev->netdev_ops = &mlx5e_netdev_ops
        netdev->xdp_metadata_ops = &mlx5e_xdp_metadata_ops
        netdev->xsk_tx_metadata_ops = &mlx5e_xsk_tx_metadata_ops
        mlx5e_dcbnl_build_netdev(netdev)
            netdev->dcbnl_ops = &mlx5e_dcbnl_ops
        netdev->watchdog_timeo    = 15 * HZ
        netdev->ethtool_ops	  = &mlx5e_ethtool_ops
        mlx5_query_port_fcs(mdev, &fcs_supported, &fcs_enabled)
            mlx5_query_ports_check
                mlx5_core_access_reg MLX5_REG_PCMR
    profile->init(mdev, netdev) -> mlx5e_nic_init
    mlx5e_resume
        mlx5e_create_mdev_resources
            mlx5_core_alloc_pd(mdev, &res->pdn) -> net/mlx5e：仅创建 NIC 全局资源一次，为了允许在同一 PCI 功能上创建多个 netdev，我们更改了驱动程序，以便全局 NIC 资源创建一次，然后在该端口上运行的所有 mlx5e netdev 之间共享。 将 CQ UAR、PD (pdn)、传输域 (tdn)、MKey 资源从保留在 mlx5e priv 部分中移动到放置在 mlx5_core 设备下的新资源结构 (mlx5e_resources)。 该补丁没有添加任何新功能
                mlx5_cmd_exec_inout MLX5_CMD_OP_ALLOC_PD
            mlx5_core_alloc_transport_domain(mdev, &res->td.tdn) -> MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN
            mlx5e_create_mkey -> net/mlx5e：暴露内存密钥创建（mkey）函数，暴露mlx5e_create_mkey函数，以供将来的macsec系列补丁使用。 上述函数创建一个内存密钥，它描述了内存中的一个区域，以后可以由硬件和软件使用。 对应的销毁功能已经公开
                mlx5_core_create_mkey -> MLX5_CMD_OP_CREATE_MKEY
            mlx5_alloc_bfreg -> net/mlx5e：适用于所有 mlx5e SQ 和 netdev 的单个 bfreg (UAR)，一个就足够了，因为不再支持 Blue Flame。 这对于 switchdev 模式来节省资源也很有用，因为 VF 表示器也将使用相同的单个 UAR 来用于它们自己的 SQ -> net/mlx5：引入蓝焰寄存器分配器，这里是分配蓝焰寄存器的分配器的实现。 蓝色火焰寄存器用于生成发送门铃。 蓝焰寄存器可用于生成常规门铃或蓝焰门铃，其中要发送的数据被写入设备的 I/O 存储器，从而节省了从存储器读取数据的需要。 为了让蓝焰门铃成功，蓝焰寄存器需要映射为写组合。 用户可以指定她希望使用哪种发送门铃。 如果她请求写入组合映射但失败，则分配器将回退到非写入组合映射并向用户指示这一点。 本系列的后续补丁将使用此分配器 -> commit: https://github.com/ssbandjl/linux/commit/a6d51b68611e98f05042ada662aed5dbe3279c1e
                alloc_bfreg(mdev, bfreg, map_wc, fast_path)
                    up = alloc_uars_page(mdev, map_wc)
                        bfregs = uars_per_sys_page(mdev) * MLX5_BFREGS_PER_UAR
                        up->reg_bitmap = bitmap_zalloc_node(bfregs, GFP_KERNEL, node)
                        mlx5_cmd_alloc_uar -> MLX5_CMD_OP_ALLOC_UAR
                        pfn = uar2pfn(mdev, up->index)
                        up->map = ioremap_wc(pfn << PAGE_SHIFT, PAGE_SIZE)
                        or up->map = ioremap(pfn << PAGE_SHIFT, PAGE_SIZE)
            mlx5e_create_tises -> net/mlx5：将 TIS 从 priv 移动到 mdev 硬件资源，传输接口发送 (TIS) 对象负责执行传输侧的所有传输相关操作。 来自发送队列的消息由 TIS 进行分段和传输，包括所有传输所需的含义，例如 在大量发送卸载的情况下，TIS 负责分段。 这些是无状态对象，可以由共享同一核心设备的多个网络开发人员（例如代表者）使用。 将 TIS 作为从核心层到 netdev 层的服务提供可减少重复的 TIS 对象数量（在多个 netdev 的情况下），并且将简化向具有多个 mdev 的 netdev 的过渡
                mlx5_lag_should_assign_affinity
                mlx5e_create_tis
                    mlx5_core_create_tis -> MLX5_CMD_OP_CREATE_TIS -> net/mlx5：以太网资源处理文件，此补丁包含资源处理文件： - flow_table.c：此文件包含处理低级 API 以配置硬件流表的代码。 它与 flow_table_en.c 分开，因为将来 mlx5_ib 中的原始以太网 QP 也会使用它。 - en_flow_table.[ch]：以太网流控制处理。 流表对象包含流规范和 TIR 之间的映射。 将来当添加 SR-IOV 支持时，该机制还将用于配置 e-switch。 - transobj.[ch] - 用于创建/修改/销毁传输对象的低级函数：RQ/SQ/TIR/TIS - vport.[ch] - 处理嵌入式交换机中虚拟端口 (vPort) 的属性。 目前此交换机是直通交换机，直到添加 SR-IOV 支持
            mlx5_crypto_dek_init
                mlx5_crypto_cmd_sync_crypto -> MLX5_CMD_OP_SYNC_CRYPTO
        mlx5e_attach_netdev
            mlx5e_calc_max_nch
            profile->init_tx(priv)
            profile->init_rx(priv)
            profile->enable(priv)
            mlx5e_update_features(priv->netdev)
                netdev_update_features(netdev) -> 重新计算设备功能
    register_netdev
    mlx5e_dcbnl_init_app
    mlx5_core_uplink_netdev_set -> net/mlx5e：在上行链路 netdev 更改时传播内部事件，每当设置/清除上行链路 netdev 时，传播新引入的事件以通知通知程序块 netdev 已添加/删除。 将 set() 帮助器从标头移至 core.c，引入clear() 和 netdev_added_event_replay() 帮助器。 最后一个将从 rdma 驱动程序调用，因此将其导出
        mlx5_blocking_notifier_call_chain MLX5_DRIVER_EVENT_UPLINK_NETDEV -> net/mlx5：通过阻塞事件通知陷阱操作，为了允许 mlx5 核心驱动程序向其使用者触发同步操作，请添加阻塞事件处理程序。 将包装器添加到blocking_notifier_[call_chain/chain_register/chain_unregister]。 为操作集添加陷阱回调并通知此更改。 该集中的以下补丁添加了此事件的侦听器
            blocking_notifier_call_chain
    mlx5e_params_print_info -> net/mlx5e：将 params 内核日志打印移至探针函数，Params 信息打印本应在加载时打印。 随着时间的推移，添加了对 mlx5e_init_rq_type_params 和 mlx5e_build_rq_params 的新调用，再次错误地打印了参数。 将打印内容移至其所属位置，在 mlx5e_probe 中


static const struct mlx5e_profile mlx5e_nic_profile = {
    .init		   = mlx5e_nic_init,
    .cleanup	   = mlx5e_nic_cleanup,
    .init_rx	   = mlx5e_init_nic_rx,
    .cleanup_rx	   = mlx5e_cleanup_nic_rx,
    .init_tx	   = mlx5e_init_nic_tx,
    .cleanup_tx	   = mlx5e_cleanup_nic_tx,
    .enable		   = mlx5e_nic_enable,
    .disable	   = mlx5e_nic_disable,
    .update_rx	   = mlx5e_update_nic_rx,
    .update_stats	   = mlx5e_stats_update_ndo_stats,
    .update_carrier	   = mlx5e_update_carrier,
    .rx_handlers       = &mlx5e_rx_handlers_nic,
    .max_tc		   = MLX5_MAX_NUM_TC,
    .stats_grps	   = mlx5e_nic_stats_grps,
    .stats_grps_num	   = mlx5e_nic_stats_grps_num,
    .features          = BIT(MLX5E_PROFILE_FEATURE_PTP_RX) |
        BIT(MLX5E_PROFILE_FEATURE_PTP_TX) |
        BIT(MLX5E_PROFILE_FEATURE_QOS_HTB) |
        BIT(MLX5E_PROFILE_FEATURE_FS_VLAN) |
        BIT(MLX5E_PROFILE_FEATURE_FS_TC),
};









git remote add origin git@gitlab.nsv6.b122.top:bin/linux_kernel.git


register_chrdev

pci_enable_device

filter: ./drivers/net/ethernet/intel/


get info:
System with RoCE SR-IOV card with 4 VFs:
[leonro@vm ~]$ lspci |grep nox
01:00.0 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6]
01:00.1 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.2 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.3 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.4 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
[leonro@vm ~]$ ls -l /sys/bus/auxiliary/devices/
mlx5_core.eth.0 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.0/mlx5_core.eth.0
mlx5_core.eth.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.eth.1
mlx5_core.eth.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.eth.2
mlx5_core.eth.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.eth.3
mlx5_core.eth.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.eth.4
mlx5_core.rdma.0 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.0/mlx5_core.rdma.0
mlx5_core.rdma.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.rdma.1
mlx5_core.rdma.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.rdma.2
mlx5_core.rdma.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.rdma.3
mlx5_core.rdma.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.rdma.4
mlx5_core.vdpa.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.vdpa.1
mlx5_core.vdpa.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.vdpa.2
mlx5_core.vdpa.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.vdpa.3
mlx5_core.vdpa.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.vdpa.4
[leonro@vm ~]$ rdma dev
0: rocep1s0f0: node_type ca fw 4.6.9999 node_guid 5254:00c0:fe12:3455 sys_image_guid 5254:00c0:fe12:3455
1: rocep1s0f0v0: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3456
2: rocep1s0f0v1: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3457
3: rocep1s0f0v2: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3458
4: rocep1s0f0v3: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3459



static const struct mlx5_adev_device {
    const char *suffix;
    bool (*is_supported)(struct mlx5_core_dev *dev);
    bool (*is_enabled)(struct mlx5_core_dev *dev);
} mlx5_adev_devices[] = {
    [MLX5_INTERFACE_PROTOCOL_VNET] = { .suffix = "vnet",
                       .is_supported = &mlx5_vnet_supported,
                       .is_enabled = &is_vnet_enabled },
    [MLX5_INTERFACE_PROTOCOL_IB] = { .suffix = "rdma",
                     .is_supported = &mlx5_rdma_supported,
                     .is_enabled = &is_ib_enabled },
    [MLX5_INTERFACE_PROTOCOL_ETH] = { .suffix = "eth",
                      .is_supported = &mlx5_eth_supported,
                      .is_enabled = &mlx5_core_is_eth_enabled },
    [MLX5_INTERFACE_PROTOCOL_ETH_REP] = { .suffix = "eth-rep",
                       .is_supported = &is_eth_rep_supported },
    [MLX5_INTERFACE_PROTOCOL_IB_REP] = { .suffix = "rdma-rep",
                       .is_supported = &is_ib_rep_supported },
    [MLX5_INTERFACE_PROTOCOL_MPIB] = { .suffix = "multiport",
                       .is_supported = &is_mp_supported },
    [MLX5_INTERFACE_PROTOCOL_DPLL] = { .suffix = "dpll",
                       .is_supported = &is_dpll_supported },
};


capability types:
static const int types[] = {
    MLX5_CAP_GENERAL,
    MLX5_CAP_GENERAL_2,
    MLX5_CAP_ETHERNET_OFFLOADS,
    MLX5_CAP_IPOIB_ENHANCED_OFFLOADS,
    MLX5_CAP_ODP,
    MLX5_CAP_ATOMIC,
    MLX5_CAP_ROCE,
    MLX5_CAP_IPOIB_OFFLOADS,
    MLX5_CAP_FLOW_TABLE,
    MLX5_CAP_ESWITCH_FLOW_TABLE,
    MLX5_CAP_ESWITCH,
    MLX5_CAP_QOS,
    MLX5_CAP_DEBUG,
    MLX5_CAP_DEV_MEM,
    MLX5_CAP_DEV_EVENT,
    MLX5_CAP_TLS,
    MLX5_CAP_VDPA_EMULATION,
    MLX5_CAP_IPSEC,
    MLX5_CAP_PORT_SELECTION,
    MLX5_CAP_MACSEC,
    MLX5_CAP_ADV_VIRTUALIZATION,
    MLX5_CAP_CRYPTO,
};



module_init(mlx5_dpll_init); -> mlx5：使用 DPLL 基础设施实现 SyncE 支持 使用新引入的 DPLL 支持实现 SyncE 支持。 确保使用适当功能探测的每个 PF/VF/SF 将生成 dpll 辅助设备并注册适当的 dpll 设备和引脚实例



该产品组合包括符合 ITU-T/IEEE 标准的数字锁相环 (DPLL)，用于网络同步，其性能满足 SyncE 和 IEEE 1588 严格的 10G/40G/100G 接口要求。


mlx5_tout_init


The defaults of the enable_* devlink params of these SFs are set to
false.

Usage example:
Create SF:
$ devlink port add pci/0000:08:00.0 flavour pcisf pfnum 0 sfnum 11
$ devlink port function set pci/0000:08:00.0/32768 \
hw_addr 00:00:00:00:00:11 state active

Enable ETH auxiliary device:
$ devlink dev param set auxiliary/mlx5_core.sf.1 \
name enable_eth value true cmode driverinit

Now, in order to fully probe the SF, use devlink reload:
$ devlink dev reload auxiliary/mlx5_core.sf.1
此时，用户拥有仅用于以太网功能的带有辅助设备的 SF devlink 实例


命令操作:
const char *mlx5_command_str(int command)
{
#define MLX5_COMMAND_STR_CASE(__cmd) case MLX5_CMD_OP_ ## __cmd: return #__cmd

    switch (command) {
    MLX5_COMMAND_STR_CASE(QUERY_HCA_CAP);
    MLX5_COMMAND_STR_CASE(QUERY_ADAPTER);
    MLX5_COMMAND_STR_CASE(INIT_HCA);
    MLX5_COMMAND_STR_CASE(TEARDOWN_HCA);
    MLX5_COMMAND_STR_CASE(ENABLE_HCA);
    MLX5_COMMAND_STR_CASE(DISABLE_HCA);
    MLX5_COMMAND_STR_CASE(QUERY_PAGES);
    MLX5_COMMAND_STR_CASE(MANAGE_PAGES);
    MLX5_COMMAND_STR_CASE(SET_HCA_CAP);
    MLX5_COMMAND_STR_CASE(QUERY_ISSI);
    MLX5_COMMAND_STR_CASE(SET_ISSI);
    MLX5_COMMAND_STR_CASE(SET_DRIVER_VERSION);
    MLX5_COMMAND_STR_CASE(CREATE_MKEY);
    MLX5_COMMAND_STR_CASE(QUERY_MKEY);
    MLX5_COMMAND_STR_CASE(DESTROY_MKEY);
    MLX5_COMMAND_STR_CASE(QUERY_SPECIAL_CONTEXTS);
    MLX5_COMMAND_STR_CASE(PAGE_FAULT_RESUME);
    MLX5_COMMAND_STR_CASE(CREATE_EQ);
    MLX5_COMMAND_STR_CASE(DESTROY_EQ);
    MLX5_COMMAND_STR_CASE(QUERY_EQ);
    MLX5_COMMAND_STR_CASE(GEN_EQE);
    MLX5_COMMAND_STR_CASE(CREATE_CQ);
    MLX5_COMMAND_STR_CASE(DESTROY_CQ);
    MLX5_COMMAND_STR_CASE(QUERY_CQ);
    MLX5_COMMAND_STR_CASE(MODIFY_CQ);
    MLX5_COMMAND_STR_CASE(CREATE_QP);
    MLX5_COMMAND_STR_CASE(DESTROY_QP);
    MLX5_COMMAND_STR_CASE(RST2INIT_QP);
    MLX5_COMMAND_STR_CASE(INIT2RTR_QP);
    MLX5_COMMAND_STR_CASE(RTR2RTS_QP);
    MLX5_COMMAND_STR_CASE(RTS2RTS_QP);
    MLX5_COMMAND_STR_CASE(SQERR2RTS_QP);
    MLX5_COMMAND_STR_CASE(2ERR_QP);
    MLX5_COMMAND_STR_CASE(2RST_QP);
    MLX5_COMMAND_STR_CASE(QUERY_QP);
    MLX5_COMMAND_STR_CASE(SQD_RTS_QP);
    MLX5_COMMAND_STR_CASE(INIT2INIT_QP);
    MLX5_COMMAND_STR_CASE(CREATE_PSV);
    MLX5_COMMAND_STR_CASE(DESTROY_PSV);
    MLX5_COMMAND_STR_CASE(CREATE_SRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_SRQ);
    MLX5_COMMAND_STR_CASE(QUERY_SRQ);
    MLX5_COMMAND_STR_CASE(ARM_RQ);
    MLX5_COMMAND_STR_CASE(CREATE_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(QUERY_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(ARM_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(CREATE_DCT);
    MLX5_COMMAND_STR_CASE(DESTROY_DCT);
    MLX5_COMMAND_STR_CASE(DRAIN_DCT);
    MLX5_COMMAND_STR_CASE(QUERY_DCT);
    MLX5_COMMAND_STR_CASE(ARM_DCT_FOR_KEY_VIOLATION);
    MLX5_COMMAND_STR_CASE(QUERY_VPORT_STATE);
    MLX5_COMMAND_STR_CASE(MODIFY_VPORT_STATE);
    MLX5_COMMAND_STR_CASE(QUERY_ESW_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_ESW_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_NIC_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_NIC_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_ROCE_ADDRESS);
    MLX5_COMMAND_STR_CASE(SET_ROCE_ADDRESS);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_HCA_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_GID);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_PKEY);
    MLX5_COMMAND_STR_CASE(QUERY_VNIC_ENV);
    MLX5_COMMAND_STR_CASE(QUERY_VPORT_COUNTER);
    MLX5_COMMAND_STR_CASE(ALLOC_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(DEALLOC_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(QUERY_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(SET_MONITOR_COUNTER);
    MLX5_COMMAND_STR_CASE(ARM_MONITOR_COUNTER);
    MLX5_COMMAND_STR_CASE(SET_PP_RATE_LIMIT);
    MLX5_COMMAND_STR_CASE(QUERY_RATE_LIMIT);
    MLX5_COMMAND_STR_CASE(CREATE_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(DESTROY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(QUERY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(MODIFY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(CREATE_QOS_PARA_VPORT);
    MLX5_COMMAND_STR_CASE(DESTROY_QOS_PARA_VPORT);
    MLX5_COMMAND_STR_CASE(ALLOC_PD);
    MLX5_COMMAND_STR_CASE(DEALLOC_PD);
    MLX5_COMMAND_STR_CASE(ALLOC_UAR);
    MLX5_COMMAND_STR_CASE(DEALLOC_UAR);
    MLX5_COMMAND_STR_CASE(CONFIG_INT_MODERATION);
    MLX5_COMMAND_STR_CASE(ACCESS_REG);
    MLX5_COMMAND_STR_CASE(ATTACH_TO_MCG);
    MLX5_COMMAND_STR_CASE(DETACH_FROM_MCG);
    MLX5_COMMAND_STR_CASE(GET_DROPPED_PACKET_LOG);
    MLX5_COMMAND_STR_CASE(MAD_IFC);
    MLX5_COMMAND_STR_CASE(QUERY_MAD_DEMUX);
    MLX5_COMMAND_STR_CASE(SET_MAD_DEMUX);
    MLX5_COMMAND_STR_CASE(NOP);
    MLX5_COMMAND_STR_CASE(ALLOC_XRCD);
    MLX5_COMMAND_STR_CASE(DEALLOC_XRCD);
    MLX5_COMMAND_STR_CASE(ALLOC_TRANSPORT_DOMAIN);
    MLX5_COMMAND_STR_CASE(DEALLOC_TRANSPORT_DOMAIN);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_STATUS);
    MLX5_COMMAND_STR_CASE(MODIFY_CONG_STATUS);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_PARAMS);
    MLX5_COMMAND_STR_CASE(MODIFY_CONG_PARAMS);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_STATISTICS);
    MLX5_COMMAND_STR_CASE(ADD_VXLAN_UDP_DPORT);
    MLX5_COMMAND_STR_CASE(DELETE_VXLAN_UDP_DPORT);
    MLX5_COMMAND_STR_CASE(SET_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(QUERY_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(DELETE_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(SET_WOL_ROL);
    MLX5_COMMAND_STR_CASE(QUERY_WOL_ROL);
    MLX5_COMMAND_STR_CASE(CREATE_LAG);
    MLX5_COMMAND_STR_CASE(MODIFY_LAG);
    MLX5_COMMAND_STR_CASE(QUERY_LAG);
    MLX5_COMMAND_STR_CASE(DESTROY_LAG);
    MLX5_COMMAND_STR_CASE(CREATE_VPORT_LAG);
    MLX5_COMMAND_STR_CASE(DESTROY_VPORT_LAG);
    MLX5_COMMAND_STR_CASE(CREATE_TIR);
    MLX5_COMMAND_STR_CASE(MODIFY_TIR);
    MLX5_COMMAND_STR_CASE(DESTROY_TIR);
    MLX5_COMMAND_STR_CASE(QUERY_TIR);
    MLX5_COMMAND_STR_CASE(CREATE_SQ);
    MLX5_COMMAND_STR_CASE(MODIFY_SQ);
    MLX5_COMMAND_STR_CASE(DESTROY_SQ);
    MLX5_COMMAND_STR_CASE(QUERY_SQ);
    MLX5_COMMAND_STR_CASE(CREATE_RQ);
    MLX5_COMMAND_STR_CASE(MODIFY_RQ);
    MLX5_COMMAND_STR_CASE(DESTROY_RQ);
    MLX5_COMMAND_STR_CASE(QUERY_RQ);
    MLX5_COMMAND_STR_CASE(CREATE_RMP);
    MLX5_COMMAND_STR_CASE(MODIFY_RMP);
    MLX5_COMMAND_STR_CASE(DESTROY_RMP);
    MLX5_COMMAND_STR_CASE(QUERY_RMP);
    MLX5_COMMAND_STR_CASE(CREATE_TIS);
    MLX5_COMMAND_STR_CASE(MODIFY_TIS);
    MLX5_COMMAND_STR_CASE(DESTROY_TIS);
    MLX5_COMMAND_STR_CASE(QUERY_TIS);
    MLX5_COMMAND_STR_CASE(CREATE_RQT);
    MLX5_COMMAND_STR_CASE(MODIFY_RQT);
    MLX5_COMMAND_STR_CASE(DESTROY_RQT);
    MLX5_COMMAND_STR_CASE(QUERY_RQT);
    MLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ROOT);
    MLX5_COMMAND_STR_CASE(CREATE_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(DESTROY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(CREATE_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(DESTROY_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(DELETE_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(ALLOC_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(DEALLOC_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(MODIFY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(ALLOC_PACKET_REFORMAT_CONTEXT);
    MLX5_COMMAND_STR_CASE(DEALLOC_PACKET_REFORMAT_CONTEXT);
    MLX5_COMMAND_STR_CASE(ALLOC_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(DEALLOC_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(FPGA_CREATE_QP);
    MLX5_COMMAND_STR_CASE(FPGA_MODIFY_QP);
    MLX5_COMMAND_STR_CASE(FPGA_QUERY_QP);
    MLX5_COMMAND_STR_CASE(FPGA_QUERY_QP_COUNTERS);
    MLX5_COMMAND_STR_CASE(FPGA_DESTROY_QP);
    MLX5_COMMAND_STR_CASE(CREATE_XRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_XRQ);
    MLX5_COMMAND_STR_CASE(QUERY_XRQ);
    MLX5_COMMAND_STR_CASE(ARM_XRQ);
    MLX5_COMMAND_STR_CASE(CREATE_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(DESTROY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(MODIFY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(QUERY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(QUERY_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(ALLOC_MEMIC);
    MLX5_COMMAND_STR_CASE(DEALLOC_MEMIC);
    MLX5_COMMAND_STR_CASE(QUERY_ESW_FUNCTIONS);
    MLX5_COMMAND_STR_CASE(CREATE_UCTX);
    MLX5_COMMAND_STR_CASE(DESTROY_UCTX);
    MLX5_COMMAND_STR_CASE(CREATE_UMEM);
    MLX5_COMMAND_STR_CASE(DESTROY_UMEM);
    MLX5_COMMAND_STR_CASE(RELEASE_XRQ_ERROR);
    MLX5_COMMAND_STR_CASE(MODIFY_XRQ);
    MLX5_COMMAND_STR_CASE(QUERY_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(MODIFY_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(ALLOC_SF);
    MLX5_COMMAND_STR_CASE(DEALLOC_SF);
    MLX5_COMMAND_STR_CASE(SUSPEND_VHCA);
    MLX5_COMMAND_STR_CASE(RESUME_VHCA);
    MLX5_COMMAND_STR_CASE(QUERY_VHCA_MIGRATION_STATE);
    MLX5_COMMAND_STR_CASE(SAVE_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(LOAD_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(SYNC_CRYPTO);
    MLX5_COMMAND_STR_CASE(ALLOW_OTHER_VHCA_ACCESS);
    default: return "unknown command opcode";
    }
}



vlan header:
#define IANA_VXLAN_UDP_PORT     4789
#define IANA_VXLAN_GPE_UDP_PORT 4790

/* VXLAN protocol (RFC 7348) header:
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 * |R|R|R|R|I|R|R|R|               Reserved                        |
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 * |                VXLAN Network Identifier (VNI) |   Reserved    |
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *
 * I = VXLAN Network Identifier (VNI) present.
 */



.unlocked_ioctl = ib_uverbs_ioctl
err_no: #define	ETIMEDOUT	110	/* Connection timed out */, tools/include/uapi/asm-generic/errno.h
...
user space
ioctl(context->cmd_fd, RDMA_VERBS_IOCTL, &cmd->hdr)
...
ib_uverbs_ioctl
    unlikely(cmd != RDMA_VERBS_IOCTL)
    copy_from_user
    srcu_read_lock
    ib_uverbs_cmd_verbs -> IB/uverbs：使用 uverbs_api 解组 ioctl 命令 转换 ioctl 方法系统调用路径以使用 uverbs_api 数据结构。 新的 uapi 结构包含所有相同的信息，只是以不同且更优化的方式。 - 对于与属性相关的所有内容，使用 attr_bkey 而不是 2 级基数树。 这包括属性存储、存在以及缺失强制属性的检测。 - 避免在完成时迭代所有属性存储，而是使用 find_first_bit 和 attr_bkey 来仅定位那些需要清理的属性。 - 组织事物始终运行并始终依赖清理。 这避免了一堆棘手的错误展开情况。 - 使用基数树定位方法，并使用非常高效的增量基数树查找来定位属性 - 使用预先计算的 destroy_bkey 来处理 uobject 销毁 - 使用预先计算的分配大小和预先计算的“need_stack”以避免快速路径中的数学运算。 如果用户空间不传递（许多）不支持的属性，这是最佳的。 总的来说，这为属性访问器带来了更好的代码生成，所有内容现在都存储在由 attr_bkey 索引的位图或线性数组中。 编译器可以在编译时计算所有方法属性的 attr_bkey 值，这意味着像 uverbs_attr_is_valid() 这样的东西现在编译成单指令位测试
        radix_tree_iter_lookup <- uapi_add_get_elm
            uapi_key_ioctl_method(hdr->method_id)
        method_elm = rcu_dereference_protected(*slot, true)
        ib_uverbs_run_method
            handler = srcu_dereference
            ret = handler(&pbundle->bundle)
            ...
            ib_uverbs_alloc_pd -> IB_USER_VERBS_CMD_ALLOC_PD
                uverbs_request
                    copy_from_user
                uobj_alloc(UVERBS_OBJECT_PD, attrs, &ib_dev)
                    ...
                    rdma_alloc_begin_uobject
                        obj->type_class->alloc_begin
                rdma_zalloc_drv_obj
                rdma_restrack_new
                rdma_restrack_set_name
                ib_dev->ops.alloc_pd(pd, &attrs->driver_udata) -> .alloc_pd =  -> mlx5_ib_alloc_pd
                    rdma_udata_to_drv_context
                    mlx5_cmd_exec_inout(to_mdev(ibdev)->mdev, alloc_pd, in, out) -> 命令框架
                        ...
                    ib_copy_to_udata
                rdma_restrack_add
                    xa_insert
                    or xa_alloc_cyclic
                uobj_finalize_uobj_create
                uverbs_response
        bundle_destroy
    srcu_read_unlock


ioctl, cmd, 
uverbs_core_api
uverbs_def_write_intf
static const struct uapi_definition uverbs_core_api[] = {
	UAPI_DEF_CHAIN(uverbs_def_obj_async_fd),
	UAPI_DEF_CHAIN(uverbs_def_obj_counters),
	UAPI_DEF_CHAIN(uverbs_def_obj_cq),
	UAPI_DEF_CHAIN(uverbs_def_obj_device),
	UAPI_DEF_CHAIN(uverbs_def_obj_dm),
	UAPI_DEF_CHAIN(uverbs_def_obj_flow_action),
	UAPI_DEF_CHAIN(uverbs_def_obj_intf),
	UAPI_DEF_CHAIN(uverbs_def_obj_mr),
	UAPI_DEF_CHAIN(uverbs_def_obj_qp),
	UAPI_DEF_CHAIN(uverbs_def_obj_srq),
	UAPI_DEF_CHAIN(uverbs_def_obj_wq),
	UAPI_DEF_CHAIN(uverbs_def_write_intf),
	{},
};




static struct ib_client uverbs_client = {
    .name   = "uverbs",
    .no_kverbs_req = true,
    .add    = ib_uverbs_add_one,
    .remove = ib_uverbs_remove_one,
    .get_nl_info = ib_uverbs_get_nl_info,
};




ibv_reg_mr:
drivers/infiniband/hw/irdma/verbs.c
IB_USER_VERBS_CMD_REG_MR
ib_uverbs_reg_mr -> .reg_user_mr = irdma_reg_user_mr <- DECLARE_UVERBS_WRITE
    region = ib_umem_get -> pin住以及通过DMA映射的用户空间内存, IB/uverbs：将 ib_umem_get()/ib_umem_release() 导出到模块，导出 ib_umem_get()/ib_umem_release() 并让低级驱动程序控制何时调用 ib_umem_get() 来pin和 DMA 映射用户空间，而不是总是调用它 在调用低级驱动程序的 reg_user_mr 方法之前在 ib_uverbs_reg_mr() 中。 还将这些函数移至 ib_core 模块而不是 ib_uverbs 中，以便使用它们的驱动程序模块不依赖于 ib_uverbs。 这具有许多优点： - 从使通用代码成为可以根据特定设备的详细信息指示由设备特定代码使用或覆盖的库的角度来看，这是更好的设计。 - 不需要固定用户空间内存区域的驱动程序不需要承受调用 ib_mem_get() 的性能损失。 例如，虽然我没有尝试在此补丁中实现它，但 ipath 驱动程序应该能够避免固定内存并仅使用 copy_{to,from}_user() 来访问用户空间内存区域。 - 需要特殊映射处理的缓冲区可以由低级驱动程序识别。 例如，通过使用额外标志映射 CQ 缓冲区，可以解决用户空间中 mthca CQ 的一些特定于 Altix 的内存排序问题。 - 需要为内存区域以外的内容固定和 DMA 映射用户空间内存的驱动程序可以直接使用 ib_umem_get()，而不是使用其 reg_phys_mr 方法的额外参数进行黑客攻击。 例如，待合并的 mlx4 驱动程序需要引脚和 DMA 映射 QP 和 CQ 缓冲区，但不需要为这些缓冲区创建内存密钥。 因此，最干净的解决方案是 mlx4 在 create_qp 和 create_cq 方法中调用 ib_umem_get() -> 调用 ib_umem_get 来完成内存页面pin操作 + 将pin住的内存页面组织为DMA SG List
        can_do_mlock -> [PATCH] IB uverbs：内存固定实现(pin)，添加对固定用户空间内存区域并返回该区域中的页面列表的支持。 这包括根据 vm_locked 跟踪固定内存并防止非特权用户超过 RLIMIT_MEMLOCK
        mmgrab(mm) -> 抓住内存(引用+1)
        __get_free_page -> get continue pa(return va) -> https://blog.csdn.net/do2jiang/article/details/5450705
        npages = ib_umem_num_pages(umem)
            ib_umem_num_dma_blocks(umem, PAGE_SIZE) -> RDMA/umem：将 ib_umem_num_pages() 拆分为 ib_umem_num_dma_blocks()，ib_umem_num_pages() 只能由直接在 CPU 页面中使用 SGL 的事物使用。 构建 DMA 列表的驱动程序应使用新的 ib_num_dma_blocks()，它返回 rdma_umem_for_each_block() 将返回的块数。 要使 DMA 驱动程序通用，需要不同的实现。 仅当请求的页面大小为 < PAGE_SIZE 和/或 IOVA == umem->address 时，基于 umem->address 计算 DMA 块计数才有效。 相反，DMA 页数应在 IOVA 地址空间中计算，而不是 umem->address。 因此，IOVA 必须存储在 umem 内，以便可以用于这些计算。 现在默认将其设置为 umem->address 并在调用 ib_umem_find_best_pgsz() 时修复它。 这允许驱动程序安全地转换为 ib_umem_num_dma_blocks()
                ALIGN ALIGN_DOWN / pgsz
        cond_resched -> RDMA/umem：在 ib_umem_get() 中添加一个调度点，映射小至 64GB 可能需要 10 秒以上，触发 CONFIG_PREEMPT_NONE=y 的内核问题。 ib_umem_get() 已经在 x86_64 上以 2MB 为单位分割工作，在持久循环中添加 cond_resched() 足以解决问题。 请注意，sg_alloc_table() 仍然可以使用超过 100 毫秒，这也是有问题的。 这可能稍后在 ib_umem_add_sg_table() 中解决，按需在 sql 中添加新块. 在一些比较耗时的处理中如文件系统和内存回收的一些路径会调用cond_resched, 用cond_resched来进行检查是否具备调度时机, 对于非抢占式内核来说，在内核的很多地方，特别是文件系统操作和内存管理相关的一些耗时路径中，都已经被内核开发者识别出来，并使用cond_resched来减小延迟, cond_resched() 函数，它的功能是主动放权，等待下一次的调度运行, 参考: https://www.zhihu.com/question/35004859
        pin_user_pages_fast -> 与 get_user_pages_fast() 几乎相同，只是设置了 FOLL_PIN。 有关函数参数的文档，请参阅 get_user_pages_fast()，因为此处的参数是相同的。 FOLL_PIN 意味着必须通过 unpin_user_page() 释放页面。 请参阅 Documentation/core-api/pin_user_pages.rst 了解更多详细信息。 请注意，如果返回的页面中有一个 zero_page，则其中不会有pin，并且 unpin_user_page() 不会从中删除pin -> mm/gup：从内部 GUP 函数中删除 vmas 数组，现在我们已经消除了所有使用 vmas 参数的 GUP API 的调用者，完全消除了它。 这消除了一类错误，其中 vmas 的保留时间可能比 mmap_lock 的时间长，因此我们不必担心在此操作期间锁定被删除，留下悬空指针。 这简化了 GUP API 并使其用途更加清晰 - 应用跟随标志，如果固定，则返回页面数组
            is_valid_gup_args
                WARN_ON_ONCE()会将调试信息输出到dmesg，类似于BUG_ON()打印的内容。与BUG_ON()的区别在于，WARN_ON_ONCE()仅会在第一次触发时打印调试信息
            internal_get_user_pages_fast -> 获取用户空间页面: https://sanli-b.com.cn/posts/35092.html -> mm/gup：跟踪 FOLL_PIN 页面 添加对通过 FOLL_PIN 固定的页面的跟踪。 此跟踪是通过 page->_refcount 的重载来实现的：通过将 GUP_PIN_COUNTING_BIAS (1024) 添加到 refcount 来添加引脚。 这提供了固定的模糊指示，并且可能会出现误报（但这没关系）。 请参阅现有的 Documentation/core-api/pin_user_pages.rst 了解详细信息。 正如 pin_user_pages.rst 中提到的，有效设置 FOLL_PIN（通常通过 pin_user_pages*()）的调用者需要最终通过 unpin_user_page() 释放此类页面。 另请注意 pin_user_pages.rst 中“TODO：适用于 1GB 及更大的大页面”部分中讨论的限制。 （该限制将在后续补丁中删除。）FOLL_PIN 标志的效果与 FOLL_GET 的效果类似，并且可以被视为“用于 DIO 和/或 RDMA 使用的 FOLL_GET”。 通过 FOLL_PIN 固定的页面可通过新函数调用进行识别： bool page_maybe_dma_pinned(struct page *page); 遇到这样的页面该怎么办，就留给以后的补丁了。 在[1]、[2]、[3]和[4]中对此进行了讨论。 这也会将 follow_page_mask() 中的 BUG_ON() 更改为 WARN_ON()
                mm_set_has_pinned_flag
                    set_bit(MMF_HAS_PINNED, mm_flags) -> flag -> MMF_HAS_PINNED：该mm是否已固定任何页面。 当它变得稳定时，它可以在将来被 mm.pinned_vm 取代，或者自己成长为一个计数器。 我们现在对此非常积极：即使稍后取消固定的页面，我们仍然会在该 mm 的生命周期中保留此位设置，只是为了简单起见
                untagged_addr -> 调用 untagged_addr() 宏直接去除指针标记
                check_add_overflow
                lockless_pages_from_mm -> mm/gup：重组 internal_get_user_pages_fast()，补丁系列“在gup_fast和copy_page_range()之间添加seqcount”，v4。 正如 Linus 所讨论和建议的，使用 seqcount 来结束 gup_fast 和 copy_page_range() 之间的小竞争。 Ahmed 确认 raw_write_seqcount_begin() 是在这种情况下使用的正确 API，并且它不会触发任何 lockdeps。 我能够使用两个线程对其进行测试，一个线程分叉，另一个使用 ibv_reg_mr() 快速触发 GUP。 将 copy_page_range() 修改为睡眠状态使窗口足够大，可以可靠地命中来测试逻辑。 此补丁（共 2 个）：本系列中的下一个补丁使无锁流程变得更加复杂，因此将整个块移至新函数中并删除一定程度的缩进。 整理一些废话： - addr 始终与 start 相同，因此使用 start - 使用现代的 check_add_overflow() 进行计算 end = start + len - nr_pinned/pages << PAGE_SHIFT 需要 LHS 为 unsigned long 以避免移位溢出 ，将变量设置为 unsigned long 以避免在两个地方进行编码转换。 nr_pinned 缺少其演员 - ret 和 nr_pinned 的处理可以稍微简化一点 没有功能变化 -> https://gwzlchn.github.io/202208/rdma-stack-02/
                    IS_ENABLED
                    gup_fast_permitted
                    raw_read_seqcount
                    gup_pgd_range
                    read_seqcount_retry
                    unpin_user_pages_lockless
                __gup_longterm_locked
        sg_alloc_append_table_from_pages
        ib_dma_map_sgtable_attrs
    ib_copy_from_udata(&req, udata, min(sizeof(req), udata->inlen)
    irdma_alloc_iwmr
        ib_umem_find_best_pgsz
        ib_umem_num_dma_blocks
    case IRDMA_MEMREG_TYPE_QP
        irdma_reg_user_mr_type_qp(req, udata, iwmr)
            irdma_handle_q_mem(iwdev, &req, iwpbl, lvl)
                irdma_setup_pbles -> 将用户页拷贝到PBLE中
                case IRDMA_MEMREG_TYPE_QP
                    irdma_check_mem_contiguous
            rdma_udata_to_drv_context
            list_add_tail(&iwpbl->list, &ucontext->qp_reg_mem_list)
    case IRDMA_MEMREG_TYPE_MEM
        irdma_reg_user_mr_type_mem
            irdma_setup_pbles -> 使用位掩码重构 PBLE 函数来表示所需的 PBLE 级别，而使用 2 个参数 use_pble 和 lvl_one_only 使代码变得混乱
            HW 使用主机内存作为许多协议上下文对象和队列状态跟踪的后备存储。 主机内存缓存 (HMC) 是负责管理存储在主机内存中的这些对象的组件。 添加函数和数据结构来管理 HMC 为各种对象使用的支持页面的分配, 本文主要分析inux内核intel/hns3/mlx5等RDMA驱动上下文内存管理机制优缺点: https://zhuanlan.zhihu.com/p/610503666, 实现物理缓冲区列表条目 (PBLE) 资源管理器来管理 PBLE HMC 资源对象池, 
                irdma_get_pble ?
                    get_lvl1_lvl2_pble
                        get_lvl1_pble
                            irdma_prm_get_pbles
                                bitmap_find_next_zero_area
                                bitmap_set
                        get_lvl2_pble
                            ...
                    add_pble_prm -> Host Memory Cache (HMC) 主机内存缓存, prm 页资源管理
                        irdma_get_type
                        add_sd_direct
                            irdma_add_sd_table_entry
                            dma_alloc_coherent
                            memcpy(&sd_entry->u.pd_table.pd_page_addr, &dma_mem,
                        add_bp_pages -> 为段描述添加后端内存页
                            irdma_pble_get_paged_mem
                                irdma_map_vm_page_list
                                    vmalloc_to_page -> 找到由vmalloc( )所分配的内存的虚拟地址所映射的物理页，并返回该页的指针描述符
                                    dma_map_page -> 将一页物理内存进行映射
                            irdma_add_sd_table_entry
                            irdma_add_pd_table_entry
                                dma_alloc_coherent
                                memcpy(&pd_entry->bp.addr, page, sizeof(pd_entry->bp.addr))
                                memcpy(pd_addr, &page_desc, sizeof(*pd_addr))
                                irdma_invalidate_pf_hmc_pd -> 使 PF 硬件中的 pd 缓存无效
                                    writel(val, dev->hw_regs[IRDMA_PFHMC_PDINV])
                        irdma_prm_add_pble_mem
                            bitmap_zalloc
                        irdma_hmc_sd_one
                            irdma_set_sd_entry
                            or irdma_clr_sd_entry
                            dev->cqp->process_cqp_sds(dev, &sdinfo) -> irdma_update_sds_noccq
                                cqp_sds_wqe_fill
                                    irdma_sc_cqp_get_next_send_wqe_idx
                                    switch (wqe_entries)
                                    case 3:
                                    ...
                                irdma_get_cqp_reg_info
                                irdma_sc_cqp_post_sq(cqp)
                                irdma_cqp_poll_registers
                        list_add(&chunk->list, &pble_rsrc->pinfo.clist)
                    get_lvl1_lvl2_pble
                irdma_copy_user_pgaddrs -> 将用户页面地址复制到本地 pble 的操作系统
                    sg_page -> 获取scatterlist所对应的page指针
                    rdma_umem_for_each_dma_block -> 迭代 umem 的连续 DMA 块
                        rdma_block_iter_dma_address -> 获取块迭代器持有的当前块的对齐 dma 地址
                        irdma_next_pbl_addr
            irdma_check_mr_contiguous
                irdma_check_mem_contiguous
            irdma_create_stag -> 随机stag
                get_random_bytes
                irdma_alloc_rsrc -> RDMA/irdma：注册辅助驱动程序并实现私有通道 OP，注册可以从 Intel PCI netdev 驱动程序 i40e 和ice 连接到辅助 RDMA 设备的辅助驱动程序。 实现私有通道操作，并注册网络通知程序
            irdma_hwreg_mr(iwdev, iwmr, access) -> 发送cqp命令进行内存注册
                irdma_alloc_and_get_cqp_request
                irdma_get_mr_access
                cqp_info->cqp_cmd = IRDMA_OP_MR_REG_NON_SHARED -> irdma_sc_mr_reg_non_shared
                    irdma_sc_cqp_get_next_send_wqe
                    ...
                    set_64bit_val(wqe, 32, info->reg_addr_pa)
                    irdma_sc_cqp_post_sq
                stag_info->reg_addr_pa = iwmr->pgaddrmem[0]
                irdma_handle_cqp_op
                irdma_put_cqp_request
UVERBS_OBJECT_MR
ib_check_mr_access
uobj_get_obj_read
reg_user_mr


intel irdma/ice/e810 driver:
drivers/infiniband/hw/irdma/main.c
module_init(irdma_init_module);
    auxiliary_driver_register i40iw_auxiliary_drv
        .probe = i40iw_probe
    auxiliary_driver_register(&irdma_auxiliary_drv.adrv)
    irdma_register_notifiers
        register_inetaddr_notifier(&irdma_inetaddr_notifier);
        register_inet6addr_notifier(&irdma_inetaddr6_notifier);
        register_netevent_notifier(&irdma_net_notifier);
        register_netdevice_notifier(&irdma_netdevice_notifier);
...		
irdma_probe <- irdma_auxiliary_drv

irdma_ib_register_device
    irdma_init_rdma_device
        irdma_init_roce_device(iwdev)
        or
        irdma_init_iw_device
        ib_set_device_ops(&iwdev->ibdev, &irdma_dev_ops)
    ib_device_set_netdev
    dma_set_max_seg_size
    ib_register_device(&iwdev->ibdev, "irdma%d", iwdev->rf->hw.device)
    irdma_port_ibevent(iwdev)
        event.event = iwdev->iw_status ? IB_EVENT_PORT_ACTIVE : IB_EVENT_PORT_ERR
        ib_dispatch_event(&event)



.reg_user_mr = rxe_reg_user_mr,



static struct notifier_block irdma_inetaddr_notifier = {
	.notifier_call = irdma_inetaddr_event
};
static struct notifier_block irdma_inetaddr6_notifier = {
	.notifier_call = irdma_inet6addr_event
};
static struct notifier_block irdma_net_notifier = {
	.notifier_call = irdma_net_event
};
static struct notifier_block irdma_netdevice_notifier = {
	.notifier_call = irdma_netdevice_event
};


...
irdma_init_roce_device
    ib_set_device_ops(&iwdev->ibdev, &irdma_roce_dev_ops);
        SET_DEVICE_OP(dev_ops, add_gid);
        SET_DEVICE_OP(dev_ops, counter_bind_qp)
        ...

static const struct ib_device_ops irdma_roce_dev_ops = {
    .attach_mcast = irdma_attach_mcast,
    .create_ah = irdma_create_ah,
    .create_user_ah = irdma_create_user_ah,
    .destroy_ah = irdma_destroy_ah,
    .detach_mcast = irdma_detach_mcast,
    .get_link_layer = irdma_get_link_layer,
    .get_port_immutable = irdma_roce_port_immutable,
    .modify_qp = irdma_modify_qp_roce,
    .query_ah = irdma_query_ah,
    .query_pkey = irdma_query_pkey,
};


ioctl -> ib_uverbs_modify_qp -> return modify_qp(attrs, &cmd)
    ...
    if (cmd->base.attr_mask & IB_QP_RQ_PSN)
    ...



irdma_modify_qp
irdma_modify_qp_roce
    irdma_query_pkey
    rdma_get_udp_sport -> 根据 grh.flow_label 或 lqpn/rqrpn 获取 QP 的源 udp 端口号。 这可以更好地跨 NIC RX 队列传播流量
    irdma_qp_rem_qos
    dev->ws_remove
    rdma_read_gid_l2_fields
    irdma_roce_get_vlan_prio
        vlan_dev_get_egress_qos_mask
    irdma_qp_add_qos
        list_add(&qp->list, &vsi->qos[qp->user_pri].qplist)
    ib_modify_qp_is_ok
        qp_state_table[cur_state][next_state].valid) -> IB：添加 ib_modify_qp_is_ok() 库函数，内核中的 mthca 驱动程序包含一个表，其中的属性对于每个队列对状态转换都有效。 事实证明，正在准备合并的其他两个 IB 驱动程序（ipath 和 ehca）都复制了该表、错误等。 为了防止代码重复，请将此表和用于检查参数的代码移动到中间层库函数 ib_modify_qp_is_ok() 中
        qp状态表及参数: qp_state_table[IB_QPS_ERR + 1][IB_QPS_ERR + 1]
    wait_event(iwqp->mod_qp_waitq, !atomic_read(&iwqp->hw_mod_qp_pend)) <- irdma_hw_modify_qp_callback
        wake_up(&iwqp->mod_qp_waitq)
    switch (attr->qp_state) -> QP状态机
    ...
    irdma_flush_wqes
        irdma_hw_flush_wqes
            cqp_request->callback_fcn = irdma_hw_flush_wqes_callback
            cqp_info->cqp_cmd = IRDMA_OP_QP_FLUSH_WQES
            irdma_handle_cqp_op -> cqp 控制QP
                irdma_process_cqp_cmd
                    irdma_exec_cqp_cmd
                        switch (pcmdinfo->cqp_cmd) -> 判断控制QP命令类型
                        case IRDMA_OP_CEQ_CREATE -> 驱动程序将特权命令发布到硬件管理队列（控制 QP 或 CQP），以请求硬件执行管理操作。 实现 CQP 的创建/销毁以及支持函数、数据结构和标头以处理不同的 CQP 命令
                            irdma_sc_cq_create
                                irdma_sc_cqp_get_next_send_wqe
                                set_64bit_val(wqe, 0, cq->cq_uk.cq_size) -> 按位设置其值(每8字节)
                                dma_wmb()
                                irdma_sc_cqp_post_sq -> no msleep(300)
                                    writel(IRDMA_RING_CURRENT_HEAD(cqp->sq_ring), cqp->dev->cqp_db) -> 写寄存器(往内存映射的 I/O 空间上写4字节数据)
                        ...
                        case IRDMA_OP_QP_CREATE
                            irdma_sc_qp_create -> 创建QP判断对应QP HMC是否已准备好
                        ...
    irdma_sc_qp_setctx_roce -> void irdma_sc_qp_setctx_roce(struct irdma_sc_qp *qp, __le64 *qp_ctx, -> 设置QP上下文
        set_64bit_val rq_wqe_size
        set_64bit_val(qp_ctx, 8, qp->sq_pa) -> set sendq pa
        set_64bit_val(qp_ctx, 16, qp->rq_pa)
        ...
        print_hex_dump_debug("WQE: QP_HOST CTX WQE", DUMP_PREFIX_OFFSET, 16, -> print_hex_dump
    if (attr_mask & IB_QP_STATE)
        irdma_hw_modify_qp
            cqp_request->callback_fcn = irdma_hw_modify_qp_callback -> no wait/async
        cqp_info->cqp_cmd = IRDMA_OP_QP_MODIFY
        irdma_handle_cqp_op(rf, cqp_request)

irdma_uk_rdma_write
irdma_uk_rdma_read
irdma_uk_cq_poll_cmpl


/proc/pid/pagemap - an array mapping virtual pages to pfns, 如果页面不存在但在交换中，则 PFN 包含交换文件号的编码以及页面在交换中的偏移量。 未映射的页面返回空 PFN。 这允许精确确定哪些页面被映射（或在交换中）并比较进程之间的映射页面。 * 此接口的高效用户将使用 /proc/pid/maps 来确定实际映射的内存区域，并使用 llseek 跳过未映射的区域
pagemap_read -> Maps4：添加 /proc/pid/pagemap 接口，该接口为地址空间中的每个页面提供到其物理页帧号的映射，允许精确确定哪些页面被映射以及哪些页面在进程之间共享。 此版本中的新增内容： - 标头再次消失（根据 Dave Hansen 和 Alan Cox 的建议） - 64 位条目（根据与 Andi Kleen 的讨论） - 交换导出的 pte 信息（来自 Dave Hansen） - 页面遍历器回调以查找漏洞（来自 Dave Hansen） - 直接 put_user I/O（根据 Rusty Russell 的建议）此补丁折叠在清理中并交换 Dave Hansen 的 PTE 支持
    file_ns_capable
    mmap_read_lock_killable
    untagged_addr_remote
    mmap_read_lock_killable
    walk_page_range(mm, start_vaddr, end, &pagemap_ops, &pm) -> walk_page_range - 使用回调遍历内存映射的页表：起始地址：结束地址：为树的每个级别调用的回调集递归地遍历 VMA 中内存区域的页表，调用提供的回调。 回调按顺序调用（第一个 PGD、第一个 PUD、第一个 PMD、第一个 PTE、第二个 PTE...第二个 PMD 等）。 如果省略较低级别的回调，则行走深度会减少。 每个回调接收一个入口指针以及关联范围的开始和结束，以及用于访问 ->private 或 ->mm 字段的原始 mm_walk 的副本。 通常不加锁，但分割透明大页可能会加页表锁。 如果需要，底层迭代器将从 highmem 映射 PTE 目录。 如果任何回调返回非零值，则遍历将中止并将返回值传播回调用者。 否则返回 0。 如果 walk->hugetlb_entry 为 !NULL，则 walk->mm->mmap_sem 必须至少保持读取状态
    copy_to_user

static const struct mm_walk_ops pagemap_ops = {
    .pmd_entry	= pagemap_pmd_range,
    .pte_hole	= pagemap_pte_hole,
    .hugetlb_entry	= pagemap_hugetlb_range,
    .walk_lock	= PGWALK_RDLOCK,
};

pagemap_pmd_range -> pagemap：将 mm 传递给 pagewalkers ，我们现在至少需要这个来检测大页，因为 powerpc 需要 vm_area_struct 来确定虚拟地址是否引用大页（它的 pmd_huge() 不起作用）。 对于其他一些用户来说它也可能派上用场
    pmd_trans_huge_lock
    ...
    for pte
        内核态实现pagemap proc接口的代码位于: fs/proc/task_mmu.c, 把PTE转换为pagemap_entry
        pte_to_pagemap_entry -> proc：报告 /proc/pid/pagemap 中的文件/匿名位，这是安德鲁提议的实现，扩展页面映射文件位以报告任务工作集缺少的内容。 工作集检测的问题是多方面的。 在 criu（检查点/恢复）项目中，我们将任务的内存转储到图像文件中，为了正确执行此操作，我们需要检测映射中的哪些页面真正在使用。 我虽然可以帮助解决这个问题，但 mincore 系统调用却没有。 首先，它不报告交换的页面，因此我们无法找出要转储的匿名映射的哪些部分。 接下来，它会报告页面缓存中存在的页面，即使它们没有被映射，但这并不意味着它们没有受到威胁。 请注意，交换页的问题至关重要——我们必须将交换页转储到映像文件。 但是文件页面的问题是优化 - 我们可以将所有文件页面进行映像，这是正确的，但是如果我们知道页面未映射或未受到限制，我们可以将它们从转储文件中删除。 转储仍然是自洽的，尽管大小明显较小（在实际应用程序中最多小 10 倍）。 Andrew 注意到，proc pagemap 文件解决了上述 3 个问题中的 2 个——它报告页面是否存在或交换，并且不报告未映射的页面缓存页面。 但是，它无法区分受限制的文件页面和不受限制的文件页面。 我想在此文件中最后一个未使用的位来报告映射到相应 pte 的页面是否为 PageAnon
            pte_present(pte)
            frame = pte_pfn(pte) -> 
            make_pme(frame, flags)
        add_to_pagemap
    ...




smap: 基于映射的扩展，显示每个映射的内存消耗以及与其关联的标志, scan page table
static const struct mm_walk_ops smaps_walk_ops = {
    .pmd_entry		= smaps_pte_range,
    .hugetlb_entry		= smaps_hugetlb_range,
    .walk_lock		= PGWALK_RDLOCK,
};
smaps_pte_range
    smaps_pte_entry


show_smap
    smap_gather_stats
    show_map_vma
    __show_smap
    seq_printf


irdma：为英特尔(R) 以太网控制器 E810 添加 RDMA 驱动程序，这是针对英特尔(R) 以太网控制器 E810 的 RDMA FreeBSD 驱动程序（称为 irdma）的初始提交。 以每 PF 方式支持 RoCEv2 和 iWARP 协议，RoCEv2 为默认协议。 测试已使用 krping 工具、perftest、ucmatose、rping、ud_pingpong、rc_pingpong 等完成, https://cgit.freebsd.org/src/commit/?id=42bad04a2156


struct ice_vsi




intel e810, drivers/infiniband/hw/irdma/main.c
irdma_probe
    ib_alloc_device -> #define ib_alloc_device(drv_struct, member) -> struct ib_device *_ib_alloc_device(size_t size)
        device = kzalloc(size, GFP_KERNEL)
        rdma_restrack_init
        rdma_init_coredev -> RDMA/core：在net命名空间中实现compat device/sysfs树，实现ib_core的兼容层sysfs条目，以便非init_net net命名空间也可以发现rdma设备。 每个非 init_net 网络命名空间都在其中创建了 ib_core_device。 这样的 ib_core_device sysfs 树类似于 init_net 命名空间中找到的 rdma 设备。 这允许通过 sysfs 条目在多个非 init_net 网络命名空间中发现 rdma 设备，并且对 rdma-core 用户空间很有帮助
            此 BUILD_BUG_ON 旨在捕获 ib_core_device 和 device 联合的布局更改。 dev 必须是第一个元素，因为 ib_core 和提供程序驱动程序使用它。 在 ib_core_device 中的 device 之前添加任何内容都会打破这个假设
            coredev->dev.class = &ib_class
            device_initialize -> device_initialize - 初始化设备结构。 @dev：设备。 * 这通过初始化其字段来准备设备以供其他层使用。 如果由该函数调用，则它是 device_register() 的前半部分，尽管它也可以单独调用，因此可以使用 @dev 的字段。 特别是，调用此函数后，可以使用 get_device()/put_device() 对 @dev 进行引用计数。 * @dev 中的所有字段都必须由调用者初始化为 0，除非那些明确设置为其他值的字段。 最简单的方法是使用 kzalloc() 来分配包含 @dev 的结构。 * 注意：调用此函数后，使用 put_device() 放弃引用，而不是直接释放 @dev
                INIT_LIST_HEAD(&dev->dma_pools)
                device_pm_init(dev)
                swiotlb_dev_init(dev)
                    dev->dma_io_tlb_mem = &io_tlb_default_mem
            INIT_LIST_HEAD(&coredev->port_list) -> RDMA/core：引入 ib_core_device 来保存设备，为了支持 rdma 设备的多个网络命名空间中的 sysfs 条目，引入一个 ib_core_device ，其范围仅限于保存核心设备和每个端口 sysfs 相关条目。 这是准备补丁，以便在后续补丁中可以在每个网络命名空间中创建多个 ib_core_device，这些设备都可以共享 ib_device。 (a) 将 sysfs 特定字段移至 ib_core_device。 (b) 使 sysfs 和设备生命周期相关例程在 ib_core_device 上工作。 (c) 引入并使用 rdma_init_coredev() 帮助程序来初始化 coredev 字段
            write_pnet(&coredev->rdma_net, net)
        INIT_LIST_HEAD(&device->event_handler_list)
        init_rwsem(&device->event_handler_rwsem) -> init_rwsem()的功能是初始化读写信号量，将信号量的count字段设置为0
        xa_init_flags(&device->client_data, XA_FLAGS_ALLOC) -> 初始化数组
        init_completion(&device->unreg_completion) -> RDMA/核心：使用 netlink 命令同步取消注册, -> 初始化动态分配的完成对象 -> 参考: https://zhuanlan.zhihu.com/p/504938832
        device->uverbs_cmd_mask = -> IB_USER_VERBS_CMD_ALLOC_MW... -> 设置命令掩码/比特位
    irdma_fill_device_info -> 填充设备信息,默认配置
        rf->gen_ops.register_qset = irdma_lan_register_qset;
            ice_add_rdma_qset(pf, &qset)
                ice_get_main_vsi
                ice_cfg_vsi_rdma
                    ice_cfg_vsi_qs
                        ice_sched_get_tc_node
                        ice_sched_cfg_vsi
                            ice_get_vsi_ctx
                            ice_sched_get_vsi_node
                            ...
                ice_ena_vsi_rdma_qset
                    ice_sched_get_free_qparent
        rf->gen_ops.unregister_qset = irdma_lan_unregister_qset
        rf->gen_ops.request_reset = irdma_request_reset
        rf->hw.hw_addr = pf->hw.hw_addr
        ...
    irdma_ctrl_init_hw -> 初始化硬件的控制部分
        irdma_setup_init_state
            irdma_save_msix_info
            rf->obj_mem.size = ALIGN(8192, IRDMA_HW_PAGE_SIZE) -> 以4096为上界对齐, 分配8KB
            rf->obj_mem.va = dma_alloc_coherent(rf->hw.device, rf->obj_mem.size, &rf->obj_mem.pa, GFP_KERNEL) -> 申请连续的大块内存(8KB)
            irdma_initialize_dev
                irdma_obj_aligned_mem -> irdma_obj_aligned_mem - 从设备分配的内存中获取对齐的内存，@rf：RDMA PCI函数@memptr：指向内存地址@size：所需的内存大小@mask：对齐内存的掩码获取请求大小的对齐内存并更新memptr 指向新对齐的内存成功则返回0，否则返回无内存错误 -> rf: RDMA PCI function
                    rf->obj_next.pa = memptr->pa + size
                irdma_obj_aligned_mem(rf, &mem, IRDMA_COMMIT_FPM_BUF_SIZE,
                info.bar0 = rf->hw.hw_addr
                irdma_sc_dev_init -> Initialize control part of device
                    dev->hw->hw_addr = info->bar0
                    irdma_sc_init_hw(dev) -> RDMA/irdma：实施硬件管理队列 OP，驱动程序将特权命令发布到硬件管理队列（控制 QP 或 CQP）以请求硬件的管理操作。 实现 CQP 的创建/销毁以及支持函数、数据结构和标头以处理不同的 CQP 命令
                        i40iw_init_hw(dev)
                            dev->hw_regs[i] = (u32 __iomem *)(i40iw_regs[i] + hw_addr)
                            dev->wqe_alloc_db = dev->hw_regs[IRDMA_WQEALLOC]
                            dev->hw_attrs.page_size_cap = SZ_4K | SZ_2M -> RDMA/irdma：不要为 x722 通告 1GB 页面大小，x722 不支持 1GB 页面大小，但 irdma 驱动程序错误地将 x722 设备的 1GB 页面大小支持通告给 ib_core，以计算在此 MR 上使用的最佳页面大小。 这可能会导致 MR 上的硬件计算出不正确的起始偏移量
                            dev->hw_attrs.max_qp_wr = I40IW_MAX_QP_WRS
                        or icrdma_init_hw(dev)
                            dev->hw_attrs.page_size_cap = SZ_4K | SZ_2M | SZ_1G;
                    irdma_wait_pe_ready(dev)
                        do {
                            statuscpu0 = readl(dev->hw_regs[IRDMA_GLPE_CPUSTATUS0])
                            mdelay(1000) -> mdelay是忙等待函数，在延迟过程中无法运行其他任务．这个延迟的时间是准确的．是需要等待多少时间就会真正等待多少时间
                        }
                    val = readl(dev->hw_regs[IRDMA_GLPCI_LBARCTRL])
                    dev->db_addr = dev->hw->hw_addr + (uintptr_t)dev->hw_regs[IRDMA_DB_ADDR_OFFSET]
        irdma_create_cqp(rf)
            cqp->sq.va = dma_alloc_coherent(dev->hw->device, cqp->sq.size,
            irdma_obj_aligned_mem(rf, &mem, sizeof(struct irdma_cqp_ctx),
            irdma_sc_cqp_init(dev->cqp, &cqp_init_info) -> Initialize buffers for a control Queue Pair
                irdma_get_encoded_wqe_size IRDMA_QUEUE_TYPE_CQP
                cqp->rocev2_rto_policy = info->rocev2_rto_policy
                memcpy(&cqp->dcqcn_params, &info->dcqcn_params, sizeof(cqp->dcqcn_params))
                IRDMA_RING_INIT(cqp->sq_ring, cqp->sq_size)
                INIT_LIST_HEAD(&cqp->dev->cqp_cmd_head)
                writel(0, cqp->dev->hw_regs[IRDMA_CQPTAIL]) -> db, register -> fpga, xt not call this db
                writel(0, cqp->dev->hw_regs[IRDMA_CQPDB])
                writel(0, cqp->dev->hw_regs[IRDMA_CCQPSTATUS])
            irdma_sc_cqp_create(dev->cqp, &maj_err, &min_err) -> create cqp during bringup
                cqp->sdbuf.size = ALIGN(IRDMA_UPDATE_SD_BUFF_SIZE * cqp->sq_size, IRDMA_SD_BUF_ALIGNMENT -> 128
                writel(p1, cqp->dev->hw_regs[IRDMA_CCQPHIGH])
                writel(p2, cqp->dev->hw_regs[IRDMA_CCQPLOW])
                udelay(cqp->dev->hw_attrs.max_sleep_count)
                readl(cqp->dev->hw_regs[IRDMA_CCQPSTATUS])
                cqp->process_cqp_sds = irdma_update_sds_noccq
            INIT_LIST_HEAD(&cqp->cqp_avail_reqs)
            INIT_LIST_HEAD(&cqp->cqp_pending_reqs)
            init_waitqueue_head(&cqp->cqp_requests[i].waitq) <- wake_up(&cqp_request->waitq)
        irdma_hmc_setup(rf)
            rf->sd_type = IRDMA_SD_TYPE_DIRECT
            irdma_cfg_fpm_val(&rf->sc_dev, qpcnt) -> 算法
                irdma_sc_init_iw_hmc(dev, dev->hmc_fn_id)
                    irdma_sc_query_fpm_val(dev->cqp, 0, hmc_info->hmc_fn_id, &query_fpm_mem, true, wait_type)
                        wqe = irdma_sc_cqp_get_next_send_wqe(cqp, scratch)
                        irdma_sc_cqp_post_sq(cqp)
                        irdma_cqp_poll_registers(cqp, tail,
                            irdma_get_cqp_reg_info(cqp, &val, &newtail, &error)
                            error = readl(cqp->dev->hw_regs[IRDMA_CQPERRCODES])
                    irdma_sc_parse_fpm_query_buf(dev, query_fpm_mem.va, hmc_info,
                        irdma_sc_decode_fpm_query(buf, 32, obj_info, IRDMA_HMC_IW_HTE)
                        obj_info[IRDMA_HMC_IW_APBVT_ENTRY].size = 8192
                sd_needed = irdma_est_sd(dev, hmc_info) -> 返回 HMC 的 SD 的近似数量
                    size += round_up(hmc_info->hmc_obj[IRDMA_HMC_IW_PBLE].cnt *
                qpwanted = min(qp_count, hmc_info->hmc_obj[IRDMA_HMC_IW_QP].max_cnt)
                while (irdma_q1_cnt(dev, hmc_info, qpwanted) > hmc_info->hmc_obj[IRDMA_HMC_IW_Q1].max_cnt)
                    roundup_pow_of_two
                cfg_fpm_value_gen_1
                or
                cfg_fpm_value_gen_2
                irdma_sc_cfg_iw_fpm(dev, dev->hmc_fn_id) -> warp
                    irdma_sc_parse_fpm_commit_buf
                        irdma_sc_decode_fpm_commit
                            obj_info[rsrc_idx].cnt = (u32)FIELD_GET(IRDMA_COMMIT_FPM_QPCNT, temp) -> 初始化时获取支持的QP数量规格
                hmc_info->sd_table.sd_entry = virt_mem.va
            irdma_create_hmc_objs(rf, true, rf->rdma_ver) -> 初始化时驱动会按照支持QP数量规格把HMC准备好 -> create all hmc objects for the device
                for (i = 0; i < IW_HMC_OBJ_TYPE_NUM; i++)
                    irdma_create_hmc_obj_type(dev, &info) -> irdma_sc_create_hmc_obj
	                    irdma_find_sd_index_limit(info->hmc_info, info->rsrc_type, info->start_idx, info->count, &sd_idx, &sd_lmt) -> 查找段描述符索引限制，@hmc_info：指向 HMC 配置信息结构的指针 @type：我们正在搜索的 HMC 资源类型 @idx：对象的起始索引 @cnt：我们尝试创建的对象数量 @ sd_idx：返回相关段描述符索引的指针 @sd_limit：返回段描述符最大数量的指针 该函数计算 irdma_hmc_rsrc_type 定义的资源的段描述符索引和索引限制
                        irdma_find_pd_index_limit(info->hmc_info, info->rsrc_type, info->start_idx, info->count, &pd_idx, &pd_lmt) -> finds page descriptor index limit
                        for (j = sd_idx; j < sd_lmt; j++)
                            irdma_add_sd_table_entry(dev->hw, info->hmc_info, j, info->entry_type, IRDMA_HMC_DIRECT_BP_SIZE) -> RDMA/irdma：添加 HMC 后备存储设置功能，HW 使用主机内存作为多个协议上下文对象和队列状态跟踪的后备存储。 主机内存缓存 (HMC) 是负责管理存储在主机内存中的这些对象的组件。 添加函数和数据结构来管理 HMC 为各种对象使用的支持页面的分配 -> Adds a segment descriptor to the table
                                allocate a 4K pd page or 2M backing page
                                dma_mem.size = ALIGN(alloc_len, IRDMA_HMC_PD_BP_BUF_ALIGNMENT)
                                dma_mem.va = dma_alloc_coherent(hw->device, dma_mem.size,
                                if (type == IRDMA_SD_TYPE_PAGED)
                                    vmem->size = sizeof(struct irdma_hmc_pd_entry) * 512
                                    vmem->va = kzalloc(vmem->size, GFP_KERNEL)
                                    sd_entry->u.pd_table.pd_entry = vmem->va
                                    memcpy(&sd_entry->u.pd_table.pd_page_addr, &dma_mem, sizeof(sd_entry->u.pd_table.pd_page_addr))
                                else
                                    memcpy(&sd_entry->u.bp.addr, &dma_mem, sizeof(sd_entry->u.bp.addr))
                            irdma_add_pd_table_entry -> Adds page descriptor to the specified table -> 将页面描述符添加到指定的表中，@dev：指向我们的设备结构的指针@hmc_info：指向HMC配置信息结构的指针@pd_index：要操作的页面描述符索引@rsrc_pg：如果不为NULL，则使用预分配的页面而不是分配 新的一个。 该函数： 1. 初始化 pd 条目 2. 在 pd_table 中添加 pd_entry 3. 在 irdma_hmc_pd_entry 结构中标记该条目有效 4. 将 pd_entry 的引用计数初始化为 1 假设： 1. pd 的内存应该固定，物理上连续并且 在 4K 边界上对齐并将内存归零。 2.大小应为4K
                                page->size = ALIGN(IRDMA_HMC_PAGED_BP_SIZE, IRDMA_HMC_PD_BP_BUF_ALIGNMENT)
                                page->va = dma_alloc_coherent(dev->hw->device, page->size, &page->pa,GFP_KERNEL)
                                memcpy(&pd_entry->bp.addr, page, sizeof(pd_entry->bp.addr))
                                pd_entry->bp.entry_type = IRDMA_SD_TYPE_PAGED
                                irdma_invalidate_pf_hmc_pd(dev, sd_idx, rel_pd_idx) -> 使 PF 硬件中的 pd 缓存无效
                                    writel(val, dev->hw_regs[IRDMA_PFHMC_PDINV])
                        irdma_hmc_finish_add_sd_reg(dev, info) -> irdma_hmc_sd_grp -> 为 cqp 设置 sd 条目组
                            for (i = sd_index; i < sd_index + sd_cnt; i++)
                                irdma_set_sd_entry(pa, i, sd_entry->entry_type,
                                or irdma_clr_sd_entry(i, sd_entry->entry_type,
                                ret_code = dev->cqp->process_cqp_sds(dev, &sdinfo)
        irdma_initialize_hw_rsrc -> 初始化硬件资源跟踪数组
            if (rf->rdma_ver != IRDMA_GEN_1)
                rf->allocated_ws_nodes = bitmap_zalloc(IRDMA_MAX_WS_NODES,
                set_bit(0, rf->allocated_ws_nodes)
            rsrc_size = irdma_calc_mem_rsrc_size(rf) -> 计算内存资源大小
                rsrc_size = sizeof(struct irdma_arp_entry) * rf->arp_table_size
                rsrc_size += sizeof(unsigned long) * BITS_TO_LONGS(rf->max_qp)
                ...
            rf->mem_rsrc = vzalloc(rsrc_size) -> 分配虚拟连续内存并用零填充
            rf->arp_table = (struct irdma_arp_entry *)rf->mem_rsrc
            irdma_set_hw_rsrc(rf) -> 按基址偏移和预留空间设置各物理资源(QP,CQ,MR,PD,AH,MCG,ARP,qp_table, cq_table)基地址
            rf->mr_stagmask = ~(((1 << mrdrvbits) - 1) << (32 - mrdrvbits))
        irdma_create_ccq -> 创建用于控制操作的完成队列
            ccq->shadow_area.size = sizeof(struct irdma_cq_shadow_area)
            ccq->mem_cq.va = dma_alloc_coherent
            info.num_elem = IW_CCQ_SIZE -> 2048
            irdma_sc_ccq_init(dev->ccq, &info)
                cq->cq_type = IRDMA_CQ_TYPE_CQP
                IRDMA_RING_INIT(cq->cq_uk.cq_ring, info->num_elem)
                cq->cq_uk.polarity = true -> 极性位/可反转/有效位
            irdma_sc_ccq_create(dev->ccq, 0, true, true)
                irdma_sc_cq_create(ccq, scratch, check_overflow, post_sq) -> 创建完成队列
                     irdma_sc_add_cq_ctx(ceq, cq) -> 为 ceq 添加 cq ctx 跟踪
                        ceq->reg_cq[ceq->reg_cq_size++] = cq
                     ...
                irdma_sc_ccq_create_done -> irdma_sc_poll_for_cqp_op_done(cqp, IRDMA_CQP_OP_CREATE_CQ, NULL) -> 等待 CQP SQ 中最后一次写入完成
                    while (1)
                        irdma_sc_ccq_get_cqe_info
                            polarity = (u8)FIELD_GET(IRDMA_CQ_VALID, temp)
                            IRDMA_RING_MOVE_HEAD ->  move the head for cq
                            IRDMA_RING_MOVE_TAIL ->  update cq tail in cq shadow memory also
                        udelay(cqp->dev->hw_attrs.max_sleep_count)
                ccq->dev->cqp->process_cqp_sds = irdma_cqp_sds_cmd
        irdma_setup_ceq_0 -> 创建CEQ 0及其中断资源 -> 为所有设备完成事件队列分配一个列表，创建ceq 0并配置其msix中断向量返回0，如果设置成功，否则返回错误
            num_ceqs = min(rf->msix_count, rf->sc_dev.hmc_fpm_misc.max_ceqs
            rf->ceqlist = kcalloc(num_ceqs, sizeof(*rf->ceqlist), GFP_KERNEL)
            irdma_create_ceq(rf, iwceq, 0, &rf->default_vsi) -> 创建完成事件队列
                irdma_sc_ceq_init(&iwceq->sc_ceq, &info)
                irdma_cqp_ceq_cmd(&rf->sc_dev, &iwceq->sc_ceq, IRDMA_OP_CEQ_CREATE)
                or irdma_sc_cceq_create(&iwceq->sc_ceq, 0)
            irdma_cfg_ceq_vector(rf, iwceq, 0, msix_vec) -> 为完成事件队列设置中断
                if (rf->msix_shared && !ceq_id)
                    tasklet_setup(&rf->dpc_tasklet, irdma_dpc)
                    request_irq(msix_vec->irq, irdma_irq_handler, 0,
                else
                    tasklet_setup(&iwceq->dpc_tasklet, irdma_ceq_dpc)
                        irdma_process_ceq(rf, iwceq)
                            do cq = irdma_sc_process_ceq(dev, sc_ceq)
                                ceq->polarity ^= 1
                                irdma_sc_cq_ack(cq)
                            queue_work(rf->cqp_cmpl_wq, &rf->cqp_cmpl_work)
                            irdma_puda_ce_handler(rf, cq)
                                do {
                                    irdma_puda_poll_cmpl(dev, cq, &compl_error)
                                        if (info.q_type == IRDMA_CQE_QTYPE_RQ)
                                            irdma_puda_poll_info(cq, &info)
                                                cqe = IRDMA_GET_CURRENT_CQ_ELEM(&cq->cq_uk)
                                                    (_cq)->cq_base[IRDMA_RING_CURRENT_HEAD((_cq)->cq_ring)].buf
                                                get_64bit_val(cqe, 24, &qword3)
                                                info->qp = (struct irdma_qp_uk *)(unsigned long)comp_ctx
                                                ...
                                            dma_sync_single_for_cpu -> 确保DMA缓冲区中的数据与物理内存中的数据同步。如果需要将数据从设备上读取到内存中，则应该使用 dma_sync_single_for_cpu()函数。如果需要将数据从内存中写入到设备上，则应该使用 dma_sync_single_for_device()函数
                                            irdma_puda_get_tcpip_info -> get tcpip info from puda buffer
                                                if (buf->vsi->dev->hw_attrs.uk_attrs.hw_rev == IRDMA_GEN_1)
                                                    irdma_gen1_puda_get_tcpip_info(info, buf)
                                                        if (ethh->h_proto == htons(0x8100))
                                                            buf->vlan_id = ntohs(((struct vlan_ethhdr *)ethh)->h_vlan_TCI) & VLAN_VID_MASK
                                                            ip6h = (struct ipv6hdr *)buf->iph
                                                buf->ipv4 = info->ipv4
                                                buf->seqnum = ntohl(tcph->seq)
                                                ether_addr_copy(buf->smac, info->smac)
                                            rsrc->receive(rsrc->vsi, buf) -> irdma_ieq_receive
                                                qp = irdma_ieq_get_qp(vsi->dev, buf)
                                                irdma_ieq_handle_exception(ieq, qp, buf)
                                                    irdma_ieq_check_first_buf(buf, fps)
                                                    irdma_send_ieq_ack(qp)
                                            irdma_ilq_putback_rcvbuf
                                            or irdma_puda_replenish_rq
                                                irdma_puda_get_bufpool
                                                    irdma_puda_get_listbuf
                                                irdma_puda_post_recvbuf
                                        else
                                            rsrc->xmit_complete(rsrc->vsi, buf -> irdma_ieq_tx_compl
                                                irdma_puda_ret_bufpool
                                                    list_add(&buf->list, &rsrc->bufpool)
                                            irdma_puda_send_buf
                                                irdma_puda_send
                                                    wqe = irdma_puda_get_next_send_wqe(&qp->qp_uk, &wqe_idx)
                                                    irdma_uk_qp_post_wr(&qp->qp_uk)
                                                        writel(qp->qp_id, qp->wqe_alloc_db)
                                    irdma_sc_ccq_arm(cq)
                                        writel(ccq->cq_uk.cq_id, ccq->dev->cq_arm_db)
                                }
                        irdma_ena_intr(&rf->sc_dev, iwceq->msix_idx) -> dev->irq_ops->irdma_en_irq(dev, msix_id) -> icrdma_ena_irq -> 启用中断
                            writel(val, dev->hw_regs[IRDMA_GLINT_DYN_CTL] + idx)
                    request_irq(msix_vec->irq, irdma_ceq_handler, 0,
                        tasklet_schedule(&iwceq->dpc_tasklet)
                cpumask_clear(&msix_vec->mask)
                cpumask_set_cpu(msix_vec->cpu_affinity, &msix_vec->mask)
                irq_update_affinity_hint(msix_vec->irq, &msix_vec->mask)
                rf->sc_dev.irq_ops->irdma_cfg_ceq(&rf->sc_dev, ceq_id, msix_vec->idx, true) -> icrdma_cfg_ceq
                    writel(reg_val, dev->hw_regs[IRDMA_GLINT_CEQCTL] + ceq_id)
            irdma_ena_intr(&rf->sc_dev, msix_vec->idx)
        INIT_WORK(&rf->cqp_cmpl_work, cqp_compl_worker) -> irdma_cqp_ce_handler
            wake_up(&cqp_request->waitq)
            or cqp_request->callback_fcn(cqp_request)
        irdma_sc_ccq_arm
    ice_get_qos_params
    irdma_fill_qos_info
        l2params->vsi_prio_type = qos_info->vport_priority_type
        l2params->tc_info[i].rel_bw = qos_info->tc_info[i].rel_bw
        memcpy(l2params->dscp_map, qos_info->dscp_map, sizeof(l2params->dscp_map))
    irdma_rt_init_hw -> 初始化硬件运行时, ILQ, IEQ, CEQs and PBLEs
        irdma_sc_vsi_init
        irdma_setup_cm_core
        irdma_vsi_stats_init
        do {
            if (!iwdev->roce_mode) -> 非RoCE模式
            irdma_initialize_ilq -> create iwarp local queue for cm
            irdma_initialize_ieq
                irdma_puda_create_rsrc
                    irdma_puda_qp_create
                        irdma_cqp_qp_create_cmd
                            cqp_info->cqp_cmd = IRDMA_OP_QP_CREATE
            irdma_setup_ceqs -> 管理设备 ceq 及其中断资源，@rf：RDMA PCI 函数 @vsi：此 CEQ 的 VSI 结构 为所有设备完成事件队列分配列表 创建 ceq 并配置其 msix 中断向量 如果 ceq 成功
                irdma_create_ceq
                irdma_cfg_ceq_vector
                irdma_ena_intr
            irdma_hmc_init_pble -> Initialize pble resources during module load
                pble_rsrc->fpm_base_addr = hmc_info->hmc_obj[IRDMA_HMC_IW_PBLE].base
                INIT_LIST_HEAD(&pble_rsrc->pinfo.clist)
                add_pble_prm(pble_rsrc)
            irdma_setup_aeq
                irdma_create_aeq
                irdma_cfg_aeq_vector
                irdma_ena_intr
            irdma_alloc_set_mac -> set up a mac address table entry
                irdma_alloc_local_mac_entry
                    cqp_info->cqp_cmd = IRDMA_OP_ALLOC_LOCAL_MAC_ENTRY
                irdma_add_local_mac_entry
                    cqp_info->cqp_cmd = IRDMA_OP_ADD_LOCAL_MAC_ENTRY
            irdma_add_ip -> add ip addresses
                irdma_add_ipv4_addr
                    ip_addr = ntohl(ifa->ifa_address)
                    irdma_manage_arp_cache(iwdev->rf, dev->dev_addr, &ip_addr, true, IRDMA_ARP_ADD) -> manage hw arp cache
                        arp_index = irdma_arp_table(rf, ip_addr, ipv4, mac_addr, action)
                        cqp_request = irdma_alloc_and_get_cqp_request(&rf->cqp, false)
                        cqp_info->cqp_cmd = IRDMA_OP_ADD_ARP_CACHE_ENTRY
                irdma_add_ipv6_addr -> 将IPv6地址添加到硬件ARP表中
                    idev = __in6_dev_get(ip_dev)
                    irdma_copy_ip_ntohl(local_ipaddr6, ifp->addr.in6_u.u6_addr32)
                        *dst++ = ntohl(*src++);
                        ...
            iwdev->cleanup_wq = alloc_workqueue("irdma-cleanup-wq",
            irdma_get_used_rsrc -> 确定内部使用的资源
                iwdev->rf->used_pds
                ...
            init_waitqueue_head
        }
        irdma_rt_deinit_hw(iwdev) -> clean up the irdma device resources -> 根据状态机清理设备资源
            switch (iwdev->init_state)
    irdma_ib_register_device
    ice_rdma_update_vsi_filter -> update main VSI filters for RDMA -> get ice eth api
        vsi = ice_find_vsi(pf, vsi_id)
        ice_cfg_rdma_fltr(&pf->hw, vsi->idx, enable) -> enable/disable RDMA filtering on VSI
            cached_ctx = ice_get_vsi_ctx(hw, vsi_handle)
            ctx->info.valid_sections = cpu_to_le16(ICE_AQ_VSI_PROP_Q_OPT_VALID)
            ice_update_vsi
                ice_aq_update_vsi -> Ice：扩展 VSI 句柄的使用第 1/2 部分，VSI 句柄只是驱动程序维护的一个数字，用于唯一标识 VSI。 VSI 句柄由硬件中的 VSI 编号支持。 当与硬件交互时，VSI句柄被转换成VSI编号。 在提交 0f9d5027a749（“ice：重构 VSI 分配、删除和重建流程”）中，引入了 VSI 句柄，但仅在创建和删除 VSI 时使用。 该补丁是两个补丁之一，这两个补丁扩展了 VSI 句柄在驱动程序其余部分的使用。 此外，在此补丁中，必须重构代码的某些部分才能正确使用 VSI 句柄
                    ice_fill_dflt_direct_cmd_desc
                    cmd->vsi_num = cpu_to_le16(vsi_ctx->vsi_num | ICE_AQ_VSI_IS_VALID)
                    status = ice_aq_send_cmd(hw, &desc, &vsi_ctx->info, -> send FW Admin Queue command to FW Admin Queue
                        ice_sq_send_cmd_retry
                            ice_sq_send_cmd -> send command to Control Queue (ATQ)
                                desc_on_ring = ICE_CTL_Q_DESC(cq->sq, cq->sq.next_to_use)
                                wr32(hw, cq->sq.tail, cq->sq.next_to_use)
                                ice_flush(hw)
                                udelay(5)
    auxiliary_set_drvdata




static const struct irdma_irq_ops icrdma_irq_ops = {
	.irdma_cfg_aeq = irdma_cfg_aeq,
	.irdma_cfg_ceq = icrdma_cfg_ceq,
	.irdma_dis_irq = icrdma_disable_irq,
	.irdma_en_irq = icrdma_ena_irq,
};


static struct class ib_class = {
    .name    = "infiniband",
    .dev_release = ib_device_release,
    .dev_uevent = ib_device_uevent,
    .ns_type = &net_ns_type_operations,
    .namespace = net_namespace,
};



iavf_register_client


drivers/net/ethernet/hisilicon/Makefile
net：添加海思网络子系统hnae框架支持，HNAE（海思网络加速引擎）是为海思网络加速引擎提供统一环形缓冲区接口的框架。 通过该接口，上层可以有意地充当以太网驱动程序、ODP驱动程序或其他服务驱动程序


capability:
pci_find_capability

read pcie config space of device:
u32 read_pci_config
    outl(0x80000000 | (bus<<16) | (slot<<11) | (func<<8) | offset, 0xcf8);



drivers/dma/dmatest.c
late_initcall(dmatest_init);


三星:
drivers/dma/pl330.c
pd->device_issue_pending = pl330_issue_pending;
dma_async_issue_pending
    device_issue_pending
xdev->common.device_issue_pending = xilinx_dma_issue_pending;
chan->start_transfer = xilinx_dma_start_transfer

struct dma_device

desc->txd.tx_submit = pl330_tx_submit;


module_amba_driver(pl330_driver);
dma_async_device_register


Xilinx media platform drivers
drivers/media/platform/xilinx/xilinx-dma.c
dmaengine_prep_interleaved_dma


dmaengine_prep_interleaved_dma
dmaengine_submit


https://www.kernel.org/doc/html/v4.9/media/kapi/v4l2-videobuf2.html
static const struct vb2_ops xvip_dma_queue_qops = {
    .queue_setup = xvip_dma_queue_setup,
    .buf_prepare = xvip_dma_buffer_prepare,
    .buf_queue = xvip_dma_buffer_queue,
    .wait_prepare = vb2_ops_wait_prepare,
    .wait_finish = vb2_ops_wait_finish,
    .start_streaming = xvip_dma_start_streaming,
    .stop_streaming = xvip_dma_stop_streaming,
};

xvip_dma_buffer_queue


static struct platform_driver xvip_composite_driver = {
    .driver = {
        .name = "xilinx-video",
        .of_match_table = xvip_composite_of_id_table,
    },
    .probe = xvip_composite_probe,
    .remove_new = xvip_composite_remove,
};

module_platform_driver(xvip_composite_driver);
xvip_graph_init
xvip_graph_dma_init
xvip_graph_dma_init_one
    xvip_dma_init
        ...
        dma->queue.ops = &xvip_dma_queue_qops;
        dma->dma = dma_request_chan(dma->xdev->dev, name);


https://github.com/Xilinx/linux-xlnx/tree/xilinx-v14.4



drivers/infiniband/core/ucma.c
static ssize_t (*ucma_cmd_table[])(struct ucma_file *file,
                   const char __user *inbuf,
                   int in_len, int out_len) = {
    [RDMA_USER_CM_CMD_CREATE_ID] 	 = ucma_create_id,
    [RDMA_USER_CM_CMD_DESTROY_ID]	 = ucma_destroy_id,
    [RDMA_USER_CM_CMD_BIND_IP]	 = ucma_bind_ip,
    [RDMA_USER_CM_CMD_RESOLVE_IP]	 = ucma_resolve_ip,
    [RDMA_USER_CM_CMD_RESOLVE_ROUTE] = ucma_resolve_route,
    [RDMA_USER_CM_CMD_QUERY_ROUTE]	 = ucma_query_route,
    [RDMA_USER_CM_CMD_CONNECT]	 = ucma_connect,
    [RDMA_USER_CM_CMD_LISTEN]	 = ucma_listen,
    [RDMA_USER_CM_CMD_ACCEPT]	 = ucma_accept,
    [RDMA_USER_CM_CMD_REJECT]	 = ucma_reject,
    [RDMA_USER_CM_CMD_DISCONNECT]	 = ucma_disconnect,
    [RDMA_USER_CM_CMD_INIT_QP_ATTR]	 = ucma_init_qp_attr,
    [RDMA_USER_CM_CMD_GET_EVENT]	 = ucma_get_event,
    [RDMA_USER_CM_CMD_GET_OPTION]	 = NULL,
    [RDMA_USER_CM_CMD_SET_OPTION]	 = ucma_set_option,
    [RDMA_USER_CM_CMD_NOTIFY]	 = ucma_notify,
    [RDMA_USER_CM_CMD_JOIN_IP_MCAST] = ucma_join_ip_multicast,
    [RDMA_USER_CM_CMD_LEAVE_MCAST]	 = ucma_leave_multicast,
    [RDMA_USER_CM_CMD_MIGRATE_ID]	 = ucma_migrate_id,
    [RDMA_USER_CM_CMD_QUERY]	 = ucma_query,
    [RDMA_USER_CM_CMD_BIND]		 = ucma_bind,
    [RDMA_USER_CM_CMD_RESOLVE_ADDR]	 = ucma_resolve_addr,
    [RDMA_USER_CM_CMD_JOIN_MCAST]	 = ucma_join_multicast
};

UCMA_CMD_CONNECT -> static ssize_t (*ucma_cmd_table[]) -> static ssize_t ucma_connect
    copy_from_user
    ucma_get_ctx_dev
    ucma_copy_conn_param -> RDMA/cma：为AF_IB设置qkey，允许用户在使用AF_IB时指定qkey。 qkey 被添加到 struct rdma_ucm_conn_param 中代替保留字段，但为了向后兼容，仅当关联的 rdma_cm_id 使用 AF_IB 时才可访问
        ...
        dst->qkey = (id->route.addr.src_addr.ss_family == AF_IB) ? src->qkey : 0;
    rdma_connect_ece -> RDMA/ucma：扩展ucma_connect以接收ECE参数，CMID的主动方通过librdmacm的rdma_connect()和内核的ucma_connect()发起连接。 扩展 UCMA 接口来处理这些新参数
        rdma_connect(id, conn_param) -> rdma_connect_locked
            cma_comp_exch(id_priv, RDMA_CM_ROUTE_RESOLVED, RDMA_CM_CONNECT)
            rdma_cap_ib_cm(id->device, id->port_num) -> rdma_cap_ib_cm - 检查设备端口是否具有 Infiniband Communication Manager 功能。 @device：要检查的设备 @port_num：要检查的端口号 InfiniBand 通信管理器是通过通用服务接口 (GSI) 访问的许多预定义通用服务代理 (GSA) 之一。 它的作用是促进节点之间连接的建立以及已建立的连接的其他管理相关任务。 返回：如果端口支持 IB CM，则返回 true（但这并不能保证 CM 实际正在运行）
                RDMA_CORE_CAP_IB_CM
            if (id->qp_type == IB_QPT_UD) -> cma_resolve_ib_udp -> RDMA/cma：添加对 RDMA_PS_UDP 的支持，允许通过 rdma_cm 使用 UD QP，以便为使用 SIDR 解析数据报消息的 IB 地址提供地址转换服务
            or cma_connect_ib
                check_add_overflow
                ib_create_cm_id(id_priv->id.device, cma_ib_handler, id_priv)
                    cm_alloc_id_priv -> RDMA/cm：简化建立监听cm_id
                        RB_CLEAR_NODE(&cm_id_priv->service_node) -> rb_tree
                        init_completion(&cm_id_priv->comp)
                        xa_alloc_cyclic -> 在 XArray 中找到存储此条目的位置
                trace_cm_send_req
                ib_send_cm_req
                    msg->context[1] = (void *)(unsigned long)IB_CM_REQ_SENT
                    ib_post_send_mad -> [IB] 修复 MAD 层 DMA 映射，以避免在映射后触及数据缓冲区。MAD 层在 DMA 映射完成后触及用于发送的数据缓冲区，从而违反了 DMA API。 这会导致非缓存一致性架构出现问题，因为执行 DMA 的设备不会看到仅存在于 CPU 缓存中的有效负载缓冲区的更新。 通过让所有 MAD 使用者使用 ib_create_send_mad() 分配其发送缓冲区，并将 DMA 映射移动到 MAD 层，以便可以在调用 send 之前（以及 MAD 层对发送缓冲区进行任何修改之后）完成此操作，可以解决此问题。 在非缓存一致性 PowerPC 440SPe 系统上进行测试
                        ib_mad_enforce_security -> IB/核心：在管理数据报上强制执行安全性，在创建和销毁 MAD 代理时分配和释放安全上下文。 该上下文用于控制对 PKey 的访问以及发送和接收 SMP。 发送或接收 MAD 时，检查代理是否有权访问端口子网前缀的 PKey。 在 SMI QP 的 MAD 和监听代理注册期间，检查调用进程是否有权访问管理子网并向 LSM 注册回调以获取策略更改通知。 当发生策略更改通知时，重新检查权限并设置一个标志，指示允许发送和接收 SMP。 发送和接收 MAD 时，如果代理位于 SMI QP 上，请检查代理是否有权访问 SMI。 由于安全策略可以更改，因此在创建代理时可能允许许可，但不再允许
                            rdma_protocol_ib
                            ib_security_pkey_access
                        ib_is_mad_class_rmpp
                        handle_outgoing_dr_smp
                        ib_mad_kernel_rmpp_agent
                        ib_send_rmpp_mad
                        ib_send_mad
                            ib_dma_map_single
                                ib_uses_virt_dma
                                dma_map_single
                            ib_post_send
                                .post_send = mlx5_ib_post_send_nodrain,
            or cma_connect_iw
    ucma_put_ctx



mlx5_ib_post_send_nodrain -> mlx5_ib_post_send
    begin_wqe
    ...



cm状态机:
enum rdma_cm_state {
    RDMA_CM_IDLE,
    RDMA_CM_ADDR_QUERY,
    RDMA_CM_ADDR_RESOLVED,
    RDMA_CM_ROUTE_QUERY,
    RDMA_CM_ROUTE_RESOLVED,
    RDMA_CM_CONNECT,
    RDMA_CM_DISCONNECT,
    RDMA_CM_ADDR_BOUND,
    RDMA_CM_LISTEN,
    RDMA_CM_DEVICE_REMOVAL,
    RDMA_CM_DESTROYING
};


cma_ib_handler
switch (ib_event->event)
case IB_CM_REP_RECEIVED
    ib_send_cm_mra(cm_id, CMA_CM_MRA_SETTING, NULL, 0) -> IB/cma：为回复消息发送MRA，RDMA_CM的当前实现仅针对请求消息发送MRA（消息接收确认），而不针对响应消息发送MRA。 因此，连接的缓慢主动方可能会在延迟太长的情况下向被动方发送就绪消息，而被动方无法等待。 该补丁在收到响应消息时添加了对 ib_send_cm_mra() 的调用，从而告诉对方将服务超时修改为更大的值，是之前的 16 倍。 与请求情况一样，仅当重复响应到达时才会发送用于回复的 MRA
        ...


大页:
配置内核大页:
echo 16 >/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages



mm/hugetlb.c
free_hugepages



const struct file_operations hugetlbfs_file_operations = {
    .read_iter		= hugetlbfs_read_iter,
    .mmap			= hugetlbfs_file_mmap,
    .fsync			= noop_fsync,
    .get_unmapped_area	= hugetlb_get_unmapped_area,
    .llseek			= default_llseek,
    .fallocate		= hugetlbfs_fallocate,
};




ibv_create_qp -> IB_USER_VERBS_CMD_CREATE_QP -> static int ib_uverbs_create_qp
    ...
    uobj_get_obj_read
    attr.event_handler = ib_uverbs_qp_event_handler
    ib_create_qp_user
        create_qp
            rdma_zalloc_drv_obj_numa
            rdma_restrack_new(&qp->res, RDMA_RESTRACK_QP)
             dev->ops.create_qp(qp, attr, udata) -> .create_qp = irdma_create_qp,
                ...
             ib_create_qp_security
             rdma_restrack_add(&qp->res)
        create_xrc_qp_user
    ib_qp_usecnt_inc
    uverbs_response





l2b:
include/linux/byteorder/generic.h
cpu_to_be64 -> #define cpu_to_be64 __cpu_to_be64




samples/trace_events
samples/trace_events/trace-events-sample.c




rdma version: 5.4.18





struct bundle_priv
IB/uverbs：为 uverbs_attr_bundle 提供实现私有内存，这已经作为匿名“ctx”结构存在，但这并不是真正有用的形式。 将此结构提升到bundle_priv并重新设计内部内容以使用它。 将一堆处理内部状态移入 priv 并减少函数参数的过度使用



强制实现的函数:
static void ib_device_check_mandatory(struct ib_device *device)
{
#define IB_MANDATORY_FUNC(x) { offsetof(struct ib_device_ops, x), #x }
	static const struct {
		size_t offset;
		char  *name;
	} mandatory_table[] = {
		IB_MANDATORY_FUNC(query_device),
		IB_MANDATORY_FUNC(query_port),
		IB_MANDATORY_FUNC(alloc_pd),
		IB_MANDATORY_FUNC(dealloc_pd),
		IB_MANDATORY_FUNC(create_qp),
		IB_MANDATORY_FUNC(modify_qp),
		IB_MANDATORY_FUNC(destroy_qp),
		IB_MANDATORY_FUNC(post_send),
		IB_MANDATORY_FUNC(post_recv),
		IB_MANDATORY_FUNC(create_cq),
		IB_MANDATORY_FUNC(destroy_cq),
		IB_MANDATORY_FUNC(poll_cq),
		IB_MANDATORY_FUNC(req_notify_cq),
		IB_MANDATORY_FUNC(get_dma_mr),
		IB_MANDATORY_FUNC(reg_user_mr),
		IB_MANDATORY_FUNC(dereg_mr),
		IB_MANDATORY_FUNC(get_port_immutable)
	};




为该端口需要由内核支持的各种功能定义位
/* Define bits for the various functionality this port needs to be supported by
 * the core.
 */
/* Management                           0x00000FFF */
#define RDMA_CORE_CAP_IB_MAD            0x00000001
#define RDMA_CORE_CAP_IB_SMI            0x00000002
#define RDMA_CORE_CAP_IB_CM             0x00000004
#define RDMA_CORE_CAP_IW_CM             0x00000008
#define RDMA_CORE_CAP_IB_SA             0x00000010
#define RDMA_CORE_CAP_OPA_MAD           0x00000020

/* Address format                       0x000FF000 */
#define RDMA_CORE_CAP_AF_IB             0x00001000
#define RDMA_CORE_CAP_ETH_AH            0x00002000
#define RDMA_CORE_CAP_OPA_AH            0x00004000
#define RDMA_CORE_CAP_IB_GRH_REQUIRED   0x00008000

/* Protocol                             0xFFF00000 */
#define RDMA_CORE_CAP_PROT_IB           0x00100000
#define RDMA_CORE_CAP_PROT_ROCE         0x00200000
#define RDMA_CORE_CAP_PROT_IWARP        0x00400000
#define RDMA_CORE_CAP_PROT_ROCE_UDP_ENCAP 0x00800000
#define RDMA_CORE_CAP_PROT_RAW_PACKET   0x01000000
#define RDMA_CORE_CAP_PROT_USNIC        0x02000000


iw40


static int irdma_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)





.mmap = mlx5_ib_mmap,


mmap
SYSCALL_DEFINE6(mmap_pgoff, unsigned long, addr, unsigned long, len,
    ksys_mmap_pgoff
        vm_mmap_pgoff
            do_mmap
                addr = get_unmapped_area(file, addr, len, pgoff, flags)
                switch (flags & MAP_TYPE)
                mmap_region
                    count_vma_pages_range
                    call_mmap
                        file->f_op->mmap(file, vma) -> or filemap_fault -> or xtrdma_mmap by cmd_fd fs
                    khugepaged_enter_vma



build kernel, https://zhuanlan.zhihu.com/p/105069730
apt-get install libncurses5-dev libssl-dev bison flex libelf-dev gcc make openssl libc6-dev -y

qemu:
apt-get install qemu -y
apt-get update
apt install qemu-kvm virt-manager virtinst libvirt-clients bridge-utils libvirt-daemon-system -y
apt install dwarves
buid:
gcc --static -o helloworld main.c
echo helloworld | cpio -o --format=newc > rootfs


此时将断点设在 init/main.c 中的start_kernel函数中，然后Qemu 开启GDB调试，vscode start debug即可开始调试内核

using make menuconfig it's going to be under "Kernel hacking" -> "Compile-time checks and compiler options" -> "Compiler a kernel with debug info"


source code:
wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.4.18.tar.gz


set key to ""
CONFIG_SYSTEM_TRUSTED_KEYS
CONFIG_SYSTEM_REVOCATION_KEYS

[iproute2-next,4/8] rdma：添加 rdma 统计计数器每端口自动模式支持，通过每 QP 统计计数器支持，用户可以监控特定的 QP 类别，这些类别与动态分配的计数器绑定/解除绑定 /解除分配。 在每端口“自动”模式下，QP 根据通用标准自动绑定到计数器。 例如，每个“类型”（qp 类型）方案，其中每个进程中所有具有相同 qp 类型的 QP 都会自动绑定到单个计数器。 目前仅支持“type”（qp 类型）。 示例: $ rdma statistic qp set link mlx5_2/1 auto type on $ rdma statistic qp set link mlx5_2/1 auto off, https://patchwork.kernel.org/project/linux-rdma/patch/20190410112121.6790-5-leon@kernel.org/



SET_PORT_SNIFFER



irdma register: -> RDMA/irdma：实施硬件管理队列 OP，驱动程序将特权命令发布到硬件管理队列（控制 QP 或 CQP）以请求硬件的管理操作。 实现 CQP 的创建/销毁以及支持函数、数据结构和标头以处理不同的 CQP 命令
enum irdma_registers {
	IRDMA_CQPTAIL,
	IRDMA_CQPDB,
	IRDMA_CCQPSTATUS,
	IRDMA_CCQPHIGH,
	IRDMA_CCQPLOW,
	IRDMA_CQARM,
	IRDMA_CQACK,
	IRDMA_AEQALLOC,
	IRDMA_CQPERRCODES,
	IRDMA_WQEALLOC,
	IRDMA_GLINT_DYN_CTL,
	IRDMA_DB_ADDR_OFFSET,
	IRDMA_GLPCI_LBARCTRL,
	IRDMA_GLPE_CPUSTATUS0,
	IRDMA_GLPE_CPUSTATUS1,
	IRDMA_GLPE_CPUSTATUS2,
	IRDMA_PFINT_AEQCTL,
	IRDMA_GLINT_CEQCTL,
	IRDMA_VSIQF_PE_CTL1,
	IRDMA_PFHMC_PDINV,
	IRDMA_GLHMC_VFPDINV,
	IRDMA_GLPE_CRITERR,
	IRDMA_GLINT_RATE,
	IRDMA_MAX_REGS, /* Must be last entry */
};



get_user_pages_fast:
进行参数检查，确保传入的gup_flags是合法的组合。
如果设置了FOLL_PIN标记，将当前进程的内存管理结构中的has_pinned原子变量设为1。
如果没有设置FOLL_FAST_ONLY标记，使用might_lock_read宏提示可能会对mmap_lock读锁进行加锁。
计算起始地址、结束地址和地址范围长度，确保它们是有效的。
禁用中断，阻止页面表页面在操作期间被释放。
如果启用了CONFIG_HAVE_FAST_GUP配置，并且允许快速GUP（Get User Pages）操作，则调用gup_pgd_range函数获取页面，将获取到的页面数量存储在nr_pinned变量中。
如果没有获取到所有请求的页面并且没有设置FOLL_FAST_ONLY标记，则尝试使用__gup_longterm_unlocked函数获取剩余的页面。
根据已获取页面的数量和剩余页面尝试的结果，返回最终结果。




rxe:
int rxe_mr_init_user
    rxe_mr_init
    xa_init -> struct xarray		page_list
    ib_umem_get
    rxe_mr_fill_pages_from_sgt
        __sg_page_iter_start
        __sg_page_iter_next
        while
            sg_page_iter_page
            xas_store
            xas_next


vaddr = page_address(sg_page_iter_page(&sg_iter))
page_address( )宏的功能是获得物理页的逻辑地址, 根据给定的struct page 结构体返回该物理页面的内核起始虚拟地址
buf->addr = (uintptr_t)vaddr


#define __va(x)			((void *)((unsigned long)(x)+PAGE_OFFSET))
在x86_64等64位架构中，因为内核虚拟空间较大，所以直接把所有物理内存直接线性映射到内核虚拟地址当中，物理地址和内核虚拟地址仅仅一个PAGE_OFFSET的偏移, __va() 宏用于将给定的物理地址转换为对应的内核虚拟地址


ibv_create_flow -> IB_USER_VERBS_EX_CMD_CREATE_FLOW -> ib_uverbs_ex_create_flow
uverbs_request_start
rdma_is_port_valid
uobj_get_obj_read
flow_resources_alloc
    kcalloc
kern_spec_to_ib_spec
flow_id = qp->device->ops.create_flow(qp, flow_attr, -> mlx5_ib_create_flow
    get_flow_table
        mlx5_eswitch_get_encap_mode
    _create_flow_rule
        parse_flow_attr
        flow_is_multicast_only
            ipv4_is_multicast -> 用于检查地址是否是多播地址，即224.x.x.x的D类地址 -> static inline bool ipv4_is_multicast(__be32 addr) -> return (addr & htonl(0xf0000000)) == htonl(0xe0000000)
            is_multicast_ether_addr -> 如果一个流可以同时捕获组播和单播数据包，则它不会落入组播流转向表中，并且该规则可以窃取其他组播数据包
                return 0x01 & (a >> ((sizeof(a) * 8) - 8));
        set_underlay_qp
        mlx5_ib_set_rule_source_port
        get_match_criteria_enable
        mlx5_ib_flow_counters_set_data
        mlx5_add_flow_rules -> EXPORT_SYMBOL(mlx5_add_flow_rules)
            _mlx5_add_flow_rules
    create_leftovers_rule
        create_flow_rule
    create_sniffer_rule
        .type = IB_FLOW_ATTR_SNIFFER
        create_flow_rule(dev, ft_rx, &flow_attr, dst)
ib_set_flow
rdma_lookup_put_uobject
uobj_finalize_uobj_create
uverbs_response

qemu-system-x86_64 -enable-kvm -m 512 -smp 2 -boot order=c -hda ubuntu14.04.img -vnc :1 -monitor stdio
--graphics vnc,port=5900,listen=0.0.0.0


https://blog.csdn.net/qq_26907291/article/details/129403678?spm=1001.2014.3001.5502
qemu-system-x86_64 -m 2048 \
-drive file=ubuntu22.04.img,if=virtio \
-nic user,hostfwd=tcp::5557-:22 \
-vnc :1 -monitor stdio

# vnc可以查看开机情况，ssh可以登录VM与host主机共享网络
ssh -p 5557 username@localhost

# 往VM主机发送文件
scp -P 5557 filename username@localhost:/directory

# sharefolder方案，需要qemu安装的时候打开--enable-virtfs, # 开启virtfs方便后续切换vm的kernel版本
# host端启动qemu
qemu-system-x86_64 -m 2048 \
-drive file=ubuntu22.04.img,if=virtio \
-nic user,hostfwd=tcp::5557-:22 \
-fsdev local,security_model=passthrough,id=fsdev0,path=/host_directory \
-device virtio-9p-pci,fsdev=fsdev0,mount_tag=kernelcode \
-vnc :1 -monitor stdio

# 共享文件夹靠id和tag标识，可以加载多个
# VM启动后加载共享文件夹
mount -t 9p -o trans=virtio kernelcode /vm_directory

# 创建镜像
qemu-img create -f qcow2 ubuntu22.04.img 16G
# 安装系统
qemu-system-x86_64 -m 1024 -enable-kvm \
-drive if=virtio,file=ubuntu22.04.img,cache=none \
-cdrom ubuntu-22.04-live-server-amd64.iso \
-vnc :1


# 注意自己改路径
qemu-system-x86_64 -m 2048 -enable-kvm -cpu host \
-smp cores=16,sockets=1 \
-drive file=ubuntu-22.04.img,if=virtio \
-nic user,hostfwd=tcp::5557-:22 \
-fsdev local,security_model=passthrough,id=fsdev0,path=/kernel_code_directory \
-device virtio-9p-pci,fsdev=fsdev0,mount_tag=kernelmake \
-S -s \
-vnc :1 -monitor stdio


mounse, pointer, 
qemu/build/qemu-system-aarch64 \
-m 1024 \
-M raspi3b \
-kernel $TMP/boot/kernel8.img \
-dtb "$TMP/boot/bcm2710-rpi-3-b-plus.dtb" \
-drive file="$IMAGE_FILE",if=sd,format=raw \
-append "console=ttyAMA0 root=/dev/mmcblk0p2 rw rootwait rootfstype=ext4" \
-device usb-net,netdev=net0 \
-netdev user,id=net0,hostfwd=tcp::5555-:22 \
-device usb-mouse -device usb-tablet -device usb-kbd

-device nec-usb-xhci,id=usb,bus=pci.0,addr=0x4 for usb 3.0 or
-device usb-ehci,id=usb,bus=pci.0,addr=0x4 for usb 2.
Then you can pass -device usb-tablet.


qemu-system-x86_64 -m 2048 \
-drive file=ubuntu22.04.img,if=virtio \
-nic user,hostfwd=tcp::5557-:22 \
-vnc :1 -monitor stdio

# vnc可以查看开机情况，ssh可以登录VM与host主机共享网络
ssh -p 5557 username@localhost

# 往VM主机发送文件
scp -P 5557 filename username@localhost:/directory

# sharefolder方案，需要qemu安装的时候打开--enable-virtfs
# host端启动qemu
qemu-system-x86_64 -m 2048 \
-drive file=ubuntu22.04.img,if=virtio \
-nic user,hostfwd=tcp::5557-:22 \
-fsdev local,security_model=passthrough,id=fsdev0,path=/host_directory \
-device virtio-9p-pci,fsdev=fsdev0,mount_tag=kernelcode \
-vnc :1 -monitor stdio

# 共享文件夹靠id和tag标识，可以加载多个
# VM启动后加载共享文件夹
mount -t 9p -o trans=virtio kernelcode /vm_directory


enable-kvm
debug guest: qemu,
#ifdef KVM_CAP_SET_GUEST_DEBUG
    kvm_has_guest_debug =
        (kvm_check_extension(s, KVM_CAP_SET_GUEST_DEBUG) > 0);
            kvm_ioctl(s, KVM_CHECK_EXTENSION, extension)
KVM_CAP_SET_GUEST_DEBUG


problem: qemu-system-x86_64 -m 1024 -enable-kvm -S -s ...启动虚机的时候, 提示不支持kvm debug
查阅代码发现, 当前内核默认支持debug guest, 咱们使用的centos7, 内核是3.10的, 太老旧了

kvm_init
    kmem_cache_create_usercopy(const char *name,
    for_each_possible_cpu alloc_cpumask_var_node
    kvm_irqfd_init -> KVM：在架构硬件设置后初始化 IRQ FD，将 KVM 的 IRQ FD 工作队列的初始化移至架构硬件设置下方，作为巩固架构“init”和“硬件设置”的一步，并最终完全放弃挂钩。 不依赖于在硬件设置之前创建的工作队列，工作队列仅在销毁虚拟机时使用，即只需要在 /dev/kvm 暴露给用户空间之前创建。 将工作队列的销毁移到 arch 钩子之前以保持对称性，这样 arch 代码就可以远离钩子而不必担心顺序更改。 重写有关 kvm_irqfd_init() 需要在 kvm_arch_init() 之后出现的注释，以指出 kvm_arch_init() 必须在常见 KVM 执行任何操作之前出现，因为 x86 非常巧妙地依赖该行为来处理对 kvm_init() 的多次调用，例如 如果用户空间尝试加载 kvm_amd.ko 和 kvm_intel.ko。 使用 FIXME 标记代码，因为 x86 的微妙要求很粗暴，并且调用 arch 回调作为仅从 arch 代码调用的帮助程序中的第一个操作是愚蠢的
    kvm_async_pf_init
    kvm_init_debug
        debugfs_create_dir("kvm", NULL)
        debugfs_create_file
    kvm_vfio_ops_init
         kvm_register_device_ops(&kvm_vfio_ops, KVM_DEV_TYPE_VFIO)
    kvm_gmem_init -> KVM：为特定于客户的后备内存添加 KVM_CREATE_GUEST_MEMFD ioctl()，引入 ioctl()、KVM_CREATE_GUEST_MEMFD，以允许创建与特定 KVM 虚拟机绑定的基于文件的内存，其主要目的是为客户内存提供服务。 客户优先内存子系统允许进行优化和增强，而这些优化和增强在通用内存子系统中实现/支持是笨拙或完全不可行的。 使用 guest_memfd，来宾保护和映射大小与主机用户空间映射完全解耦。 例如。 KVM 目前不支持将内存映射为在来宾中可写，而不在主机用户空间中也可写，因为 KVM 的 ABI 使用 VMA 保护来定义允许来宾保护。 用户空间可以通过建立两个映射来弥补这一点，一个是客户可写的映射，一个是自身可读的映射，但这在多个方面都不是最佳的。 类似地，KVM 目前要求来宾映射大小是主机用户空间映射大小的严格子集，例如 KVM 不支持创建 1GiB 访客映射，除非用户空间也有 1GiB 访客映射。 解耦映射大小将允许用户空间仅精确映射所需的内容，而不会影响来宾性能，例如 加强对来宾内存的无意访问。 解耦来宾和用户空间映射还可以为 HugeTLB 的高粒度映射提供更清晰的替代方案，而 HugeTLB 已经陷入了僵局，并且不太可能被合并。 客户优先的内存子系统还为诸如专用内存池（用于硬件虚拟机切片）和消除“结构页面”（用于用户空间永远不需要 mmap() 客户内存的卸载设置）等提供了更清晰的视线。 。 更直接地说，能够将内存映射到 KVM 来宾而不将所述内存映射到主机对于机密 VM（CoCo VM）（guest_memfd 的初始用例）至关重要。 虽然 AMD 的 SEV 和英特尔的 TDX 通过使用不受信任的主机无法使用的密钥加密来宾内存来防止不受信任的软件读取来宾私有数据，但受保护的 KVM (pKVM) 等项目*无需*依赖内存加密即可提供机密性和完整性 。 对于 SEV-SNP 和 TDX，访问来宾私有内存对于主机来说可能是致命的，即无论硬件行为如何，KVM 都必须阻止主机用户空间访问来宾内存。 支持 CoCo VM 的尝试#1 是添加一个 VMA 标志来将内存标记为只能由 KVM（或类似的启发式内核子系统）映射。 这种方法被放弃主要是因为它需要使用 PROT_NONE 来玩游戏以防止用户空间访问来宾内存。 尝试 #2 是篡夺 PG_hwpoison 以阻止主机将来宾私有内存映射到用户空间，但该方法无法满足基于软件的 CoCo VM 的几个要求，例如 pKVM，因为内核无法轻松强制执行 1:1 的页面：来宾关联，更不用说 1:1 的 pfn:gfn 映射了。 并且使用 PG_hwpoison 不适用于不受“struct page”支持的内存，例如 如果设备获得向访客公开加密内存区域的支持。 尝试 #3 是扩展 memfd() 系统调用并包装 shmem 以提供基于文件的专用来宾内存。 在 Hugh Dickins 和 Christian Brauner（以及其他人）的反馈导致其消亡之前，这种方法已经发展到了 v10。 Hugh 的反对意见是，搭载 shmem 对于 KVM 的用例来说没有任何意义，因为 KVM 实际上并不“想要”shmem 提供的功能。 IE。 KVM 使用 memfd() 和 shmem 来避免直接管理内存，并不是因为 memfd() 和 shmem 是最佳解决方案，例如 shmem 中的读/写/mmap 之类的东西很重。 Christian 指出了实现部分覆盖（仅包裹 shmem 的一些）的缺陷，例如 戳 inode_operations 或 super_operations 会显示 shmem 内容，但 address_space_operations 和 file_operations 会显示 KVM 的覆盖。 Christian 重重地解释了一下，建议 KVM 不要再偷懒了，创建一个合适的 API
    kvm_chardev_ops.owner = module
    r = misc_register(&kvm_dev)


static struct file_operations kvm_chardev_ops = {
	.unlocked_ioctl = kvm_dev_ioctl,
	.compat_ioctl   = kvm_dev_ioctl,
	.llseek		= noop_llseek,
};

static struct miscdevice kvm_dev = {
	KVM_MINOR,
	"kvm",
	&kvm_chardev_ops,
};



kvm debug guest:
KVM_CAP_SET_GUEST_DEBUG


tools/testing/selftests/kvm/x86_64/debug_regs.c
    int main(void)
    TEST_REQUIRE(kvm_has_cap(KVM_CAP_SET_GUEST_DEBUG)) -> unsigned int kvm_check_cap(long cap)
        open_kvm_dev_path_or_exit
        __kvm_ioctl(kvm_fd, KVM_CHECK_EXTENSION, (void *)cap) -> kvm_do_ioctl -> ioctl(fd, cmd, arg)
            ...
            kvm_dev_ioctl
                kvm_vm_ioctl_check_extension_generic
                    kvm_vm_ioctl_check_extension
                        case KVM_CAP_SET_GUEST_DEBUG -> KVM：X86：正确声明 KVM_CAP_SET_GUEST_DEBUG，x86 应该支持 KVM_CAP_SET_GUEST_DEBUG，但未声明为受支持。 我的大胆猜测是，像 QEMU 这样的用户空间正在使用“#ifdef KVM_CAP_SET_GUEST_DEBUG”来检查功能，但这可能是错误的，因为编译主机可能不是运行时主机。 用户空间可能仍然希望保留旧的“#ifdef”，但不要破坏旧内核上的来宾调试
                            r = 1
        return (unsigned int)ret
    vm_create_with_one_vcpu
    vcpu_guest_debug_set
    vcpu_run
    vcpu_skip_insn
    cmd = get_ucall(vcpu, &uc)
    kvm_vm_free



debug module:
cat /sys/module/{这个modulede的名字}/sections/.text
cat /sys/module/{这个modulede的名字}/sections/.data
cat /sys/module/{这个modulede的名字}/sections/.bss
获取三个地址，在gdb里输入
add-symbol-file {这个module}.ko <text_addr> -s .data <data_addr> -s .bss <bss_addr>


~/.gdbinit file added
add-auto-load-safe-path path/to/linux/kernel/tree/scripts/gdb/vmlinux-gdb.py
apropos lx
lx-symbol
                        
原文链接：https://blog.csdn.net/qq_26907291/article/details/129403236


info proc map


禁用 CONFIG_RANDOMIZE_BASE
开启 CONFIG_GDB_SCRIPTS
开启 CONFIG_DEBUG_INFO_REDUCED
开启 CONFIG_FRAME_POINTER



apt-get install libncurses5-dev libssl-dev bison flex libelf-dev gcc make openssl libc6-dev -y

make menuconfig

it's going to be under "Kernel hacking" -> "Compile-time checks and compiler options" -> "Compiler a kernel with debug info"


source code:
wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.4.18.tar.gz


set key to ""
CONFIG_SYSTEM_TRUSTED_KEYS
CONFIG_SYSTEM_REVOCATION_KEYS


apt install qemu qemu-system qemu-kvm -y

Failed to generate BTF for vmlinux
Try to disable CONFIG_DEBUG_INFO_BTF
make: *** [Makefile:1077: vmlinux] Error 1

apt install dwarves

touch main.c
#include <stdio>
int main()
{
    printf("hello world!");
    printf("hello world!");
    printf("hello world!");
    printf("hello world!");
    fflush(stdout);
    while(1);
    return 0;
}

gcc --static -o helloworld main.c
echo helloworld | cpio -o --format=newc > rootfs

qemu-system-x86_64 \
    -kernel ./arch/x86/boot/bzImage \
    -initrd ./rootfs \
    -append "root=/dev/ram rdinit=/helloworld"

qemu-system-x86_64  \
 -kernel ./arch/x86/boot/bzImage  \
 -initrd ./rootfs  \
 -append "root=/dev/ram rdinit=/helloworld" \
 -smp 2  \
 -s -S --nographic


qemu-system-x86_64 -s -S -kernel /root/project/linux-5.4.18/arch/x86/boot/bzImage -initrd /root/project/linux-5.4.18/rootfs -nographic -append "root=/dev/ram rdinit=/helloworld console=ttyS0" -serial mon:stdio -device e1000,netdev=net0 -netdev user,id=net0,hostfwd=tcp::2222-:22

gdb vmLinux
#以下进行调试
target remote:1234
lx-symbol
b start_kernel
c


{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "kernel-debug",
            "type": "cppdbg",
            "request": "launch",
            "miDebuggerServerAddress": "127.0.0.1:1234",
            "program": "${workspaceFolder}/vmlinux",
            "args": [],
            "stopAtEntry": false,
            "cwd": "${workspaceFolder}",
            "environment": [],
            "externalConsole": false,
            "logging": {
                "engineLogging": false
            },
            "MIMode": "gdb",
        }
    ]
}

qemu-system-x86_64 -s -S -kernel ~/linux-5.3.7/arch/x86/boot/bzImage -initrd ~/busybox-1.31.0/initramfs.cpio.gz -nographic -append "nokaslr console=ttyS0" -serial mon:stdio -device e1000,netdev=net0 -netdev user,id=net0,hostfwd=tcp::5555-:22



(gdb) target remote:1234
Remote debugging using :1234
0x000000000000fff0 in entry_stack_storage ()
(gdb) hb start_kernel
Breakpoint 1 at 0xffffffff8302c118: file init/main.c, line 577.
(gdb) c
Continuing.

Thread 1 hit Breakpoint 1, start_kernel () at init/main.c:577
577     {
(gdb) bt
#0  start_kernel () at init/main.c:577
#1  0xffffffff8302b583 in x86_64_start_reservations (real_mode_data=<optimized out>) at arch/x86/kernel/head64.c:490
#2  0xffffffff8302b675 in x86_64_start_kernel (real_mode_data=0x14970 <bts_ctx+10608> <error: Cannot access memory at address 0x14970>) at arch/x86/kernel/head64.c:471
#3  0xffffffff810000e6 in secondary_startup_64 () at arch/x86/kernel/head_64.S:241


yum install flex bison openssl libssl-dev libelf-dev -y


rdma link add rxe_ens3 type rxe netdev ens3

./drivers/infiniband/sw/rxe/rdma_rxe.ko
cat ./drivers/infiniband/sw/rxe/rdma_rxe.ko
root@vm:~/project/linux/linux-5.4.18# cat /sys/module/rdma_rxe/sections/.text
0xffffffffc0be3000
root@vm:~/project/linux/linux-5.4.18# cat /sys/module/rdma_rxe/sections/.data
0xffffffffc0bf90a0
root@vm:~/project/linux/linux-5.4.18# cat /sys/module/rdma_rxe/sections/.bss 
0xffffffffc0bffa40

add-symbol-file ./drivers/infiniband/sw/rxe/rdma_rxe.ko 0xffffffffc0be3000 -s .data 0xffffffffc0bf90a0 -s .bss 0xffffffffc0bffa40
add-symbol-file ./drivers/infiniband/core/ib_uverbs.ko 0xffffffffc0be3000 -s .data 0xffffffffc0bf90a0 -s .bss 0xffffffffc0bffa40
add-symbol-file ./drivers/infiniband/core/ib_core.ko 0xffffffffc0be3000 -s .data 0xffffffffc0bf90a0 -s .bss 0xffffffffc0bffa40

echo "add-symbol-file ./drivers/infiniband/sw/rxe/rdma_rxe.ko `cat /sys/module/rdma_rxe/sections/.text` -s .data `cat /sys/module/rdma_rxe/sections/.data` -s .bss `cat /sys/module/rdma_rxe/sections/.bss`"
echo "add-symbol-file ./drivers/infiniband/core/ib_core.ko `cat /sys/module/ib_core/sections/.text` -s .data `cat /sys/module/ib_core/sections/.data` -s .bss `cat /sys/module/ib_core/sections/.bss`"
echo "add-symbol-file ./drivers/infiniband/core/ib_uverbs.ko `cat /sys/module/ib_uverbs/sections/.text` -s .data `cat /sys/module/ib_uverbs/sections/.data` -s .bss `cat /sys/module/ib_uverbs/sections/.bss`"




ibv_reg_mr:
.reg_user_mr = rxe_reg_user_mr,

ibv_alloc_pd
execute_cmd_write(context, IB_USER_VERBS_CMD_ALLOC_PD
.alloc_pd = rxe_alloc_pd, -> kernel IB_USER_VERBS_CMD_ALLOC_PD -> ib_uverbs_alloc_pd
    uverbs_request
    rdma_zalloc_drv_obj
    ret = ib_dev->ops.alloc_pd(pd, &attrs->driver_udata) -> rxe_alloc_pd -> rxe_add_to_pool
        might_sleep_if
        elem->pool = pool
    uverbs_response
    uobj_alloc_commit


lsmod|grep rdma
rpcrdma               299008  0
sunrpc                581632  1 rpcrdma
rdma_ucm               28672  0
rdma_cm               118784  3 rpcrdma,ib_iser,rdma_ucm
iw_cm                  53248  1 rdma_cm
ib_cm                 131072  1 rdma_cm
rdma_rxe              135168  0
ib_uverbs             163840  2 rdma_rxe,rdma_ucm
ip6_udp_tunnel         16384  1 rdma_rxe
udp_tunnel             20480  1 rdma_rxe
ib_core               393216  8 rdma_cm,rdma_rxe,rpcrdma,iw_cm,ib_iser,rdma_ucm,ib_uverbs,ib_cm
root@vm:~/project/linux/linux-5.4.18/drivers/infiniband/core# modinfo ib_core 
filename:       /lib/modules/5.15.0-67-generic/kernel/drivers/infiniband/core/ib_core.ko



root@vm:~/project/rdma/rdma-core/build/bin# ./ibv_devices 
    device                 node GUID
    ------              ----------------
    rxe_ens3            505400fffe123456
root@vm:~/project/rdma/rdma-core/build/bin# ./ibv_rc_pingpong -d rxe_ens3 -g 0
  local address:  LID 0x0000, QPN 0x000011, PSN 0x1580f2, GID fe80::5054:ff:fe12:3456
root@vm:~/project/rdma/rdma-core/build/bin# gdb --args ./ibv_rc_pingpong -d rxe_ens3 -g 0



add-auto-load-safe-path /root/project/linux/linux-5.4.18/scripts/gdb/vmlinux-gdb.py


b cmdline_proc_show


readelf -h vmlinux


boot:
vim /boot/grub/grub.cfg

vim /etc/default/grub
GRUB_DEFAULT=1> 2
GRUB_TIMEOUT_STYLE=hidden
GRUB_TIMEOUT=0
GRUB_DISTRIBUTOR=`lsb_release -i -s 2> /dev/null || echo Debian`
GRUB_CMDLINE_LINUX_DEFAULT="quiet splash"
GRUB_CMDLINE_LINUX="

update-grub
gnulinux-5.4.18+-advanced-64471880-f885-4431-a067-a2d6d996387c

dpkg --get-selections|grep linux-image

kvm:
kvm.ko, commit: https://github.com/ssbandjl/linux/commit/6aa8b732ca01c3d7a54e93f4d701b8aabbe60fb7,  
virt/kvm/vfio.c
    kvm_vfio_ops_init


kvm_main.c -> kvm_init KVM模块初始化

arch/x86/kvm


svm_init, amd
static int __init vmx_init(void) -> intel -> [PATCH] kvm：用户空间界面，网站：http://kvm.sourceforge.net 邮件列表：kvm-devel@lists.sourceforge.net (http://lists.sourceforge.net/lists/listinfo/kvm-devel ）以下补丁集将英特尔硬件虚拟化扩展的驱动程序添加到 x86 架构。 该驱动程序添加了一个向用户空间公开虚拟化功能的字符设备 (/dev/kvm)。 使用此驱动程序，进程可以在包含其自己的虚拟硬盘、网络适配器和显示器的完全虚拟化 PC 中运行虚拟机（“来宾”）。 使用此驱动程序，可以在一台主机上启动多个虚拟机。 每个虚拟机都是主机上的一个进程； 虚拟CPU是该进程中的一个线程。 Kill(1)、nice(1)、top(1) 按预期工作。 实际上，驱动程序在现有两种执行模式的基础上添加了第三种执行模式：现在有内核模式、用户模式和来宾模式。 访客模式有自己的地址空间映射访客物理内存（用户模式可通过 mmap()ing /dev/kvm 访问）。 访客模式无法访问任何I/O设备； 任何此类访问都会被拦截并定向到用户模式进行模拟。 该驱动程序支持 i386 和 x86_64 主机和来宾。 除了 i386 主机上的 x86_64 guest 以外，所有组合均被允许。 对于 i386 来宾和主机，支持 pae 和 non-pae 分页模式。 支持 SMP 主机和 UP 来宾。 目前仅支持 Intel 硬件，但正在开发 AMD 虚拟化支持。 由于 mmu 虚拟化的简单实现，每次上下文切换都会丢弃大部分影子页表条目，因此目前的性能并不理想。 我们计划通过两种方式解决这个问题： - 跨 tlb 刷新缓存影子页表 - 等到 AMD 和 Intel 发布具有嵌套页表的处理器 目前，虚拟桌面响应良好，但会消耗大量 CPU。 在Windows下我尝试玩弹球游戏和看一些Flash电影； 使用最新的 CPU 几乎感觉不到虚拟化。 Linux/X 较慢，可能是因为 X 位于单独的进程中。 除了驱动程序之外，您还需要稍微修改一下的 qemu 来提供 I/O 设备模拟和 BIOS。 注意事项（akpm：可能不再正确）： - 由于虚拟 APIC 问题，Windows 安装当前出现蓝屏。 我们正在努力修复。 临时解决方法是使用现有映像或通过 qemu 安装 - Windows 64 位不起作用。 qemu也是如此，所以很可能是设备型号的问题
    kvm_is_vmx_supported
        smp_processor_id
        if (!(cpuid_ecx(1) & feature_bit(VMX)))
    hv_init_evmcs
    kvm_x86_vendor_init
    vmx_setup_l1d_flush
    pi_init_cpu
    cpu_emergency_register_virt_callback
    vmx_check_vmcs12_offsets
    kvm_init THIS_MODULE ->  这是一个表示当前模块的标识符，用于标记KVM模块的所属

总结一下kvm模块初始化到底做了什么：  硬件检查： 初始化过程首先会进行硬件检查，确保主机的硬件支持虚拟化扩展，如 Intel VT-x 或 AMD-V。这些硬件扩展允许虚拟机在更加隔离的环境中运行，提高性能和安全性。 分配结构缓存： KVM 初始化过程分配了一些常用的数据结构的缓存，这些结构将用于管理虚拟机和虚拟 CPU 的状态。 创建设备节点： 通过创建 /dev/kvm 设备节点，用户空间程序可以通过这个设备与 KVM 内核模块进行通信，发起虚拟化请求和操作。 获取 VMCS 配置： 在初始化过程中，KVM 模块会获取 VMCS（Virtual Machine Control Structure）的配置信息，这些信息用于初始化 VMCS 结构。VMCS 是一个关键的数据结构，用于控制虚拟机运行的各个方面。 设置全局变量： 根据主机 CPU 的特性和支持，KVM 模块会设置一些全局变量，以适应不同的硬件环境。例如，根据 CPU 是否支持 EPT（Extended Page Tables）等特性，设置相应的全局标志。 为每个物理 CPU 分配 VMCS： KVM 初始化过程会为每个物理 CPU 分配一个 VMCS 结构，并将这些结构保存在 percpu 变量中。这为虚拟机在不同的物理 CPU 上切换和调度提供了支持。 进入 VMX 模式： 在初始化过程中，并没有将 CPU 设置为 VMX 模式。VMX 模式是虚拟机扩展的一种硬件虚拟化模式，需要通过设置 CR4 寄存器的 VMXE 位并分配 VMXON 区域来开启。然而，在创建第一个虚拟机之前，这些步骤不会执行。这是一种惰性策略，只有在实际需要创建虚拟机时才会启用 VMX 模式，以避免不必要的开销。 综上所述，KVM 模块的初始化过程主要包括硬件检查、资源分配、设备节点创建、全局变量设置、VMCS 配置等步骤。该过程确保了在虚拟化环境下能够准备好必要的数据结构和配置，以便在创建和管理虚拟机时进行有效的虚拟化操作。真正的 VMX 模式开启是在创建第一个虚拟机时才会执行，以避免不必要的性能损耗





核心驱动:
static struct pci_driver mlx5_core_driver = {
    .name           = KBUILD_MODNAME,
    .id_table       = mlx5_core_pci_table,
    .probe          = probe_one,
    .remove         = remove_one,
    .suspend        = mlx5_suspend,
    .resume         = mlx5_resume,
    .shutdown	= shutdown,
    .err_handler	= &mlx5_err_handler,
    .sriov_configure   = mlx5_core_sriov_configure, / 支持sriov功能需要实现的函数 /
    .sriov_get_vf_total_msix = mlx5_sriov_get_vf_total_msix, //  PF 驱动程序回调以获取可用于分发到VF 的MSI-X 向量的总数
    .sriov_set_msix_vec_count = mlx5_core_sriov_set_msix_vec_count, // PF 驱动程序回调以更改 VF 上的 MSI-X 向量的数量
};

static struct auxiliary_driver mlx5_sf_driver = {
    .name = MLX5_SF_DEV_ID_NAME,
    .probe = mlx5_sf_dev_probe,
    .remove = mlx5_sf_dev_remove,
    .shutdown = mlx5_sf_dev_shutdown,
    .id_table = mlx5_sf_dev_id_table,
};



static int mlx5_sf_dev_probe(struct auxiliary_device *adev, const struct auxiliary_device_id *id)
    mlx5_devlink_alloc -> devlink：尽早设置设备 所有内核 devlink 实现都会在特定设备的初始化例程期间调用 devlink_alloc()，该设备稍后用作 devlink_register() 的父设备。 这种较晚的设备分配会导致需要我们在设置其他参数之前调用 device_register() 的情况，但该调用向世界打开了 devlink 并可供 netlink 用户访问。 由于访问 devlink->dev 指针，任何将 devlink_register() 移至最后一次调用的尝试都会生成以下错误。
    mlx5_dev_set_lightweight -> net/mlx5：轻探测本地 SF 如果用户想要配置 SF，例如：仅使用 vdpa 功能，则他需要完全探测 SF，配置他想要的内容，然后重新加载 SF。 为了节省重新加载的时间，本地SF将在没有任何辅助子设备的情况下进行探测，从而可以在其完全探测之前对SF进行配置。 这些 SF 的 enable_* devlink 参数的默认值设置为 false。
    mlx5_mdev_init -> net/mlx5：为 SF 创建新的配置文件 为 SF 创建新的配置文件以禁用命令缓存。 每个功能命令缓存消耗约 500KB 的内存，当使用大量 SF 时，这种节省在内存受限的系统上非常显着。 使用新的配置文件来提供 SF 和 PF 之间未来的差异。 mr_cache 不用于非 PF 函数，因此它被排除在新配置文件之外。
    ioremap
    mlx5_init_one_light
    or
    mlx5_init_one
    mlx5_core_peer_devlink_set
    devlink_register


net/mlx5: SF，添加辅助设备驱动程序
为mlx5子功能辅助设备添加辅助设备驱动程序。 mlx5 子功能类似于 PCI PF 和 VF。 对于子功能，创建辅助设备。 因此，当 mlx5 SF 辅助设备绑定到驱动程序时，会创建其 netdev 和 rdma 设备，它们显示为
$ ls -l /sys/bus/auxiliary/devices/
mlx5_core.sf.4 -> ../../../devices/pci0000:00/0000:00:03.0/0000:06:00.0/mlx5_core.sf.4
$ ls -l /sys/class/net/eth1/device
/sys/class/net/eth1/device -> ../../../mlx5_core.sf.4
$ cat /sys/bus/auxiliary/devices/mlx5_core.sf.4/sfnum
$ devlink dev show
pci/0000:06:00.0
auxiliary/mlx5_core.sf.4
$ devlink port show auxiliary/mlx5_core.sf.4/1
auxiliary/mlx5_core.sf.4/1: type eth netdev p0sf88 flavour virtual port 0 splittable false
$ rdma link show mlx5_0/1
link mlx5_0/1 state ACTIVE physical_state LINK_UP netdev p0sf88
$ rdma dev show
8: rocep6s0f1: node_type ca fw 16.29.0550 node_guid 248a:0703:00b3:d113 sys_image_guid 248a:0703:00b3:d112
13: mlx5_0: node_type ca fw 16.29.0550 node_guid 0000:00ff:fe00:8888 sys_image_guid 248a:0703:00b3:d112
将来，devlink 设备实例名称将适应使用别名或 RFC [1] 中描述的 devlink 实例名称的 sfnum 注释。










default config profile:
static struct mlx5_profile profile[]




git remote add origin git@gitlab.nsv6.b122.top:bin/linux_kernel.git


register_chrdev

pci_enable_device

filter: ./drivers/net/ethernet/intel/


get info:
System with RoCE SR-IOV card with 4 VFs:
[leonro@vm ~]$ lspci |grep nox
01:00.0 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6]
01:00.1 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.2 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.3 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
01:00.4 Ethernet controller: Mellanox Technologies MT28908 Family [ConnectX-6 Virtual Function]
[leonro@vm ~]$ ls -l /sys/bus/auxiliary/devices/
mlx5_core.eth.0 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.0/mlx5_core.eth.0
mlx5_core.eth.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.eth.1
mlx5_core.eth.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.eth.2
mlx5_core.eth.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.eth.3
mlx5_core.eth.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.eth.4
mlx5_core.rdma.0 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.0/mlx5_core.rdma.0
mlx5_core.rdma.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.rdma.1
mlx5_core.rdma.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.rdma.2
mlx5_core.rdma.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.rdma.3
mlx5_core.rdma.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.rdma.4
mlx5_core.vdpa.1 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.1/mlx5_core.vdpa.1
mlx5_core.vdpa.2 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.2/mlx5_core.vdpa.2
mlx5_core.vdpa.3 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.3/mlx5_core.vdpa.3
mlx5_core.vdpa.4 -> ../../../devices/pci0000:00/0000:00:09.0/0000:01:00.4/mlx5_core.vdpa.4
[leonro@vm ~]$ rdma dev
0: rocep1s0f0: node_type ca fw 4.6.9999 node_guid 5254:00c0:fe12:3455 sys_image_guid 5254:00c0:fe12:3455
1: rocep1s0f0v0: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3456
2: rocep1s0f0v1: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3457
3: rocep1s0f0v2: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3458
4: rocep1s0f0v3: node_type ca fw 4.6.9999 node_guid 0000:0000:0000:0000 sys_image_guid 5254:00c0:fe12:3459



static const struct mlx5_adev_device {
    const char *suffix;
    bool (*is_supported)(struct mlx5_core_dev *dev);
    bool (*is_enabled)(struct mlx5_core_dev *dev);
} mlx5_adev_devices[] = {
    [MLX5_INTERFACE_PROTOCOL_VNET] = { .suffix = "vnet",
                       .is_supported = &mlx5_vnet_supported,
                       .is_enabled = &is_vnet_enabled },
    [MLX5_INTERFACE_PROTOCOL_IB] = { .suffix = "rdma",
                     .is_supported = &mlx5_rdma_supported,
                     .is_enabled = &is_ib_enabled },
    [MLX5_INTERFACE_PROTOCOL_ETH] = { .suffix = "eth",
                      .is_supported = &mlx5_eth_supported,
                      .is_enabled = &mlx5_core_is_eth_enabled },
    [MLX5_INTERFACE_PROTOCOL_ETH_REP] = { .suffix = "eth-rep",
                       .is_supported = &is_eth_rep_supported },
    [MLX5_INTERFACE_PROTOCOL_IB_REP] = { .suffix = "rdma-rep",
                       .is_supported = &is_ib_rep_supported },
    [MLX5_INTERFACE_PROTOCOL_MPIB] = { .suffix = "multiport",
                       .is_supported = &is_mp_supported },
    [MLX5_INTERFACE_PROTOCOL_DPLL] = { .suffix = "dpll",
                       .is_supported = &is_dpll_supported },
};


capability types:
static const int types[] = {
    MLX5_CAP_GENERAL,
    MLX5_CAP_GENERAL_2,
    MLX5_CAP_ETHERNET_OFFLOADS,
    MLX5_CAP_IPOIB_ENHANCED_OFFLOADS,
    MLX5_CAP_ODP,
    MLX5_CAP_ATOMIC,
    MLX5_CAP_ROCE,
    MLX5_CAP_IPOIB_OFFLOADS,
    MLX5_CAP_FLOW_TABLE,
    MLX5_CAP_ESWITCH_FLOW_TABLE,
    MLX5_CAP_ESWITCH,
    MLX5_CAP_QOS,
    MLX5_CAP_DEBUG,
    MLX5_CAP_DEV_MEM,
    MLX5_CAP_DEV_EVENT,
    MLX5_CAP_TLS,
    MLX5_CAP_VDPA_EMULATION,
    MLX5_CAP_IPSEC,
    MLX5_CAP_PORT_SELECTION,
    MLX5_CAP_MACSEC,
    MLX5_CAP_ADV_VIRTUALIZATION,
    MLX5_CAP_CRYPTO,
};



module_init(mlx5_dpll_init); -> mlx5：使用 DPLL 基础设施实现 SyncE 支持 使用新引入的 DPLL 支持实现 SyncE 支持。 确保使用适当功能探测的每个 PF/VF/SF 将生成 dpll 辅助设备并注册适当的 dpll 设备和引脚实例



该产品组合包括符合 ITU-T/IEEE 标准的数字锁相环 (DPLL)，用于网络同步，其性能满足 SyncE 和 IEEE 1588 严格的 10G/40G/100G 接口要求。


mlx5_tout_init


The defaults of the enable_* devlink params of these SFs are set to
false.

Usage example:
Create SF:
$ devlink port add pci/0000:08:00.0 flavour pcisf pfnum 0 sfnum 11
$ devlink port function set pci/0000:08:00.0/32768 \
hw_addr 00:00:00:00:00:11 state active

Enable ETH auxiliary device:
$ devlink dev param set auxiliary/mlx5_core.sf.1 \
name enable_eth value true cmode driverinit

Now, in order to fully probe the SF, use devlink reload:
$ devlink dev reload auxiliary/mlx5_core.sf.1
此时，用户拥有仅用于以太网功能的带有辅助设备的 SF devlink 实例


命令操作:
const char *mlx5_command_str(int command)
{
#define MLX5_COMMAND_STR_CASE(__cmd) case MLX5_CMD_OP_ ## __cmd: return #__cmd

    switch (command) {
    MLX5_COMMAND_STR_CASE(QUERY_HCA_CAP);
    MLX5_COMMAND_STR_CASE(QUERY_ADAPTER);
    MLX5_COMMAND_STR_CASE(INIT_HCA);
    MLX5_COMMAND_STR_CASE(TEARDOWN_HCA);
    MLX5_COMMAND_STR_CASE(ENABLE_HCA);
    MLX5_COMMAND_STR_CASE(DISABLE_HCA);
    MLX5_COMMAND_STR_CASE(QUERY_PAGES);
    MLX5_COMMAND_STR_CASE(MANAGE_PAGES);
    MLX5_COMMAND_STR_CASE(SET_HCA_CAP);
    MLX5_COMMAND_STR_CASE(QUERY_ISSI);
    MLX5_COMMAND_STR_CASE(SET_ISSI);
    MLX5_COMMAND_STR_CASE(SET_DRIVER_VERSION);
    MLX5_COMMAND_STR_CASE(CREATE_MKEY);
    MLX5_COMMAND_STR_CASE(QUERY_MKEY);
    MLX5_COMMAND_STR_CASE(DESTROY_MKEY);
    MLX5_COMMAND_STR_CASE(QUERY_SPECIAL_CONTEXTS);
    MLX5_COMMAND_STR_CASE(PAGE_FAULT_RESUME);
    MLX5_COMMAND_STR_CASE(CREATE_EQ);
    MLX5_COMMAND_STR_CASE(DESTROY_EQ);
    MLX5_COMMAND_STR_CASE(QUERY_EQ);
    MLX5_COMMAND_STR_CASE(GEN_EQE);
    MLX5_COMMAND_STR_CASE(CREATE_CQ);
    MLX5_COMMAND_STR_CASE(DESTROY_CQ);
    MLX5_COMMAND_STR_CASE(QUERY_CQ);
    MLX5_COMMAND_STR_CASE(MODIFY_CQ);
    MLX5_COMMAND_STR_CASE(CREATE_QP);
    MLX5_COMMAND_STR_CASE(DESTROY_QP);
    MLX5_COMMAND_STR_CASE(RST2INIT_QP);
    MLX5_COMMAND_STR_CASE(INIT2RTR_QP);
    MLX5_COMMAND_STR_CASE(RTR2RTS_QP);
    MLX5_COMMAND_STR_CASE(RTS2RTS_QP);
    MLX5_COMMAND_STR_CASE(SQERR2RTS_QP);
    MLX5_COMMAND_STR_CASE(2ERR_QP);
    MLX5_COMMAND_STR_CASE(2RST_QP);
    MLX5_COMMAND_STR_CASE(QUERY_QP);
    MLX5_COMMAND_STR_CASE(SQD_RTS_QP);
    MLX5_COMMAND_STR_CASE(INIT2INIT_QP);
    MLX5_COMMAND_STR_CASE(CREATE_PSV);
    MLX5_COMMAND_STR_CASE(DESTROY_PSV);
    MLX5_COMMAND_STR_CASE(CREATE_SRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_SRQ);
    MLX5_COMMAND_STR_CASE(QUERY_SRQ);
    MLX5_COMMAND_STR_CASE(ARM_RQ);
    MLX5_COMMAND_STR_CASE(CREATE_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(QUERY_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(ARM_XRC_SRQ);
    MLX5_COMMAND_STR_CASE(CREATE_DCT);
    MLX5_COMMAND_STR_CASE(DESTROY_DCT);
    MLX5_COMMAND_STR_CASE(DRAIN_DCT);
    MLX5_COMMAND_STR_CASE(QUERY_DCT);
    MLX5_COMMAND_STR_CASE(ARM_DCT_FOR_KEY_VIOLATION);
    MLX5_COMMAND_STR_CASE(QUERY_VPORT_STATE);
    MLX5_COMMAND_STR_CASE(MODIFY_VPORT_STATE);
    MLX5_COMMAND_STR_CASE(QUERY_ESW_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_ESW_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_NIC_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_NIC_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_ROCE_ADDRESS);
    MLX5_COMMAND_STR_CASE(SET_ROCE_ADDRESS);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(MODIFY_HCA_VPORT_CONTEXT);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_GID);
    MLX5_COMMAND_STR_CASE(QUERY_HCA_VPORT_PKEY);
    MLX5_COMMAND_STR_CASE(QUERY_VNIC_ENV);
    MLX5_COMMAND_STR_CASE(QUERY_VPORT_COUNTER);
    MLX5_COMMAND_STR_CASE(ALLOC_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(DEALLOC_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(QUERY_Q_COUNTER);
    MLX5_COMMAND_STR_CASE(SET_MONITOR_COUNTER);
    MLX5_COMMAND_STR_CASE(ARM_MONITOR_COUNTER);
    MLX5_COMMAND_STR_CASE(SET_PP_RATE_LIMIT);
    MLX5_COMMAND_STR_CASE(QUERY_RATE_LIMIT);
    MLX5_COMMAND_STR_CASE(CREATE_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(DESTROY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(QUERY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(MODIFY_SCHEDULING_ELEMENT);
    MLX5_COMMAND_STR_CASE(CREATE_QOS_PARA_VPORT);
    MLX5_COMMAND_STR_CASE(DESTROY_QOS_PARA_VPORT);
    MLX5_COMMAND_STR_CASE(ALLOC_PD);
    MLX5_COMMAND_STR_CASE(DEALLOC_PD);
    MLX5_COMMAND_STR_CASE(ALLOC_UAR);
    MLX5_COMMAND_STR_CASE(DEALLOC_UAR);
    MLX5_COMMAND_STR_CASE(CONFIG_INT_MODERATION);
    MLX5_COMMAND_STR_CASE(ACCESS_REG);
    MLX5_COMMAND_STR_CASE(ATTACH_TO_MCG);
    MLX5_COMMAND_STR_CASE(DETACH_FROM_MCG);
    MLX5_COMMAND_STR_CASE(GET_DROPPED_PACKET_LOG);
    MLX5_COMMAND_STR_CASE(MAD_IFC);
    MLX5_COMMAND_STR_CASE(QUERY_MAD_DEMUX);
    MLX5_COMMAND_STR_CASE(SET_MAD_DEMUX);
    MLX5_COMMAND_STR_CASE(NOP);
    MLX5_COMMAND_STR_CASE(ALLOC_XRCD);
    MLX5_COMMAND_STR_CASE(DEALLOC_XRCD);
    MLX5_COMMAND_STR_CASE(ALLOC_TRANSPORT_DOMAIN);
    MLX5_COMMAND_STR_CASE(DEALLOC_TRANSPORT_DOMAIN);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_STATUS);
    MLX5_COMMAND_STR_CASE(MODIFY_CONG_STATUS);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_PARAMS);
    MLX5_COMMAND_STR_CASE(MODIFY_CONG_PARAMS);
    MLX5_COMMAND_STR_CASE(QUERY_CONG_STATISTICS);
    MLX5_COMMAND_STR_CASE(ADD_VXLAN_UDP_DPORT);
    MLX5_COMMAND_STR_CASE(DELETE_VXLAN_UDP_DPORT);
    MLX5_COMMAND_STR_CASE(SET_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(QUERY_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(DELETE_L2_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(SET_WOL_ROL);
    MLX5_COMMAND_STR_CASE(QUERY_WOL_ROL);
    MLX5_COMMAND_STR_CASE(CREATE_LAG);
    MLX5_COMMAND_STR_CASE(MODIFY_LAG);
    MLX5_COMMAND_STR_CASE(QUERY_LAG);
    MLX5_COMMAND_STR_CASE(DESTROY_LAG);
    MLX5_COMMAND_STR_CASE(CREATE_VPORT_LAG);
    MLX5_COMMAND_STR_CASE(DESTROY_VPORT_LAG);
    MLX5_COMMAND_STR_CASE(CREATE_TIR);
    MLX5_COMMAND_STR_CASE(MODIFY_TIR);
    MLX5_COMMAND_STR_CASE(DESTROY_TIR);
    MLX5_COMMAND_STR_CASE(QUERY_TIR);
    MLX5_COMMAND_STR_CASE(CREATE_SQ);
    MLX5_COMMAND_STR_CASE(MODIFY_SQ);
    MLX5_COMMAND_STR_CASE(DESTROY_SQ);
    MLX5_COMMAND_STR_CASE(QUERY_SQ);
    MLX5_COMMAND_STR_CASE(CREATE_RQ);
    MLX5_COMMAND_STR_CASE(MODIFY_RQ);
    MLX5_COMMAND_STR_CASE(DESTROY_RQ);
    MLX5_COMMAND_STR_CASE(QUERY_RQ);
    MLX5_COMMAND_STR_CASE(CREATE_RMP);
    MLX5_COMMAND_STR_CASE(MODIFY_RMP);
    MLX5_COMMAND_STR_CASE(DESTROY_RMP);
    MLX5_COMMAND_STR_CASE(QUERY_RMP);
    MLX5_COMMAND_STR_CASE(CREATE_TIS);
    MLX5_COMMAND_STR_CASE(MODIFY_TIS);
    MLX5_COMMAND_STR_CASE(DESTROY_TIS);
    MLX5_COMMAND_STR_CASE(QUERY_TIS);
    MLX5_COMMAND_STR_CASE(CREATE_RQT);
    MLX5_COMMAND_STR_CASE(MODIFY_RQT);
    MLX5_COMMAND_STR_CASE(DESTROY_RQT);
    MLX5_COMMAND_STR_CASE(QUERY_RQT);
    MLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ROOT);
    MLX5_COMMAND_STR_CASE(CREATE_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(DESTROY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(CREATE_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(DESTROY_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_GROUP);
    MLX5_COMMAND_STR_CASE(SET_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(DELETE_FLOW_TABLE_ENTRY);
    MLX5_COMMAND_STR_CASE(ALLOC_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(DEALLOC_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(QUERY_FLOW_COUNTER);
    MLX5_COMMAND_STR_CASE(MODIFY_FLOW_TABLE);
    MLX5_COMMAND_STR_CASE(ALLOC_PACKET_REFORMAT_CONTEXT);
    MLX5_COMMAND_STR_CASE(DEALLOC_PACKET_REFORMAT_CONTEXT);
    MLX5_COMMAND_STR_CASE(ALLOC_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(DEALLOC_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(FPGA_CREATE_QP);
    MLX5_COMMAND_STR_CASE(FPGA_MODIFY_QP);
    MLX5_COMMAND_STR_CASE(FPGA_QUERY_QP);
    MLX5_COMMAND_STR_CASE(FPGA_QUERY_QP_COUNTERS);
    MLX5_COMMAND_STR_CASE(FPGA_DESTROY_QP);
    MLX5_COMMAND_STR_CASE(CREATE_XRQ);
    MLX5_COMMAND_STR_CASE(DESTROY_XRQ);
    MLX5_COMMAND_STR_CASE(QUERY_XRQ);
    MLX5_COMMAND_STR_CASE(ARM_XRQ);
    MLX5_COMMAND_STR_CASE(CREATE_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(DESTROY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(MODIFY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(QUERY_GENERAL_OBJECT);
    MLX5_COMMAND_STR_CASE(QUERY_MODIFY_HEADER_CONTEXT);
    MLX5_COMMAND_STR_CASE(ALLOC_MEMIC);
    MLX5_COMMAND_STR_CASE(DEALLOC_MEMIC);
    MLX5_COMMAND_STR_CASE(QUERY_ESW_FUNCTIONS);
    MLX5_COMMAND_STR_CASE(CREATE_UCTX);
    MLX5_COMMAND_STR_CASE(DESTROY_UCTX);
    MLX5_COMMAND_STR_CASE(CREATE_UMEM);
    MLX5_COMMAND_STR_CASE(DESTROY_UMEM);
    MLX5_COMMAND_STR_CASE(RELEASE_XRQ_ERROR);
    MLX5_COMMAND_STR_CASE(MODIFY_XRQ);
    MLX5_COMMAND_STR_CASE(QUERY_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(MODIFY_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(ALLOC_SF);
    MLX5_COMMAND_STR_CASE(DEALLOC_SF);
    MLX5_COMMAND_STR_CASE(SUSPEND_VHCA);
    MLX5_COMMAND_STR_CASE(RESUME_VHCA);
    MLX5_COMMAND_STR_CASE(QUERY_VHCA_MIGRATION_STATE);
    MLX5_COMMAND_STR_CASE(SAVE_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(LOAD_VHCA_STATE);
    MLX5_COMMAND_STR_CASE(SYNC_CRYPTO);
    MLX5_COMMAND_STR_CASE(ALLOW_OTHER_VHCA_ACCESS);
    default: return "unknown command opcode";
    }
}



vlan header:
#define IANA_VXLAN_UDP_PORT     4789
#define IANA_VXLAN_GPE_UDP_PORT 4790

/* VXLAN protocol (RFC 7348) header:
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 * |R|R|R|R|I|R|R|R|               Reserved                        |
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 * |                VXLAN Network Identifier (VNI) |   Reserved    |
 * +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 *
 * I = VXLAN Network Identifier (VNI) present.
 */



.unlocked_ioctl = ib_uverbs_ioctl
...
user space
ioctl(context->cmd_fd, RDMA_VERBS_IOCTL, &cmd->hdr)
...
ib_uverbs_ioctl
    unlikely(cmd != RDMA_VERBS_IOCTL)
    copy_from_user
    srcu_read_lock
    ib_uverbs_cmd_verbs -> IB/uverbs：使用 uverbs_api 解组 ioctl 命令 转换 ioctl 方法系统调用路径以使用 uverbs_api 数据结构。 新的 uapi 结构包含所有相同的信息，只是以不同且更优化的方式。 - 对于与属性相关的所有内容，使用 attr_bkey 而不是 2 级基数树。 这包括属性存储、存在以及缺失强制属性的检测。 - 避免在完成时迭代所有属性存储，而是使用 find_first_bit 和 attr_bkey 来仅定位那些需要清理的属性。 - 组织事物始终运行并始终依赖清理。 这避免了一堆棘手的错误展开情况。 - 使用基数树定位方法，并使用非常高效的增量基数树查找来定位属性 - 使用预先计算的 destroy_bkey 来处理 uobject 销毁 - 使用预先计算的分配大小和预先计算的“need_stack”以避免快速路径中的数学运算。 如果用户空间不传递（许多）不支持的属性，这是最佳的。 总的来说，这为属性访问器带来了更好的代码生成，所有内容现在都存储在由 attr_bkey 索引的位图或线性数组中。 编译器可以在编译时计算所有方法属性的 attr_bkey 值，这意味着像 uverbs_attr_is_valid() 这样的东西现在编译成单指令位测试
        radix_tree_iter_lookup <- uapi_add_get_elm
            uapi_key_ioctl_method(hdr->method_id)
        method_elm = rcu_dereference_protected(*slot, true)
        ib_uverbs_run_method
            handler = srcu_dereference
            ret = handler(&pbundle->bundle)
            ...
            ib_uverbs_alloc_pd -> IB_USER_VERBS_CMD_ALLOC_PD
                uverbs_request
                    copy_from_user
                uobj_alloc(UVERBS_OBJECT_PD, attrs, &ib_dev)
                    ...
                    rdma_alloc_begin_uobject
                        obj->type_class->alloc_begin
                rdma_zalloc_drv_obj
                rdma_restrack_new
                rdma_restrack_set_name
                ib_dev->ops.alloc_pd(pd, &attrs->driver_udata) -> .alloc_pd =  -> mlx5_ib_alloc_pd
                    rdma_udata_to_drv_context
                    mlx5_cmd_exec_inout(to_mdev(ibdev)->mdev, alloc_pd, in, out) -> 命令框架
                        ...
                    ib_copy_to_udata
                rdma_restrack_add
                    xa_insert
                    or xa_alloc_cyclic
                uobj_finalize_uobj_create
                uverbs_response
        bundle_destroy
    srcu_read_unlock


ioctl, cmd, 
uverbs_core_api
uverbs_def_write_intf
static const struct uapi_definition uverbs_core_api[] = {
	UAPI_DEF_CHAIN(uverbs_def_obj_async_fd),
	UAPI_DEF_CHAIN(uverbs_def_obj_counters),
	UAPI_DEF_CHAIN(uverbs_def_obj_cq),
	UAPI_DEF_CHAIN(uverbs_def_obj_device),
	UAPI_DEF_CHAIN(uverbs_def_obj_dm),
	UAPI_DEF_CHAIN(uverbs_def_obj_flow_action),
	UAPI_DEF_CHAIN(uverbs_def_obj_intf),
	UAPI_DEF_CHAIN(uverbs_def_obj_mr),
	UAPI_DEF_CHAIN(uverbs_def_obj_qp),
	UAPI_DEF_CHAIN(uverbs_def_obj_srq),
	UAPI_DEF_CHAIN(uverbs_def_obj_wq),
	UAPI_DEF_CHAIN(uverbs_def_write_intf),
	{},
};





ib_uverbs_add_one  -> RDMA：允许 ib_client 在调用 add() 时失败，添加客户端时不允许失败，但所有客户端在其添加例程中都有各种失败路径。 这会产生一种非常边缘的情况：添加客户端后，在添加过程中失败并且未设置 client_data。 然后，核心代码仍然会使用 NULL client_data 调用其他以 client_data 为中心的操作，例如 remove()、rename()、get_nl_info() 和 get_net_dev_by_params() - 这是令人困惑和意外的。 如果 add() 回调失败，则不要再为设备调用任何客户端操作，甚至删除。 删除操作回调中现在对 NULL client_data 的所有冗余检查。 更新所有 add() 回调以正确返回错误代码。 EOPNOTSUPP 用于 ULP 不支持 ib_device 的情况 - 例如，因为它仅适用于 IB
参考: https://www.cnblogs.com/vlhn/p/8301427.html
    ib_uverbs_create_uapi
        uverbs_alloc_api
            uapi_merge_def(uapi, ibdev, uverbs_core_api, false)
                uapi_merge_obj_tree
                    uapi_merge_method
    dev_set_name
    cdev_init
    cdev_device_add
    ib_set_client_data



Mellanox ConnectX-6-dx智能网卡 openvswitch 流表卸载源码分析: https://blog.csdn.net/qq_20679687/article/details/131632198
// -------- ovs -----------------
// --- ovs vswitchd 主线程 -----------------
// 首包触发卸载，后续包走datapath转发或硬件转发
dp_netdev_flow_add
    dpcls_insert(cls, &flow->cr, &mask);  // datapath缓存流转发规则
    // 入队 卸载任务队列
    queue_netdev_flow_put(pmd, flow, match, actions, actions_len, DP_NETDEV_FLOW_OFFLOAD_OP_ADD);

// --- ovs offload_main 卸载线程 -----
dp_netdev_flow_offload_main    // 通过队列+poll的方式，该线程 异步处理 来自ovs主线程的卸载任务队列。
    dp_offload_flow(offload);
        // netdev offload
        dp_netdev_flow_offload_put  // 单独的一个线程 dp_netdev_flow_offload_main
        netdev_flow_put->flow_ flow_api->flow_put
            netdev_offload_dpdk_flow_put
                netdev_offload_dpdk_add_flow
                    netdev_offload_dpdk_action
                        netdev_offload_dpdk_flow_create
                            netdev_dpdk_rte_flow_create
                                // ---- dpdk rte_flow ----------------------
                                rte_flow_create()
                                 ==>mlx5_flow_create    // dpdk: drivers/net/mlx5/mlx5_flow.c
                                        mlx5_flow_list_create
                                            flow_idx = flow_list_create(dev, type, attr, items, original_actions, 
                                                                        external, wks, error);
                                                flow_drv_translate(dev, dev_flow,&attr_tx, items_tx.items,
                                                                   actions_hairpin_tx.actions, error);
                                                    fops->translate(dev, dev_flow, attr, items, actions, error);
                                                     ==>flow_dv_translate(dev, dev_flow, attr, items, actions, error)  # 详见下方
                                                flow_drv_validate()
                                                flow_drv_apply(dev, flow, error);
                                                    fops->apply(dev, flow, error);
                                                     ==>flow_dv_apply     # 详见下方

// 分析 flow_dv_translate 
    for (; !actions_end ; actions++) {
        // parse action
    }
    dev_flow->act_flags = action_flags;
    flow_dv_matcher_register(dev, &matcher, &tbl_key, dev_flow, tunnel, attr->group, error)

// 分析 flow_dv_apply
flow_dv_apply
     mlx5_flow_os_create_flow(dv_h->matcher->matcher_object,(void *)&dv->value, n,dv->actions, &dh->drv_flow);
        *flow = mlx5_glue->dv_create_flow(matcher, match_value,num_actions, actions);
            mlx5_glue_dv_create_flow
                mlx5dv_dr_rule_create(matcher, match_value, num_actions,(struct mlx5dv_dr_action **)actions);
                    ==>用户态驱动 详见下小节
                    mlx5dv_dr_rule_create(matcher, match_value, num_actions,(struct mlx5dv_dr_action **)actions);
                    ==>内核态驱动 详见下下小节
                    __mlx5_glue_dv_create_flow(matcher, match_value,num_actions, actions_attr);



// --- rdma-core --------
mlx5dv_dr_rule_create(matcher, match_value, num_actions,(struct mlx5dv_dr_action **)actions);
    dr_rule_create_rule(matcher, value, num_actions, actions);
        dr_rule_create_rule_fdb(rule, &param,num_actions, actions);
            dr_rule_create_rule_nic(rule, &rule->tx, &copy_param,num_actions, actions);
                dr_rule_send_update_list(&send_ste_list, dmn, true, nic_rule->lock_index);
                    dr_rule_handle_one_ste_in_update_list(ste_info,dmn,send_ring_idx);
                        dr_send_postsend_ste(dmn, ste_info->ste, ste_info->data,ste_info->size,
                                             ste_info->offset,send_ring_idx);
                            dr_postsend_icm_data(dmn, &send_info, ring_idx);	
                                dr_post_send(send_ring->qp, send_info);   // 走rdma通道 
                                    /* Write. false, because we delay the post_send_db till the coming READ */
                                    dr_rdma_segments(dr_qp, send_info->remote_addr, send_info->rkey,
                                             &send_info->write, MLX5_OPCODE_RDMA_WRITE, false);
                                    /* Read. true, because we send WRITE + READ together */
                                    dr_rdma_segments(dr_qp, send_info->remote_addr, send_info->rkey,
                                             &send_info->read, MLX5_OPCODE_RDMA_READ, true);

// --- dpdk ---------------
mlx5_glue_dv_create_flow()
    __mlx5_glue_dv_create_flow(matcher, match_value,num_actions, actions_attr);
// --- rdma mlx5dv_create_flow in rdma-core providers/mlx5/verbs.c ---
    dvops->create_flow(flow_matcher,match_value,num_actions,actions_attr,NULL);
        _mlx5dv_create_flow
            fill_attr_in_uint32(cmd,MLX5_IB_ATTR_CREATE_FLOW_FLAGS,MLX5_IB_ATTR_CREATE_FLOW_FLAGS_DEFAULT_MISS);
            execute_ioctl(flow_matcher->context, cmd); // call kernel ioctl
// --- kernel space -- mlx5_ib.ko mlx_core.ko -------------
// ib_core dispatch message to mlx5_ib
UVERBS_HANDLER(MLX5_IB_METHOD_CREATE_FLOW)   // drivers/infiniband/hw/mlx5/fs.c
    get_dests
        uverbs_get_flags32
            uverbs_get_flags64(&flags, attrs_bundle, idx, allowed_bits);
            raw_fs_rule_add(dev, fs_matcher, &flow_context, &flow_act,counter_id, cmd_in, inlen, dest_id, dest_type);
                _create_raw_flow_rule
                    mlx5_add_flow_rules(ft, spec,flow_act, dst, dst_num);  // drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
                        rule = add_rule_fg(g, spec, flow_act, dest, dest_num, fte);
                            handle = add_rule_fte(fte, fg, dest, dest_num,old_action != flow_act->action);
                                root->cmds->update_fte(root, ft, fg, modify_mask, fte)
                                    mlx5_cmd_update_fte
                                        mlx5_cmd_set_fte(dev, opmod, modify_mask, ft, fg->id, fte);
                                            mlx5_cmd_exec(dev, in, inlen, out, sizeof(out));
                                                mlx5_cmd_do(dev, in, in_size, out, out_size);
                                                    cmd_exec(dev, in, in_size, out, out_size, NULL, NULL, false);
                                                        cmd_work_handler
                                                            down(sem)
                                                            lay = get_inst(cmd, ent->idx);
                                                                return cmd->cmd_buf + (idx << cmd->log_stride);
                                                            memset(lay, 0, sizeof(*lay));
                                                            memcpy(lay->in, ent->in->first.data, sizeof(lay->in));
                                                            lay->type = MLX5_PCI_CMD_XPORT
                                                            lay->status_own = CMD_OWNER_HW; // transfer ownership to hardware
                                                            wmb()
                                                            iowrite32be(1 << ent->idx, &dev->iseg->cmd_dbell);
                                                            // polling reg for completion
                                                            mlx5_cmd_comp_handler(dev, 1ULL << ent->idx, ent->ret == -ETIMEDOUT ?
                                                                      MLX5_CMD_COMP_TYPE_FORCED : MLX5_CMD_COMP_TYPE_POLLING);
                                                                callback or
                                                                complete

// ovs kernel datapath 路径
// -- user space ---
dpif_netlink_operate
 -->try_send_to_netdev   // 先卸载。这里会卡住。
    dpif_netlink_operate_chunks // 再转发
        dpif_netlink_operate__
            dpif_netlink_init_flow_put  // netlink
// -- kernel space ---
    ovs_flow_cmd_new()
        ovs_flow_tbl_lookup(&dp->table, &new_flow->key);
        ovs_flow_tbl_insert(&dp->table, new_flow, &mask);

// ovs卸载路径
// --- user space ---
dpif_netlink_operate
    try_send_to_netdev
        parse_flow_put(dpif, put);
            netdev_flow_put(dev, &match,...)
            flow_api->flow_put(netdev,...）
                netdev_tc_flow_put()
                    tc_replace_flower(&id, &flower);   // netlink 通信。组装tc-flow指令给tc内核模块
// --- kernel space ------
tc_ctl_tfilter // tc module。不属于ovs代码
    // 代表口卸载
    mlx5e_rep_indr_setup_tc_cb  // mlx5_core.ko
        mlx5e_rep_indr_offload(priv->netdev, type_data, priv,flags);
            mlx5e_configure_flower(netdev, priv, flower, flags)
                mlx5e_tc_add_flow(priv, f, flags, dev, &flow);
                    mlx5e_add_fdb_flow(priv, f, flow_flags,filter_dev, flow);
                        mlx5e_tc_offload_fdb_rules
                            mlx5_eswitch_add_offloaded_rule
                             ==>mlx5_add_flow_rules   //与 rte_flow/ib一样的底层调用接口
                               
// data structure
const struct net_device_ops mlx5e_netdev_ops = {
    .ndo_setup_tc            = mlx5e_setup_tc,
}

udpif_revalidator()
    revalidate(revalidator);
        dpif_flow_dump_next
            dpif->dpif_class->flow_dump_next(thread, flows, max_flows);
                dpif_netdev_flow_dump_next
                    dp_netdev_flow_to_dpif_flow
                        get_dpif_flow_status()
                            dpif_netdev_get_flow_offload_status()
                                netdev_offload_dpdk_flow_get
                                    netdev_dpdk_rte_flow_query_count
                                     ==>rte_flow_query()
// --- rte_flow_query in dpdk -----------
rte_flow_query
    flow_dv_query
        flow_dv_query_count
            _flow_dv_query_count(dev, cnt_idx, &pkts, &bytes);
                cnt = flow_dv_counter_get_by_idx(dev, counter, NULL);
                    MLX5_POOL_GET_CNT(pool, idx % MLX5_COUNTERS_PER_POOL);  // 直接读硬件统计寄存器


mellanox 命令操作码, 寄存器:
enum {
    MLX5_CMD_OP_QUERY_HCA_CAP                 = 0x100,
    MLX5_CMD_OP_QUERY_ADAPTER                 = 0x101,
    MLX5_CMD_OP_INIT_HCA                      = 0x102,
    MLX5_CMD_OP_TEARDOWN_HCA                  = 0x103,
    MLX5_CMD_OP_ENABLE_HCA                    = 0x104,
    MLX5_CMD_OP_DISABLE_HCA                   = 0x105,
    MLX5_CMD_OP_QUERY_PAGES                   = 0x107,
    MLX5_CMD_OP_MANAGE_PAGES                  = 0x108,
    MLX5_CMD_OP_SET_HCA_CAP                   = 0x109,
    MLX5_CMD_OP_QUERY_ISSI                    = 0x10a,
    MLX5_CMD_OP_SET_ISSI                      = 0x10b,
    MLX5_CMD_OP_SET_DRIVER_VERSION            = 0x10d,
    MLX5_CMD_OP_QUERY_SF_PARTITION            = 0x111,
    MLX5_CMD_OP_ALLOC_SF                      = 0x113,
    MLX5_CMD_OP_DEALLOC_SF                    = 0x114,
    MLX5_CMD_OP_SUSPEND_VHCA                  = 0x115,
    MLX5_CMD_OP_RESUME_VHCA                   = 0x116,
    MLX5_CMD_OP_QUERY_VHCA_MIGRATION_STATE    = 0x117,
    MLX5_CMD_OP_SAVE_VHCA_STATE               = 0x118,
    MLX5_CMD_OP_LOAD_VHCA_STATE               = 0x119,
    MLX5_CMD_OP_CREATE_MKEY                   = 0x200,
    MLX5_CMD_OP_QUERY_MKEY                    = 0x201,
    MLX5_CMD_OP_DESTROY_MKEY                  = 0x202,
    MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS        = 0x203,
    MLX5_CMD_OP_PAGE_FAULT_RESUME             = 0x204,
    MLX5_CMD_OP_ALLOC_MEMIC                   = 0x205,
    MLX5_CMD_OP_DEALLOC_MEMIC                 = 0x206,
    MLX5_CMD_OP_MODIFY_MEMIC                  = 0x207,
    MLX5_CMD_OP_CREATE_EQ                     = 0x301,
    MLX5_CMD_OP_DESTROY_EQ                    = 0x302,
    MLX5_CMD_OP_QUERY_EQ                      = 0x303,
    MLX5_CMD_OP_GEN_EQE                       = 0x304,
    MLX5_CMD_OP_CREATE_CQ                     = 0x400,
    MLX5_CMD_OP_DESTROY_CQ                    = 0x401,
    MLX5_CMD_OP_QUERY_CQ                      = 0x402,
    MLX5_CMD_OP_MODIFY_CQ                     = 0x403,
    MLX5_CMD_OP_CREATE_QP                     = 0x500,
    MLX5_CMD_OP_DESTROY_QP                    = 0x501,
    MLX5_CMD_OP_RST2INIT_QP                   = 0x502,
    MLX5_CMD_OP_INIT2RTR_QP                   = 0x503,
    MLX5_CMD_OP_RTR2RTS_QP                    = 0x504,
    MLX5_CMD_OP_RTS2RTS_QP                    = 0x505,
    MLX5_CMD_OP_SQERR2RTS_QP                  = 0x506,
    MLX5_CMD_OP_2ERR_QP                       = 0x507,
    MLX5_CMD_OP_2RST_QP                       = 0x50a,
    MLX5_CMD_OP_QUERY_QP                      = 0x50b,
    MLX5_CMD_OP_SQD_RTS_QP                    = 0x50c,
    MLX5_CMD_OP_INIT2INIT_QP                  = 0x50e,
    MLX5_CMD_OP_CREATE_PSV                    = 0x600,
    MLX5_CMD_OP_DESTROY_PSV                   = 0x601,
    MLX5_CMD_OP_CREATE_SRQ                    = 0x700,
    MLX5_CMD_OP_DESTROY_SRQ                   = 0x701,
    MLX5_CMD_OP_QUERY_SRQ                     = 0x702,
    MLX5_CMD_OP_ARM_RQ                        = 0x703,
    MLX5_CMD_OP_CREATE_XRC_SRQ                = 0x705,
    MLX5_CMD_OP_DESTROY_XRC_SRQ               = 0x706,
    MLX5_CMD_OP_QUERY_XRC_SRQ                 = 0x707,
    MLX5_CMD_OP_ARM_XRC_SRQ                   = 0x708,
    MLX5_CMD_OP_CREATE_DCT                    = 0x710,
    MLX5_CMD_OP_DESTROY_DCT                   = 0x711,
    MLX5_CMD_OP_DRAIN_DCT                     = 0x712,
    MLX5_CMD_OP_QUERY_DCT                     = 0x713,
    MLX5_CMD_OP_ARM_DCT_FOR_KEY_VIOLATION     = 0x714,
    MLX5_CMD_OP_CREATE_XRQ                    = 0x717,
    MLX5_CMD_OP_DESTROY_XRQ                   = 0x718,
    MLX5_CMD_OP_QUERY_XRQ                     = 0x719,
    MLX5_CMD_OP_ARM_XRQ                       = 0x71a,
    MLX5_CMD_OP_QUERY_XRQ_DC_PARAMS_ENTRY     = 0x725,
    MLX5_CMD_OP_SET_XRQ_DC_PARAMS_ENTRY       = 0x726,
    MLX5_CMD_OP_QUERY_XRQ_ERROR_PARAMS        = 0x727,
    MLX5_CMD_OP_RELEASE_XRQ_ERROR             = 0x729,
    MLX5_CMD_OP_MODIFY_XRQ                    = 0x72a,
    MLX5_CMD_OP_QUERY_ESW_FUNCTIONS           = 0x740,
    MLX5_CMD_OP_QUERY_VPORT_STATE             = 0x750,
    MLX5_CMD_OP_MODIFY_VPORT_STATE            = 0x751,
    MLX5_CMD_OP_QUERY_ESW_VPORT_CONTEXT       = 0x752,
    MLX5_CMD_OP_MODIFY_ESW_VPORT_CONTEXT      = 0x753,
    MLX5_CMD_OP_QUERY_NIC_VPORT_CONTEXT       = 0x754,
    MLX5_CMD_OP_MODIFY_NIC_VPORT_CONTEXT      = 0x755,
    MLX5_CMD_OP_QUERY_ROCE_ADDRESS            = 0x760,
    MLX5_CMD_OP_SET_ROCE_ADDRESS              = 0x761,
    MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT       = 0x762,
    MLX5_CMD_OP_MODIFY_HCA_VPORT_CONTEXT      = 0x763,
    MLX5_CMD_OP_QUERY_HCA_VPORT_GID           = 0x764,
    MLX5_CMD_OP_QUERY_HCA_VPORT_PKEY          = 0x765,
    MLX5_CMD_OP_QUERY_VNIC_ENV                = 0x76f,
    MLX5_CMD_OP_QUERY_VPORT_COUNTER           = 0x770,
    MLX5_CMD_OP_ALLOC_Q_COUNTER               = 0x771,
    MLX5_CMD_OP_DEALLOC_Q_COUNTER             = 0x772,
    MLX5_CMD_OP_QUERY_Q_COUNTER               = 0x773,
    MLX5_CMD_OP_SET_MONITOR_COUNTER           = 0x774,
    MLX5_CMD_OP_ARM_MONITOR_COUNTER           = 0x775,
    MLX5_CMD_OP_SET_PP_RATE_LIMIT             = 0x780,
    MLX5_CMD_OP_QUERY_RATE_LIMIT              = 0x781,
    MLX5_CMD_OP_CREATE_SCHEDULING_ELEMENT      = 0x782,
    MLX5_CMD_OP_DESTROY_SCHEDULING_ELEMENT     = 0x783,
    MLX5_CMD_OP_QUERY_SCHEDULING_ELEMENT       = 0x784,
    MLX5_CMD_OP_MODIFY_SCHEDULING_ELEMENT      = 0x785,
    MLX5_CMD_OP_CREATE_QOS_PARA_VPORT         = 0x786,
    MLX5_CMD_OP_DESTROY_QOS_PARA_VPORT        = 0x787,
    MLX5_CMD_OP_ALLOC_PD                      = 0x800,
    MLX5_CMD_OP_DEALLOC_PD                    = 0x801,
    MLX5_CMD_OP_ALLOC_UAR                     = 0x802,
    MLX5_CMD_OP_DEALLOC_UAR                   = 0x803,
    MLX5_CMD_OP_CONFIG_INT_MODERATION         = 0x804,
    MLX5_CMD_OP_ACCESS_REG                    = 0x805,
    MLX5_CMD_OP_ATTACH_TO_MCG                 = 0x806,
    MLX5_CMD_OP_DETACH_FROM_MCG               = 0x807,
    MLX5_CMD_OP_GET_DROPPED_PACKET_LOG        = 0x80a,
    MLX5_CMD_OP_MAD_IFC                       = 0x50d,
    MLX5_CMD_OP_QUERY_MAD_DEMUX               = 0x80b,
    MLX5_CMD_OP_SET_MAD_DEMUX                 = 0x80c,
    MLX5_CMD_OP_NOP                           = 0x80d,
    MLX5_CMD_OP_ALLOC_XRCD                    = 0x80e,
    MLX5_CMD_OP_DEALLOC_XRCD                  = 0x80f,
    MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN        = 0x816,
    MLX5_CMD_OP_DEALLOC_TRANSPORT_DOMAIN      = 0x817,
    MLX5_CMD_OP_QUERY_CONG_STATUS             = 0x822,
    MLX5_CMD_OP_MODIFY_CONG_STATUS            = 0x823,
    MLX5_CMD_OP_QUERY_CONG_PARAMS             = 0x824,
    MLX5_CMD_OP_MODIFY_CONG_PARAMS            = 0x825,
    MLX5_CMD_OP_QUERY_CONG_STATISTICS         = 0x826,
    MLX5_CMD_OP_ADD_VXLAN_UDP_DPORT           = 0x827,
    MLX5_CMD_OP_DELETE_VXLAN_UDP_DPORT        = 0x828,
    MLX5_CMD_OP_SET_L2_TABLE_ENTRY            = 0x829,
    MLX5_CMD_OP_QUERY_L2_TABLE_ENTRY          = 0x82a,
    MLX5_CMD_OP_DELETE_L2_TABLE_ENTRY         = 0x82b,
    MLX5_CMD_OP_SET_WOL_ROL                   = 0x830,
    MLX5_CMD_OP_QUERY_WOL_ROL                 = 0x831,
    MLX5_CMD_OP_CREATE_LAG                    = 0x840,
    MLX5_CMD_OP_MODIFY_LAG                    = 0x841,
    MLX5_CMD_OP_QUERY_LAG                     = 0x842,
    MLX5_CMD_OP_DESTROY_LAG                   = 0x843,
    MLX5_CMD_OP_CREATE_VPORT_LAG              = 0x844,
    MLX5_CMD_OP_DESTROY_VPORT_LAG             = 0x845,
    MLX5_CMD_OP_CREATE_TIR                    = 0x900,
    MLX5_CMD_OP_MODIFY_TIR                    = 0x901,
    MLX5_CMD_OP_DESTROY_TIR                   = 0x902,
    MLX5_CMD_OP_QUERY_TIR                     = 0x903,
    MLX5_CMD_OP_CREATE_SQ                     = 0x904,
    MLX5_CMD_OP_MODIFY_SQ                     = 0x905,
    MLX5_CMD_OP_DESTROY_SQ                    = 0x906,
    MLX5_CMD_OP_QUERY_SQ                      = 0x907,
    MLX5_CMD_OP_CREATE_RQ                     = 0x908,
    MLX5_CMD_OP_MODIFY_RQ                     = 0x909,
    MLX5_CMD_OP_SET_DELAY_DROP_PARAMS         = 0x910,
    MLX5_CMD_OP_DESTROY_RQ                    = 0x90a,
    MLX5_CMD_OP_QUERY_RQ                      = 0x90b,
    MLX5_CMD_OP_CREATE_RMP                    = 0x90c,
    MLX5_CMD_OP_MODIFY_RMP                    = 0x90d,
    MLX5_CMD_OP_DESTROY_RMP                   = 0x90e,
    MLX5_CMD_OP_QUERY_RMP                     = 0x90f,
    MLX5_CMD_OP_CREATE_TIS                    = 0x912,
    MLX5_CMD_OP_MODIFY_TIS                    = 0x913,
    MLX5_CMD_OP_DESTROY_TIS                   = 0x914,
    MLX5_CMD_OP_QUERY_TIS                     = 0x915,
    MLX5_CMD_OP_CREATE_RQT                    = 0x916,
    MLX5_CMD_OP_MODIFY_RQT                    = 0x917,
    MLX5_CMD_OP_DESTROY_RQT                   = 0x918,
    MLX5_CMD_OP_QUERY_RQT                     = 0x919,
    MLX5_CMD_OP_SET_FLOW_TABLE_ROOT		  = 0x92f,
    MLX5_CMD_OP_CREATE_FLOW_TABLE             = 0x930,
    MLX5_CMD_OP_DESTROY_FLOW_TABLE            = 0x931,
    MLX5_CMD_OP_QUERY_FLOW_TABLE              = 0x932,
    MLX5_CMD_OP_CREATE_FLOW_GROUP             = 0x933,
    MLX5_CMD_OP_DESTROY_FLOW_GROUP            = 0x934,
    MLX5_CMD_OP_QUERY_FLOW_GROUP              = 0x935,
    MLX5_CMD_OP_SET_FLOW_TABLE_ENTRY          = 0x936,
    MLX5_CMD_OP_QUERY_FLOW_TABLE_ENTRY        = 0x937,
    MLX5_CMD_OP_DELETE_FLOW_TABLE_ENTRY       = 0x938,
    MLX5_CMD_OP_ALLOC_FLOW_COUNTER            = 0x939,
    MLX5_CMD_OP_DEALLOC_FLOW_COUNTER          = 0x93a,
    MLX5_CMD_OP_QUERY_FLOW_COUNTER            = 0x93b,
    MLX5_CMD_OP_MODIFY_FLOW_TABLE             = 0x93c,
    MLX5_CMD_OP_ALLOC_PACKET_REFORMAT_CONTEXT = 0x93d,
    MLX5_CMD_OP_DEALLOC_PACKET_REFORMAT_CONTEXT = 0x93e,
    MLX5_CMD_OP_QUERY_PACKET_REFORMAT_CONTEXT = 0x93f,
    MLX5_CMD_OP_ALLOC_MODIFY_HEADER_CONTEXT   = 0x940,
    MLX5_CMD_OP_DEALLOC_MODIFY_HEADER_CONTEXT = 0x941,
    MLX5_CMD_OP_QUERY_MODIFY_HEADER_CONTEXT   = 0x942,
    MLX5_CMD_OP_FPGA_CREATE_QP                = 0x960,
    MLX5_CMD_OP_FPGA_MODIFY_QP                = 0x961,
    MLX5_CMD_OP_FPGA_QUERY_QP                 = 0x962,
    MLX5_CMD_OP_FPGA_DESTROY_QP               = 0x963,
    MLX5_CMD_OP_FPGA_QUERY_QP_COUNTERS        = 0x964,
    MLX5_CMD_OP_CREATE_GENERAL_OBJECT         = 0xa00,
    MLX5_CMD_OP_MODIFY_GENERAL_OBJECT         = 0xa01,
    MLX5_CMD_OP_QUERY_GENERAL_OBJECT          = 0xa02,
    MLX5_CMD_OP_DESTROY_GENERAL_OBJECT        = 0xa03,
    MLX5_CMD_OP_CREATE_UCTX                   = 0xa04,
    MLX5_CMD_OP_DESTROY_UCTX                  = 0xa06,
    MLX5_CMD_OP_CREATE_UMEM                   = 0xa08,
    MLX5_CMD_OP_DESTROY_UMEM                  = 0xa0a,
    MLX5_CMD_OP_SYNC_STEERING                 = 0xb00,
    MLX5_CMD_OP_QUERY_VHCA_STATE              = 0xb0d,
    MLX5_CMD_OP_MODIFY_VHCA_STATE             = 0xb0e,
    MLX5_CMD_OP_SYNC_CRYPTO                   = 0xb12,
    MLX5_CMD_OP_ALLOW_OTHER_VHCA_ACCESS       = 0xb16,
    MLX5_CMD_OP_MAX
};
net/mlx5_core：使用硬件寄存器描述头文件，添加自动生成的头文件来描述硬件寄存器以及设置/获取值的宏集。 这些宏进行静态检查以避免溢出、处理字节顺序，并总体上提供了一种干净的命令编码方式。 目前头文件很小，我们将在使用宏时添加结构。 一些命令已从命令枚举中删除，因为当前不支持它们，将在支持可用时添加



static const struct rdma_nl_cbs nldev_cb_table[RDMA_NLDEV_NUM_OPS] = {
    [RDMA_NLDEV_CMD_GET] = {
        .doit = nldev_get_doit,
        .dump = nldev_get_dumpit,
    },
如果用户提供特定索引，我们可以使用 .doit 回调加速查询，并在之后保存完整转储和过滤
nldev_get_dumpit _nldev_get_dumpit
    rdma_dev_access_netns
    _nldev_get_dumpit
        nlmsg_end



ice intel debug logging 配置固件调试日志:
The format to set the log levels for a module are:
  # echo <log level> > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/<module>
The supported log levels are:
      *	none
      *	error
      *	warning
      *	normal
      *	verbose
Each level includes the messages from the previous/lower level
The modules that are supported are:
      *	general
      *	ctrl
      *	link
      *	link_topo
      *	dnl
      *	i2c
      *	sdp
      *	mdio
      *	adminq
      *	hdma
      *	lldp
      *	dcbx
      *	dcb
      *	xlr
      *	nvm
      *	auth
      *	vpd
      *	iosf
      *	parser
      *	sw
      *	scheduler
      *	txq
      *	rsvd
      *	post
      *	watchdog
      *	task_dispatch
      *	mng
      *	synce
      *	health
      *	tsdrv
      *	pfreg
      *	mdlver
      *	all
The module 'all' is a special module which allows the user to read or
write to all of the modules.
The following example command would set the DCB module to the 'normal'
log level:
  # echo normal > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/dcb
If the user wants to set the DCB, Link, and the AdminQ modules to
'verbose' then the commands are:
  # echo verbose > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/dcb
  # echo verbose > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/link
  # echo verbose > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/adminq
If the user wants to set all modules to the 'warning' level then the
command is:
  # echo warning > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/all
If the user wants to disable logging for a module then they can set the
level to 'none'. An example setting the 'watchdog' module is:
  # echo none > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/watchdog
If the user wants to see what the log level is for a specific module
then the command is:
  # cat /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/dcb
This will return the log level for the DCB module. If the user wants to
see the log level for all the modules then the command is:
  # cat /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/modules/all
Writing to the module file will update the configuration, but NOT enable the
configuration (that is a separate command).
In addition to configuring the modules, the user can also configure the
number of log messages (nr_messages) to include in a single Admin Receive
Queue (ARQ) event.The range is 1-128 (1 means push every log message, 128
means push only when the max AQ command buffer is full). The suggested
value is 10.
To see/change the resolution the user can read/write the
'fwlog/nr_messages' file. An example changing the value to 50 is
  # echo 50 > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/nr_messages
To see the current value of 'nr_messages' then the command is:
  # cat /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/nr_messages

ice: add ability to read and configure FW log data
Once logging is enabled the user should read the data from the 'data'
file. The data is in the form of a binary blob that can be sent to Intel
for decoding. To read the data use a command like:
  # cat /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/data > log_data.bin
If the user wants to clear the FW log data that has been stored in the
driver then they can write any value to the 'data' file and that will clear
the data. An example is:
  # echo 34 > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/data
In addition to being able to read the data the user can configure how
much memory is used to store FW log data. This allows the user to
increase/decrease the amount of memory based on the users situation.
The data is stored such that if the memory fills up then the oldest data
will get overwritten in a circular manner. To change the amount of
memory the user can write to the 'log_size' file like this:
  # echo <value> > /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/log_size
Where <value> is one of 128K, 256K, 512K, 1M, and 2M. The default value
is 1M.
The user can see the current value of 'log_size' by reading the file:
  # cat /sys/kernel/debug/ice/0000\:18\:00.0/fwlog/log_size
At this point the user have SF devlink instance with auxiliary device
for the Ethernet functionality only.



timeout type:
enum mlx5_timeouts_types {
    /* pre init timeouts (not read from FW) */
    MLX5_TO_FW_PRE_INIT_TIMEOUT_MS,
    MLX5_TO_FW_PRE_INIT_ON_RECOVERY_TIMEOUT_MS,
    MLX5_TO_FW_PRE_INIT_WARN_MESSAGE_INTERVAL_MS,
    MLX5_TO_FW_PRE_INIT_WAIT_MS,

    /* init segment timeouts */
    MLX5_TO_FW_INIT_MS,
    MLX5_TO_CMD_MS,

    /* DTOR timeouts */
    MLX5_TO_PCI_TOGGLE_MS,
    MLX5_TO_HEALTH_POLL_INTERVAL_MS,
    MLX5_TO_FULL_CRDUMP_MS,
    MLX5_TO_FW_RESET_MS,
    MLX5_TO_FLUSH_ON_ERROR_MS,
    MLX5_TO_PCI_SYNC_UPDATE_MS,
    MLX5_TO_TEARDOWN_MS,
    MLX5_TO_FSM_REACTIVATE_MS,
    MLX5_TO_RECLAIM_PAGES_MS,
    MLX5_TO_RECLAIM_VFS_PAGES_MS,
    MLX5_TO_RESET_UNLOAD_MS,

    MAX_TIMEOUT_TYPES
};

default timeout:
static const u32 tout_def_sw_val[MAX_TIMEOUT_TYPES] = {
    [MLX5_TO_FW_PRE_INIT_TIMEOUT_MS] = 120000,
    [MLX5_TO_FW_PRE_INIT_ON_RECOVERY_TIMEOUT_MS] = 7200000,
    [MLX5_TO_FW_PRE_INIT_WARN_MESSAGE_INTERVAL_MS] = 20000,
    [MLX5_TO_FW_PRE_INIT_WAIT_MS] = 2,
    [MLX5_TO_FW_INIT_MS] = 2000,
    [MLX5_TO_CMD_MS] = 60000,
    [MLX5_TO_PCI_TOGGLE_MS] =  2000,
    [MLX5_TO_HEALTH_POLL_INTERVAL_MS] =  2000,
    [MLX5_TO_FULL_CRDUMP_MS] = 60000,
    [MLX5_TO_FW_RESET_MS] = 60000,
    [MLX5_TO_FLUSH_ON_ERROR_MS] = 2000,
    [MLX5_TO_PCI_SYNC_UPDATE_MS] = 5000,
    [MLX5_TO_TEARDOWN_MS] = 3000,
    [MLX5_TO_FSM_REACTIVATE_MS] = 5000,
    [MLX5_TO_RECLAIM_PAGES_MS] = 5000,
    [MLX5_TO_RECLAIM_VFS_PAGES_MS] = 120000,
    [MLX5_TO_RESET_UNLOAD_MS] = 300000
};


mlx5_function_setup



ip分片:
net/ipv4/ip_output.c
int ip_do_fragment



dev_alloc_pages 函数，用于分配多个连续的物理内存页，分配数量只能是2的非负整数次幂




.port_new = mlx5_devlink_sf_port_new
mlx5_sf_add
    mlx5_eswitch_load_sf_vport


struct devlink_port {
    ...
}
引入 devlink 基础设施，为驱动程序引入 devlink 基础设施，以通过通用 Netlink 接口注册并公开给用户空间。 定义了两个基本对象： 
devlink - 每个“父设备”都有一个实例，例如交换机 ASIC (芯片)
devlink_port - 设备的每个物理端口都有一个实例。 这个初始部分实现了将对象基本获取/转储到用户空间。 此外，还实现了端口分配器和端口类型设置

makefile:
obj-$(CONFIG_NET_DEVLINK)	+= devlink/

code_style:
devlink：将代码移动到专用目录，devlink 代码很难在一个文件中使用 13kLoC 进行导航。 我真的很喜欢 Michal 将 ethtool 分成每个命令文件和核心的方式。 将其全部拆分可能太多了，但我们至少可以将核心部分从每个 cmd 实现中分离出来，并将其放在一个目录中，以便新命令可以是单独的文件。 移动代码，后续commit会做部分分割

core_code:
drivers/net/ethernet/mellanox/mlx5/core/devlink.c


mlx5_devlink_ops



create_cq:
IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL -> ib_uverbs_create_comp_channel
ib_uverbs_init_event_queue



ovs:
module_init(dp_init) -> net：添加 Open vSwitch 内核组件。 Open vSwitch 是一款针对虚拟化环境的多层以太网交换机。 除了支持传统硬件交换机所期望的各种功能之外，它还支持细粒度的编程扩展和基于流的网络控制。 这种控制在各种应用程序中都很有用，但在多服务器虚拟化部署中尤其重要，多服务器虚拟化部署的特点通常是高度动态的端点以及需要维护多个租户的逻辑抽象。 Open vSwitch 数据路径为数据包转发提供了内核内快速路径。 它由用户空间守护进程 ovs-vswitchd 进行补充，该守护进程能够接受来自各种来源的配置并将其转换为数据包处理规则。 请参阅 http://openvswitch.org 了解更多信息和用户空间实用程序
action_fifos_init
...


int netif_rx(struct sk_buff *skb)

skeleton.c


set_64bit_val





...
irdma_init_roce_device
    ib_set_device_ops(&iwdev->ibdev, &irdma_roce_dev_ops);

static const struct ib_device_ops irdma_roce_dev_ops = {
    .attach_mcast = irdma_attach_mcast,
    .create_ah = irdma_create_ah,
    .create_user_ah = irdma_create_user_ah,
    .destroy_ah = irdma_destroy_ah,
    .detach_mcast = irdma_detach_mcast,
    .get_link_layer = irdma_get_link_layer,
    .get_port_immutable = irdma_roce_port_immutable,
    .modify_qp = irdma_modify_qp_roce,
    .query_ah = irdma_query_ah,
    .query_pkey = irdma_query_pkey,
};



ibv_modify_qp -> IB_USER_VERBS_EX_CMD_MODIFY_QP -> ib_uverbs_ex_modify_qp
    modify_qp
        uobj_get_obj_read UVERBS_OBJECT_QP
        校验参数
        ...
        ib_modify_qp_with_udata
            _ib_modify_qp -> IB/core：将 DMAC 解析限制为用户空间 QP，当前 ah_attr 由 ib_cm 层针对基于 rdma_cm 的应用程序进行初始化。 对于 RoCE 传输，ah_attr.roce.dmac 已由 ib_cm、rdma_cm 从 wc、路径记录、路由解析、显式路径记录设置（取决于主动方或被动方 QP）初始化。 因此避免为内核消费者的 QP 解析 DMAC
                attr_mask & IB_QP_AV -> IBV_QP_AV，主要用来指示内核做地址解析，对于RoCE，则进行L3到MAC地址的转换
                rdma_fill_sgid_attr
                    rdma_check_ah_attr
                    rdma_ah_retrieve_grh
                    rdma_get_gid_attr
                        rdma_gid_table
                        get_gid_entry
                ib_resolve_eth_dmac -> 调用ib_resolve_eth_dmac解析remote gid对应的MAC地址
                    ...
                    rdma_resolve_ip resolve_cb
                        complete -> IB/core：verbs/cm 结构中的以太网 L2 属性 ，此补丁添加了对 verbs/cm/cma 结构中的以太网 L2 属性的支持。 在处理 L2 以太网时，我们应该以与使用 IB L2（和 L4 PKEY）属性类似的方式使用 smac、dmac、vlan ID 和优先级。 因此，这些属性被添加到以下结构中： * ib_ah_attr - 添加了 dmac * ib_qp_attr - 添加了 smac 和 vlan_id，（sl 保留 vlan 优先级） * ib_wc - 添加了 smac、vlan_id * ib_sa_path_rec - 添加了 smac、dmac、vlan_id * cm_av - 添加了 smac 和 vlan_id 对于路径记录结构，在将其打包为有线格式时特别注意避免新字段，因此我们不会破坏 IB CM 和 SA 有线协议。 在主动侧，CM 被填充。 其内部结构来自 ULP 提供的路径。 我们添加了 ETH L2 属性并将它们放入 CM 地址句柄（struct cm_av）中。 在被动侧，CM 从与 REQ 消息关联的 WC 中填充其内部结构。 我们添加了从 WC 获取 ETH L2 属性的内容。 当硬件驱动程序在 WC 中提供所需的 ETH L2 属性时，它们会设置 IB_WC_WITH_SMAC 和 IB_WC_WITH_VLAN 标志。 IB 核心代码检查这些标志是否存在，如果没有，则从 ib_init_ah_from_wc() 辅助函数进行地址解析。 ib_modify_qp_is_ok 也被更新以考虑链路层。 有些参数对于以太网链路层是必需的，而对于IB来说则无关。 修改供应商驱动程序以支持新的函数签名
                rdma_lag_get_ah_roce_slave
                    rdma_read_gid_attr_ndev_rcu
                    rdma_get_xmit_slave_udp
                        rdma_build_skb
                        netdev_get_xmit_slave RDMA_LAG_FLAGS_HASH_ALL_SLAVES
                rdma_counter_bind_qp_auto
                ib_security_modify_qp -> IB/核心：在 QP 上强制执行 PKey 安全性，添加新的 LSM 挂钩以分配和释放安全上下文并检查访问 PKey 的权限。 创建和销毁 QP 时分配和释放安全上下文。 此上下文用于控制对 PKey 的访问。 当请求修改 QP 来更改端口、PKey 索引或备用路径时，请检查 QP 是否具有对该端口子网前缀上的 PKey 表索引中的 PKey 的权限。 如果 QP 是共享的，请确保 QP 的所有句柄也具有访问权限。 存储 QP 正在使用的端口和 PKey 索引。 重置到初始化转换后，用户可以独立修改端口、PKey 索引和备用路径。 因此，端口和 PKey 设置更改可以是先前设置和新设置的合并。 为了在 PKey 表或子网前缀更改时维持访问控制，请保留每个端口上使用每个 PKey 索引的所有 QP 的列表。 如果发生更改，则使用该设备和端口的所有 QP 都必须强制执行新缓存设置的访问权限。 这些更改将事务添加到 QP 修改过程中。 如果修改失败，则必须保持与旧端口和 PKey 索引的关联；如果修改成功，则必须将其删除。 必须在修改之前建立与新端口和 PKey 索引的关联，如果修改失败则将其删除。 1. 当 QP 被修改为特定端口时，PKey 索引或备用路径将该 QP 插入到适当的列表中。 2. 检查访问新设置的权限。 3. 如果步骤 2 授予访问权限，则尝试修改 QP。 4a. 如果步骤 2 和 3 成功，则删除任何先前的关联。 4b. 如果以太失败，请删除新的设置关联。 如果 PKey 表或子网前缀发生更改，则遍历 QP 列表并检查它们是否具有权限。 如果没有，则将 QP 发送到错误状态并引发致命错误事件。 如果它是共享 QP，请确保共享 real_qp 的所有 QP 也具有权限。 如果拥有安全结构的 QP 被拒绝访问，则安全结构将被标记为此类，并且 QP 将被添加到 error_list 中。 一旦将 QP 移至错误完成，安全结构标记就会被清除。 正确维护列表会将 QP 销毁转变为事务。 设备的硬件驱动程序释放 ib_qp 结构，因此当销毁正在进行时，ib_qp_security 结构中的 ib_qp 指针未定义。 当销毁过程开始时，ib_qp_security 结构被标记为正在销毁。 这可以防止对 QP 指针采取任何操作。 QP 成功销毁后，它仍然可以列在 error_list 上，等待该流处理它，然后再清理结构。 如果销毁失败，则 QP 端口和 PKey 设置将重新插入到适当的列表中，销毁标志将被清除，并强制执行访问控制，以防在销毁流程期间发生任何缓存更改。 为了保持安全更改隔离，使用新文件来保存与安全相关的功能
                    port_pkey_list_insert -> 在检查权限之前，将此 QP 添加到新端口和 pkey 设置的列表中，以防发生并发缓存更新。 遍历列表进行缓存更改不会获取安全互斥体，除非将 QP 发送到错误
                    check_qp_port_pkey_settings
                        get_pkey_and_subnet_prefix
                            ib_get_cached_pkey
                            ib_get_cached_subnet_prefix
                        enforce_qp_pkey_security
                    modify_qp -> .modify_qp = irdma_modify_qp_roce
                rdma_lag_put_ah_roce_slave
        release_qp:
        rdma_lookup_put_uobject

irdma_uk_rdma_write
irdma_uk_rdma_read
irdma_uk_cq_poll_cmpl


/proc/pid/pagemap - an array mapping virtual pages to pfns, 如果页面不存在但在交换中，则 PFN 包含交换文件号的编码以及页面在交换中的偏移量。 未映射的页面返回空 PFN。 这允许精确确定哪些页面被映射（或在交换中）并比较进程之间的映射页面。 * 此接口的高效用户将使用 /proc/pid/maps 来确定实际映射的内存区域，并使用 llseek 跳过未映射的区域
pagemap_read -> Maps4：添加 /proc/pid/pagemap 接口，该接口为地址空间中的每个页面提供到其物理页帧号的映射，允许精确确定哪些页面被映射以及哪些页面在进程之间共享。 此版本中的新增内容： - 标头再次消失（根据 Dave Hansen 和 Alan Cox 的建议） - 64 位条目（根据与 Andi Kleen 的讨论） - 交换导出的 pte 信息（来自 Dave Hansen） - 页面遍历器回调以查找漏洞（来自 Dave Hansen） - 直接 put_user I/O（根据 Rusty Russell 的建议）此补丁折叠在清理中并交换 Dave Hansen 的 PTE 支持
    file_ns_capable
    mmap_read_lock_killable
    untagged_addr_remote
    mmap_read_lock_killable
    walk_page_range(mm, start_vaddr, end, &pagemap_ops, &pm) -> walk_page_range - 使用回调遍历内存映射的页表：起始地址：结束地址：为树的每个级别调用的回调集递归地遍历 VMA 中内存区域的页表，调用提供的回调。 回调按顺序调用（第一个 PGD、第一个 PUD、第一个 PMD、第一个 PTE、第二个 PTE...第二个 PMD 等）。 如果省略较低级别的回调，则行走深度会减少。 每个回调接收一个入口指针以及关联范围的开始和结束，以及用于访问 ->private 或 ->mm 字段的原始 mm_walk 的副本。 通常不加锁，但分割透明大页可能会加页表锁。 如果需要，底层迭代器将从 highmem 映射 PTE 目录。 如果任何回调返回非零值，则遍历将中止并将返回值传播回调用者。 否则返回 0。 如果 walk->hugetlb_entry 为 !NULL，则 walk->mm->mmap_sem 必须至少保持读取状态
    copy_to_user

static const struct mm_walk_ops pagemap_ops = {
    .pmd_entry	= pagemap_pmd_range,
    .pte_hole	= pagemap_pte_hole,
    .hugetlb_entry	= pagemap_hugetlb_range,
    .walk_lock	= PGWALK_RDLOCK,
};

pagemap_pmd_range -> pagemap：将 mm 传递给 pagewalkers ，我们现在至少需要这个来检测大页，因为 powerpc 需要 vm_area_struct 来确定虚拟地址是否引用大页（它的 pmd_huge() 不起作用）。 对于其他一些用户来说它也可能派上用场
    pmd_trans_huge_lock
    ...
    for pte
        内核态实现pagemap proc接口的代码位于: fs/proc/task_mmu.c, 把PTE转换为pagemap_entry
        pte_to_pagemap_entry -> proc：报告 /proc/pid/pagemap 中的文件/匿名位，这是安德鲁提议的实现，扩展页面映射文件位以报告任务工作集缺少的内容。 工作集检测的问题是多方面的。 在 criu（检查点/恢复）项目中，我们将任务的内存转储到图像文件中，为了正确执行此操作，我们需要检测映射中的哪些页面真正在使用。 我虽然可以帮助解决这个问题，但 mincore 系统调用却没有。 首先，它不报告交换的页面，因此我们无法找出要转储的匿名映射的哪些部分。 接下来，它会报告页面缓存中存在的页面，即使它们没有被映射，但这并不意味着它们没有受到威胁。 请注意，交换页的问题至关重要——我们必须将交换页转储到映像文件。 但是文件页面的问题是优化 - 我们可以将所有文件页面进行映像，这是正确的，但是如果我们知道页面未映射或未受到限制，我们可以将它们从转储文件中删除。 转储仍然是自洽的，尽管大小明显较小（在实际应用程序中最多小 10 倍）。 Andrew 注意到，proc pagemap 文件解决了上述 3 个问题中的 2 个——它报告页面是否存在或交换，并且不报告未映射的页面缓存页面。 但是，它无法区分受限制的文件页面和不受限制的文件页面。 我想在此文件中最后一个未使用的位来报告映射到相应 pte 的页面是否为 PageAnon
            pte_present(pte)
            frame = pte_pfn(pte) -> 
            make_pme(frame, flags)
        add_to_pagemap
    ...




smap: 基于映射的扩展，显示每个映射的内存消耗以及与其关联的标志, scan page table
static const struct mm_walk_ops smaps_walk_ops = {
    .pmd_entry		= smaps_pte_range,
    .hugetlb_entry		= smaps_hugetlb_range,
    .walk_lock		= PGWALK_RDLOCK,
};
smaps_pte_range
    smaps_pte_entry


show_smap
    smap_gather_stats
    show_map_vma
    __show_smap
    seq_printf


irdma：为英特尔(R) 以太网控制器 E810 添加 RDMA 驱动程序，这是针对英特尔(R) 以太网控制器 E810 的 RDMA FreeBSD 驱动程序（称为 irdma）的初始提交。 以每 PF 方式支持 RoCEv2 和 iWARP 协议，RoCEv2 为默认协议。 测试已使用 krping 工具、perftest、ucmatose、rping、ud_pingpong、rc_pingpong 等完成, https://cgit.freebsd.org/src/commit/?id=42bad04a2156


struct ice_vsi




static struct class ib_class = {
    .name    = "infiniband",
    .dev_release = ib_device_release,
    .dev_uevent = ib_device_uevent,
    .ns_type = &net_ns_type_operations,
    .namespace = net_namespace,
};



iavf_register_client


drivers/net/ethernet/hisilicon/Makefile
net：添加海思网络子系统hnae框架支持，HNAE（海思网络加速引擎）是为海思网络加速引擎提供统一环形缓冲区接口的框架。 通过该接口，上层可以有意地充当以太网驱动程序、ODP驱动程序或其他服务驱动程序


capability:
pci_find_capability

read pcie config space of device:
u32 read_pci_config
    outl(0x80000000 | (bus<<16) | (slot<<11) | (func<<8) | offset, 0xcf8);



drivers/dma/dmatest.c
late_initcall(dmatest_init);


三星:
drivers/dma/pl330.c
pd->device_issue_pending = pl330_issue_pending;
dma_async_issue_pending
    device_issue_pending
xdev->common.device_issue_pending = xilinx_dma_issue_pending;
chan->start_transfer = xilinx_dma_start_transfer

struct dma_device

desc->txd.tx_submit = pl330_tx_submit;


module_amba_driver(pl330_driver);
dma_async_device_register


Xilinx media platform drivers
drivers/media/platform/xilinx/xilinx-dma.c
dmaengine_prep_interleaved_dma


dmaengine_prep_interleaved_dma
dmaengine_submit


https://www.kernel.org/doc/html/v4.9/media/kapi/v4l2-videobuf2.html
static const struct vb2_ops xvip_dma_queue_qops = {
    .queue_setup = xvip_dma_queue_setup,
    .buf_prepare = xvip_dma_buffer_prepare,
    .buf_queue = xvip_dma_buffer_queue,
    .wait_prepare = vb2_ops_wait_prepare,
    .wait_finish = vb2_ops_wait_finish,
    .start_streaming = xvip_dma_start_streaming,
    .stop_streaming = xvip_dma_stop_streaming,
};

xvip_dma_buffer_queue


static struct platform_driver xvip_composite_driver = {
    .driver = {
        .name = "xilinx-video",
        .of_match_table = xvip_composite_of_id_table,
    },
    .probe = xvip_composite_probe,
    .remove_new = xvip_composite_remove,
};

module_platform_driver(xvip_composite_driver);
xvip_graph_init
xvip_graph_dma_init
xvip_graph_dma_init_one
    xvip_dma_init
        ...
        dma->queue.ops = &xvip_dma_queue_qops;
        dma->dma = dma_request_chan(dma->xdev->dev, name);


https://github.com/Xilinx/linux-xlnx/tree/xilinx-v14.4



drivers/infiniband/core/ucma.c
static ssize_t (*ucma_cmd_table[])(struct ucma_file *file,
                   const char __user *inbuf,
                   int in_len, int out_len) = {
    [RDMA_USER_CM_CMD_CREATE_ID] 	 = ucma_create_id,
    [RDMA_USER_CM_CMD_DESTROY_ID]	 = ucma_destroy_id,
    [RDMA_USER_CM_CMD_BIND_IP]	 = ucma_bind_ip,
    [RDMA_USER_CM_CMD_RESOLVE_IP]	 = ucma_resolve_ip,
    [RDMA_USER_CM_CMD_RESOLVE_ROUTE] = ucma_resolve_route,
    [RDMA_USER_CM_CMD_QUERY_ROUTE]	 = ucma_query_route,
    [RDMA_USER_CM_CMD_CONNECT]	 = ucma_connect,
    [RDMA_USER_CM_CMD_LISTEN]	 = ucma_listen,
    [RDMA_USER_CM_CMD_ACCEPT]	 = ucma_accept,
    [RDMA_USER_CM_CMD_REJECT]	 = ucma_reject,
    [RDMA_USER_CM_CMD_DISCONNECT]	 = ucma_disconnect,
    [RDMA_USER_CM_CMD_INIT_QP_ATTR]	 = ucma_init_qp_attr,
    [RDMA_USER_CM_CMD_GET_EVENT]	 = ucma_get_event,
    [RDMA_USER_CM_CMD_GET_OPTION]	 = NULL,
    [RDMA_USER_CM_CMD_SET_OPTION]	 = ucma_set_option,
    [RDMA_USER_CM_CMD_NOTIFY]	 = ucma_notify,
    [RDMA_USER_CM_CMD_JOIN_IP_MCAST] = ucma_join_ip_multicast,
    [RDMA_USER_CM_CMD_LEAVE_MCAST]	 = ucma_leave_multicast,
    [RDMA_USER_CM_CMD_MIGRATE_ID]	 = ucma_migrate_id,
    [RDMA_USER_CM_CMD_QUERY]	 = ucma_query,
    [RDMA_USER_CM_CMD_BIND]		 = ucma_bind,
    [RDMA_USER_CM_CMD_RESOLVE_ADDR]	 = ucma_resolve_addr,
    [RDMA_USER_CM_CMD_JOIN_MCAST]	 = ucma_join_multicast
};

UCMA_CMD_CONNECT -> static ssize_t (*ucma_cmd_table[]) -> static ssize_t ucma_connect
    copy_from_user
    ucma_get_ctx_dev
    ucma_copy_conn_param -> RDMA/cma：为AF_IB设置qkey，允许用户在使用AF_IB时指定qkey。 qkey 被添加到 struct rdma_ucm_conn_param 中代替保留字段，但为了向后兼容，仅当关联的 rdma_cm_id 使用 AF_IB 时才可访问
        ...
        dst->qkey = (id->route.addr.src_addr.ss_family == AF_IB) ? src->qkey : 0;
    rdma_connect_ece -> RDMA/ucma：扩展ucma_connect以接收ECE参数，CMID的主动方通过librdmacm的rdma_connect()和内核的ucma_connect()发起连接。 扩展 UCMA 接口来处理这些新参数
        rdma_connect(id, conn_param) -> rdma_connect_locked
            cma_comp_exch(id_priv, RDMA_CM_ROUTE_RESOLVED, RDMA_CM_CONNECT)
            rdma_cap_ib_cm(id->device, id->port_num) -> rdma_cap_ib_cm - 检查设备端口是否具有 Infiniband Communication Manager 功能。 @device：要检查的设备 @port_num：要检查的端口号 InfiniBand 通信管理器是通过通用服务接口 (GSI) 访问的许多预定义通用服务代理 (GSA) 之一。 它的作用是促进节点之间连接的建立以及已建立的连接的其他管理相关任务。 返回：如果端口支持 IB CM，则返回 true（但这并不能保证 CM 实际正在运行）
                RDMA_CORE_CAP_IB_CM
            if (id->qp_type == IB_QPT_UD) -> cma_resolve_ib_udp -> RDMA/cma：添加对 RDMA_PS_UDP 的支持，允许通过 rdma_cm 使用 UD QP，以便为使用 SIDR 解析数据报消息的 IB 地址提供地址转换服务
            or cma_connect_ib
                check_add_overflow
                ib_create_cm_id(id_priv->id.device, cma_ib_handler, id_priv)
                    cm_alloc_id_priv -> RDMA/cm：简化建立监听cm_id
                        RB_CLEAR_NODE(&cm_id_priv->service_node) -> rb_tree
                        init_completion(&cm_id_priv->comp)
                        xa_alloc_cyclic -> 在 XArray 中找到存储此条目的位置
                trace_cm_send_req
                ib_send_cm_req
                    msg->context[1] = (void *)(unsigned long)IB_CM_REQ_SENT
                    ib_post_send_mad -> [IB] 修复 MAD 层 DMA 映射，以避免在映射后触及数据缓冲区。MAD 层在 DMA 映射完成后触及用于发送的数据缓冲区，从而违反了 DMA API。 这会导致非缓存一致性架构出现问题，因为执行 DMA 的设备不会看到仅存在于 CPU 缓存中的有效负载缓冲区的更新。 通过让所有 MAD 使用者使用 ib_create_send_mad() 分配其发送缓冲区，并将 DMA 映射移动到 MAD 层，以便可以在调用 send 之前（以及 MAD 层对发送缓冲区进行任何修改之后）完成此操作，可以解决此问题。 在非缓存一致性 PowerPC 440SPe 系统上进行测试
                        ib_mad_enforce_security -> IB/核心：在管理数据报上强制执行安全性，在创建和销毁 MAD 代理时分配和释放安全上下文。 该上下文用于控制对 PKey 的访问以及发送和接收 SMP。 发送或接收 MAD 时，检查代理是否有权访问端口子网前缀的 PKey。 在 SMI QP 的 MAD 和监听代理注册期间，检查调用进程是否有权访问管理子网并向 LSM 注册回调以获取策略更改通知。 当发生策略更改通知时，重新检查权限并设置一个标志，指示允许发送和接收 SMP。 发送和接收 MAD 时，如果代理位于 SMI QP 上，请检查代理是否有权访问 SMI。 由于安全策略可以更改，因此在创建代理时可能允许许可，但不再允许
                            rdma_protocol_ib
                            ib_security_pkey_access
                        ib_is_mad_class_rmpp
                        handle_outgoing_dr_smp
                        ib_mad_kernel_rmpp_agent
                        ib_send_rmpp_mad
                        ib_send_mad
                            ib_dma_map_single
                                ib_uses_virt_dma
                                dma_map_single
                            ib_post_send
                                .post_send = mlx5_ib_post_send_nodrain,
            or cma_connect_iw
    ucma_put_ctx



mlx5_ib_post_send_nodrain -> mlx5_ib_post_send
    begin_wqe
    ...



cm状态机:
enum rdma_cm_state {
    RDMA_CM_IDLE,
    RDMA_CM_ADDR_QUERY,
    RDMA_CM_ADDR_RESOLVED,
    RDMA_CM_ROUTE_QUERY,
    RDMA_CM_ROUTE_RESOLVED,
    RDMA_CM_CONNECT,
    RDMA_CM_DISCONNECT,
    RDMA_CM_ADDR_BOUND,
    RDMA_CM_LISTEN,
    RDMA_CM_DEVICE_REMOVAL,
    RDMA_CM_DESTROYING
};


cma_ib_handler
switch (ib_event->event)
case IB_CM_REP_RECEIVED
    ib_send_cm_mra(cm_id, CMA_CM_MRA_SETTING, NULL, 0) -> IB/cma：为回复消息发送MRA，RDMA_CM的当前实现仅针对请求消息发送MRA（消息接收确认），而不针对响应消息发送MRA。 因此，连接的缓慢主动方可能会在延迟太长的情况下向被动方发送就绪消息，而被动方无法等待。 该补丁在收到响应消息时添加了对 ib_send_cm_mra() 的调用，从而告诉对方将服务超时修改为更大的值，是之前的 16 倍。 与请求情况一样，仅当重复响应到达时才会发送用于回复的 MRA
        ...


大页:
配置内核大页:
echo 16 >/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages



mm/hugetlb.c
free_hugepages



const struct file_operations hugetlbfs_file_operations = {
    .read_iter		= hugetlbfs_read_iter,
    .mmap			= hugetlbfs_file_mmap,
    .fsync			= noop_fsync,
    .get_unmapped_area	= hugetlb_get_unmapped_area,
    .llseek			= default_llseek,
    .fallocate		= hugetlbfs_fallocate,
};




ibv_create_qp -> IB_USER_VERBS_CMD_CREATE_QP -> static int ib_uverbs_create_qp
    ...
    uobj_get_obj_read
    attr.event_handler = ib_uverbs_qp_event_handler
    ib_create_qp_user
        create_qp
            rdma_zalloc_drv_obj_numa
            rdma_restrack_new(&qp->res, RDMA_RESTRACK_QP)
             dev->ops.create_qp(qp, attr, udata) -> .create_qp = irdma_create_qp,
                ...
             ib_create_qp_security
             rdma_restrack_add(&qp->res)
        create_xrc_qp_user
    ib_qp_usecnt_inc
    uverbs_response


example of e810:
irdma_create_qp
    ...
    iwqp->q2_ctx_mem.va = dma_alloc_coherent
    irdma_alloc_rsrc
    rdma_protocol_roce
    irdma_sc_qp_init
        irdma_uk_qp_init
        irdma_get_encoded_wqe_size
    irdma_cqp_create_qp_cmd
        irdma_alloc_and_get_cqp_request
        cqp_info->cqp_cmd = IRDMA_OP_QP_CREATE
        status = irdma_handle_cqp_op(rf, cqp_request) -> irdma_sc_qp_create
            irdma_sc_cqp_get_next_send_wqe
            dma_wmb();
            set_64bit_val(wqe, 24, hdr)
            print_hex_dump_debug
            irdma_sc_cqp_post_sq
        irdma_put_cqp_request(&rf->cqp, cqp_request)
    iwqp->sig_all = init_attr->sq_sig_type == IB_SIGNAL_ALL_WR
    rdma_protocol_roce
    init_completion(&iwqp->free_qp)



l2b:
include/linux/byteorder/generic.h
cpu_to_be64 -> #define cpu_to_be64 __cpu_to_be64




samples/trace_events
samples/trace_events/trace-events-sample.c




static const struct ib_device_ops irdma_dev_ops = {
	.owner = THIS_MODULE,
	.driver_id = RDMA_DRIVER_IRDMA,
	.uverbs_abi_ver = IRDMA_ABI_VER,

	.alloc_hw_port_stats = irdma_alloc_hw_port_stats,
	.alloc_mr = irdma_alloc_mr,
	.alloc_mw = irdma_alloc_mw,
	.alloc_pd = irdma_alloc_pd,
	.alloc_ucontext = irdma_alloc_ucontext,
	.create_cq = irdma_create_cq,
	.create_qp = irdma_create_qp,
	.dealloc_driver = irdma_ib_dealloc_device,
	.dealloc_mw = irdma_dealloc_mw,
	.dealloc_pd = irdma_dealloc_pd,
	.dealloc_ucontext = irdma_dealloc_ucontext,
	.dereg_mr = irdma_dereg_mr,
	.destroy_cq = irdma_destroy_cq,
	.destroy_qp = irdma_destroy_qp,
	.disassociate_ucontext = irdma_disassociate_ucontext,
	.get_dev_fw_str = irdma_get_dev_fw_str,
	.get_dma_mr = irdma_get_dma_mr,
	.get_hw_stats = irdma_get_hw_stats,
	.map_mr_sg = irdma_map_mr_sg,
	.mmap = irdma_mmap,
	.mmap_free = irdma_mmap_free,
	.poll_cq = irdma_poll_cq,
	.post_recv = irdma_post_recv,
	.post_send = irdma_post_send,
	.query_device = irdma_query_device,
	.query_port = irdma_query_port,
	.query_qp = irdma_query_qp,
	.reg_user_mr = irdma_reg_user_mr,
	.reg_user_mr_dmabuf = irdma_reg_user_mr_dmabuf,
	.rereg_user_mr = irdma_rereg_user_mr,
	.req_notify_cq = irdma_req_notify_cq,
	.resize_cq = irdma_resize_cq,
	INIT_RDMA_OBJ_SIZE(ib_pd, irdma_pd, ibpd),
	INIT_RDMA_OBJ_SIZE(ib_ucontext, irdma_ucontext, ibucontext),
	INIT_RDMA_OBJ_SIZE(ib_ah, irdma_ah, ibah),
	INIT_RDMA_OBJ_SIZE(ib_cq, irdma_cq, ibcq),
	INIT_RDMA_OBJ_SIZE(ib_mw, irdma_mr, ibmw),
	INIT_RDMA_OBJ_SIZE(ib_qp, irdma_qp, ibqp),
};



rdma 5.4.18








struct bundle_priv
IB/uverbs：为 uverbs_attr_bundle 提供实现私有内存，这已经作为匿名“ctx”结构存在，但这并不是真正有用的形式。 将此结构提升到bundle_priv并重新设计内部内容以使用它。 将一堆处理内部状态移入 priv 并减少函数参数的过度使用



强制实现的函数:
static void ib_device_check_mandatory(struct ib_device *device)
{
#define IB_MANDATORY_FUNC(x) { offsetof(struct ib_device_ops, x), #x }
	static const struct {
		size_t offset;
		char  *name;
	} mandatory_table[] = {
		IB_MANDATORY_FUNC(query_device),
		IB_MANDATORY_FUNC(query_port),
		IB_MANDATORY_FUNC(alloc_pd),
		IB_MANDATORY_FUNC(dealloc_pd),
		IB_MANDATORY_FUNC(create_qp),
		IB_MANDATORY_FUNC(modify_qp),
		IB_MANDATORY_FUNC(destroy_qp),
		IB_MANDATORY_FUNC(post_send),
		IB_MANDATORY_FUNC(post_recv),
		IB_MANDATORY_FUNC(create_cq),
		IB_MANDATORY_FUNC(destroy_cq),
		IB_MANDATORY_FUNC(poll_cq),
		IB_MANDATORY_FUNC(req_notify_cq),
		IB_MANDATORY_FUNC(get_dma_mr),
		IB_MANDATORY_FUNC(reg_user_mr),
		IB_MANDATORY_FUNC(dereg_mr),
		IB_MANDATORY_FUNC(get_port_immutable)
	};




为该端口需要由内核支持的各种功能定义位
/* Define bits for the various functionality this port needs to be supported by
 * the core.
 */
/* Management                           0x00000FFF */
#define RDMA_CORE_CAP_IB_MAD            0x00000001
#define RDMA_CORE_CAP_IB_SMI            0x00000002
#define RDMA_CORE_CAP_IB_CM             0x00000004
#define RDMA_CORE_CAP_IW_CM             0x00000008
#define RDMA_CORE_CAP_IB_SA             0x00000010
#define RDMA_CORE_CAP_OPA_MAD           0x00000020

/* Address format                       0x000FF000 */
#define RDMA_CORE_CAP_AF_IB             0x00001000
#define RDMA_CORE_CAP_ETH_AH            0x00002000
#define RDMA_CORE_CAP_OPA_AH            0x00004000
#define RDMA_CORE_CAP_IB_GRH_REQUIRED   0x00008000

/* Protocol                             0xFFF00000 */
#define RDMA_CORE_CAP_PROT_IB           0x00100000
#define RDMA_CORE_CAP_PROT_ROCE         0x00200000
#define RDMA_CORE_CAP_PROT_IWARP        0x00400000
#define RDMA_CORE_CAP_PROT_ROCE_UDP_ENCAP 0x00800000
#define RDMA_CORE_CAP_PROT_RAW_PACKET   0x01000000
#define RDMA_CORE_CAP_PROT_USNIC        0x02000000


iw40


static int irdma_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)





.mmap = mlx5_ib_mmap,


mmap
SYSCALL_DEFINE6(mmap_pgoff, unsigned long, addr, unsigned long, len,
    ksys_mmap_pgoff
        vm_mmap_pgoff
            do_mmap
                addr = get_unmapped_area(file, addr, len, pgoff, flags)
                switch (flags & MAP_TYPE)
                mmap_region
                    count_vma_pages_range
                    call_mmap
                        file->f_op->mmap(file, vma) -> or filemap_fault -> or xtrdma_mmap by cmd_fd fs
                    khugepaged_enter_vma

install module:
make modules_install

install kernel
make install

will install three file to /boot
initramfs-5.16.9.img
System.map-5.16.9
vmlinuz-5.16.9

Update grub config
centos
$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg
$ sudo grubby --set-default /boot/vmlinuz-5.16.9
grubby --info=ALL | more
grubby --default-index
grubby --default-kernel

ubuntu:
$ sudo update-initramfs -c -k 5.16.9
$ sudo update-grub


mkinitramfs 
qemu-system-x86_64 \
  -hda ${disk_img} \
  -enable-kvm \
  -append "root=/dev/sda3" \
  -kernel /kernel/src/path/arch/x86/boot/bzImage \
  -initrd ${initrd-file-path} \
  -cpu host \
  -m 8G \
  -smp 8




server: 服务端创建事件通道,创建通信标识ID, 启动RDMA监听
rdma_create_event_channel <- vrb_eq_open <- fi_eq_open
rdma_create_id <- vrb_create_ep <- vrb_open_ep <- fi_endpoint, librdmacm/cma.c -> rdma_create_event_channel HG创建端点 na_ofi_basic_ep_open
rdma_listen -> fi_listen -> .listen = vrb_pep_listen -> vrb_pep_listen -> rdma_listen, na_ofi_basic_ep_open -> fi_enable -> rxm_ep_ctrl -> rxm_start_listen -> fi_listen

if (ofi_epoll_add(_eq->epollfd, _eq->channel->fd, OFI_EPOLL_IN, NULL)) -> 将rdma事件通道的fd关联到eq的epollfd

client:客户端创建事件通道,创建通信标识ID, 解析服务端地址, 发送数据时, 获取连接, 解析路由
rdma_create_event_channel
rdma_create_id
rdma_resolve_addr -> RDMA_CM_EVENT_ADDRESS_RESOLVED ->  rxm_open_conn -> fi_endpoint (vrb_open_ep) -> rdma_resolve_addr HG -> HG_Trigger -> hg_op_id->callback(&hg_cb_info) 查询地址设置的回调 lookup_callback ->  HG_Forward -> NA_Msg_send_unexpected -> fi_senddata -> rxm_get_conn -> fi_endpoint -> vrb_open_ep -> vrb_create_ep -> rdma_resolve_addr
rdma_resolve_route -> RDMA_CM_EVENT_ROUTE_RESOLVED -> rxm_send_connect -> fi_connect -> rdma_resolve_route 也是HG发送的时候建立连接
------------------ 
分配RDMA结构(服务端和客户端对等, 均要执行), 查询网卡, 分配保护域, 创建完成通道,完成队列, 通知完成队列准备好接收完成事件, 创建队列对, 注册内存
ibv_query_device <- fi_getinfo -> vrb_getinfo -> ibv_query_device
ibv_alloc_pd <- fi_domain -> rxm_domain_open -> ibv_alloc_pd
ibv_create_comp_channel -> na_ofi_eq_open -> fi_cq_open -> vrb_cq_open -> ibv_create_comp_channel
ibv_create_cq -> na_ofi_eq_open -> fi_cq_open -> vrb_cq_open -> ibv_create_cq
ibv_req_notify_cq -> na_ofi_poll_try_wait -> fi_trywait -> vrb_trywait -> vrb_cq_trywait
rdma_create_qp -> na_ofi_context_create -> fi_enable -> rdma_create_qp
ibv_reg_mr -> NA_Mem_register -> na_ofi_mem_register -> fi_mr_regv -> ibv_reg_mr
------------------
轮训完成队列
ibv_poll_cq -> na_ofi_msg_send_unexpected -> fi_senddata -> fi_send -> vrb_flush_cq -> ibv_poll_cq

接收端提前往接收队列放置工作请求WR
ibv_post_recv -> rxm_open_conn -> ibv_post_recv | na_ofi_tag_recv, na_ofi_msg_multi_recv -> fi_trecv -> ibv_post_recv

客户端与服务端建立连接
rdma_connect -> server -> RDMA_CM_EVENT_CONNECT_REQUEST, -> fi_senddata -> rxm_get_conn -> rdma_connect

server:
case RDMA_CM_EVENT_CONNECT_REQUEST
------------------ 
分配RDMA结构
ibv_query_device
ibv_alloc_pd
ibv_create_comp_channel
ibv_create_cq
ibv_req_notify_cq
rdma_create_qp
ibv_reg_mr
------------------
ibv_post_recv
rdma_accept
RDMA_CM_EVENT_ESTABLISHED
ibv_post_send

clinet: 客户端发送非预期消息
RDMA_CM_EVENT_ESTABLISHED
ibv_post_send -> na_ofi_msg_send_unexpected -> ibv_post_send

销毁资源
server:
rdma_disconnect

ibv_dereg_mr
ibv_destroy_cq
ibv_destroy_comp_channel
rdma_destroy_qp

rdma_destroy_id
rdma_destroy_event_channel

client:
rdma_disconnect

ibv_dereg_mr
ibv_destroy_cq
ibv_destroy_comp_channel
rdma_destroy_qp

rdma_destroy_id
rdma_destroy_event_channel



以下是部分接口详解:
创建事件通道:
rdma_create_event_channel - 打开用于报告通信事件的通道。 描述：异步事件通过事件通道上报给用户。 每个事件通道映射到一个文件描述符。 注意：所有创建的事件通道必须通过调用 rdma_destroy_event_channel 销毁。 用户应调用 rdma_get_cm_event 来检索事件通道上的事件。 另请参见：rdma_get_cm_event、rdma_destroy_event_channel, 流程: 查询获取所有IB设备，存放在cma_dev_array全局数组中；检测是否支持AF_IB协议, 打开CM的fd, 返回事件
struct rdma_event_channel *rdma_create_event_channel(void)
  ucma_init()
  channel->fd = open_cdev(dev_name, dev_cdev) -> 打开fd /dev/infiniband/rdma_cm
  返回通道



分配通信标识
int rdma_create_id(struct rdma_event_channel *channel, struct rdma_cm_id **id, void *context, enum rdma_port_space ps)
cmd = UCMA_CMD_CREATE_ID
ret = write(id_priv->id.channel->fd, &cmd, sizeof cmd) -> 通知内核
ucma_insert_id(id_priv)
  idm_set -> librdmacm：定义通过 RDMA 接口 (rsockets) 的流式传输，引入了一组新的 API，支持 RDMA 设备上的字节流接口。 新接口与套接字匹配，只是所有函数调用都以“r”为前缀。 定义了以下函数： rsocket rbind、rlisten、raccept、rconnect rshutdown、rclose rrecv、rrecvfrom、rrecvmsg、rread、rreadv rsend、rsendto、rsendmsg、rwrite、rwritev rpoll、rselect rgetpeername、rgetsockname rsetsockopt、rgetsockopt、rfcntl 函数采用相同的方法 参数与用于套接字的参数相同。 目前支持以下功能和标志： PF_INET、PF_INET6、SOCK_STREAM、IPPROTO_TCP MSG_DONTWAIT、MSG_PEEK SO_REUSEADDR、TCP_NODELAY、SO_ERROR、SO_SNDBUF、SO_RCVBUF O_NONBLOCK rpoll 调用支持轮询 rsockets 和普通 fd, 
  index_map(二级指针): 索引映射 - 将结构与索引关联起来。 同步必须由调用者提供。 调用者必须通过将索引映射设置为 0 来初始化它
  提供一组索引操作接口, 设置,插入(idx_insert),增长(idx_grow),替换,移除,清理等
  rsocket是附在rdma_cm库中的一个子模块，提供了完全类似于socket接口的rdma调用
  对于rdma编程，目前主流实现是利用rdma_cm来建立连接，然后利用verbs来传输数据。  rdma_cm和ibverbs分别会创建一个fd，这两个fd的分工不同。rdma_cm fd主要用于通知建连相关的事件，verbs fd则主要通知有新的cqe发生。当直接对rdma_cm fd进行poll/epoll监听时，此时只能监听到POLLIN事件，这意味着有rdma_cm事件发生。当直接对verbs fd进行poll/epoll监听时，同样只能监听到POLLIN事件，这意味着有新的cqe  作者：异客z 链接：https://www.jianshu.com/p/4d71f1c8e77c



监听客户端的连接请求, 给内核发送监听命令, 查询地址/路由
int rdma_listen(struct rdma_cm_id *id, int backlog)
cmd = UCMA_CMD_LISTEN
write(id->channel->fd, &cmd, sizeof cmd)



解析地址
int rdma_resolve_addr(struct rdma_cm_id *id, struct sockaddr *src_addr, struct sockaddr *dst_addr, int timeout_ms)



ibv_query_device
  mlx5_query_device_ex
  IB_USER_VERBS_EX_CMD_QUERY_DEVICE


发起连接请求
int rdma_connect(struct rdma_cm_id *id, struct rdma_conn_param *conn_param)
ucma_valid_param
CMA_INIT_CMD(&cmd, sizeof cmd, CONNECT)
cmd = UCMA_CMD_CONNECT -> kernel -> static ssize_t (*ucma_cmd_table[]) -> ucma_connect
ucma_copy_conn_param_to_kern
  dst->retry_count = 7;   // 无限次重试
    dst->rnr_retry_count = 7; // 无限次重试
ucma_copy_ece_param_to_kern_req
ret = write(id->channel->fd, &cmd, sizeof cmd)







ibv_advise_mr
ibv_alloc_dm
ibv_open_device
ibv_get_device_list
ibv_get_device_guid
ibv_query_device_ex
ibv_get_device_name
ibv_req_notify_cq
ibv_query_gid
ibv_memcpy_to_dm
ibv_get_cq_event
ibv_start_poll
ibv_end_poll
ibv_next_poll
ibv_wc_read_completion_ts
ibv_ack_cq_events
ibv_free_device_list
ibv_cq_ex_to_cq
ibv_create_qp
ibv_modify_qp

ibv_modify_qp
.modify_qp = irdma_umodify_qp,
    ibv_cmd_modify_qp_ex
        copy_modify_qp_fields
            ...
            cmd->retry_cnt = attr->retry_cnt
            ...
        execute_cmd_write_ex IB_USER_VERBS_EX_CMD_MODIFY_QP -> to kernel
    irdma_mmap
    or ibv_cmd_modify_qp



ibv_create_qp
.create_qp = irdma_ucreate_qp,
...
info.abi_ver = iwvctx->abi_ver -> 设置参数
...
irdma_uk_calc_depth_shift_sq -> 提供商/irdma：允许准确报告 QP 最大发送/接收 WR ，目前，在创建 QP 期间从用户空间发送的属性 cap.max_send_wr 和 cap.max_recv_wr 是提供商计算的 SQ/RQ 深度，而不是从应用程序传递的原始值。 这会禁止在内核中计算该 QP 的 max_send_wr 和 max_recv_wr 的准确值，该值与用户创建 QP 中返回的值相匹配。 此外，这些功能还需要在查询 QP 中从驱动程序报告。 通过扩展 ABI 添加支持，以允许从用户空间传递原始 cap.max_send_wr 和 cap.max_recv_wr，同时保持对旧方案的兼容性。 添加新的助手来协助完成此操作：irdma_uk_calc_depth_shift_sq、irdma_uk_calc_depth_shift_rq
    irdma_get_wqe_shift
    irdma_get_sqdepth
iwuqp = memalign(1024, sizeof(*iwuqp)) -> 在GNU系统中，malloc或realloc返回的内存块地址都是8的倍数（如果是64位系统，则为16的倍数）。如果你需要更大的粒度，请使用memalign或valloc
irdma_uk_calc_depth_shift_rq
irdma_vmapped_qp(iwuqp, pd, attr, &info, iwvctx->legacy_mode)
    irdma_alloc_hw_buf
    reg_mr_cmd.reg_type = IRDMA_MEMREG_TYPE_QP
    ibv_cmd_reg_mr
        execute_cmd_write(pd->context, IB_USER_VERBS_CMD_REG_MR -> to kernel
    ibv_cmd_create_qp
irdma_uk_qp_init




ibv_open_device -> LATEST_SYMVER_FUNC(ibv_open_device -> verbs_open_device
    verbs_get_device
    cmd_fd = open_cdev -> verbs：启用 verbs_open_device() 以在非 sysfs 设备上工作，从 mlx5 开始，启用 verbs_open_device() 通过 VFIO 在非 sysfs 设备上工作。 verbs_sysfs_dev 上的任何其他 API 都应该彻底失败
    verbs_device->ops->alloc_context -> mlx5_alloc_context -> verbs：始终分配 verbs_context，现在所有内容都在一棵树中，我们可以修改旧版 init_context 路径，通过在所有提供程序的包装结构中将 ibv_context 交换为 verbs_context 来始终分配 verbs_context。 为了保持提供者差异最小，这个补丁同时做了几件事： - 引入 verbs_init_and_alloc_context() 宏。 这会为每个驱动程序分配、清零并初始化 verbs_context。 值得注意的是，这个新宏在失败时根据需要正确设置 errno。 - 从所有驱动程序、calloc、malloc、memset、cmd_fd 和设备分配中删除样板文件 - 与 verbs_init 方案一起必然出现 verbs_uninit 方案，该方案将 uninit 调用降低到提供者而不是公共代码中。 这使我们能够在 init 错误路径上正确地 uninit。 总之，这遵循我们在内核中看到的相当成功的模式，用于对子系统进行驱动程序初始化。 此外，这会将 ibv_cmd_get_context 更改为接受 verbs_context，因为大多数调用者现在都提供该内容，这使得差异较小。 这使得整个流程更加一致，并且可以让我们消除 init_context 流程
        mlx5_init_context
            verbs_init_and_alloc_context -> _verbs_init_and_alloc_context
                verbs_init_context
                    ibverbs_device_hold
                    verbs_set_ops(context_ex, &verbs_dummy_ops) -> rdma verbs操作 -> 在上下文中设置 -> 如果更改，则必须更改 PRIVATE IBVERBS_PRIVATE_ 符号。 这是驱动程序可以支持的每个操作的联合。 如果向此结构添加新元素，则 verbs_dummy_ops 也必须更新。 保持排序
                        SET_OP -> 设置一系列操作
                        ...
                    use_ioctl_write = has_ioctl_write(context)
            mlx5_open_debug_file
            mlx5_set_debug_mask
            single_threaded_app
            get_uar_info
                get_total_uuars
                get_num_low_lat_uuars
        mlx5_cmd_get_context
            ibv_cmd_get_context
                ...
                execute_write_bufs(context, IB_USER_VERBS_CMD_GET_CONTEXT
        mlx5_set_context
            adjust_uar_info
            cl_qmap_init
            mlx5_mmap
            mlx5_read_env
            verbs_set_ops(v_ctx, &mlx5_ctx_common_ops)
            mlx5_query_device_ctx
                get_hca_general_caps
                    mlx5dv_devx_general_cmd MLX5_CMD_OP_QUERY_HCA_CAP
                ibv_cmd_query_device_any
                    execute_cmd_write_ex IB_USER_VERBS_EX_CMD_QUERY_DEVICE
                    execute_cmd_write(context, IB_USER_VERBS_CMD_QUERY_DEVICE -> 转到内核态
            mlx5_set_singleton_nc_uar
    set_lib_ops
    ibv_cmd_alloc_async_fd





rdma verbs ops
const struct verbs_context_ops verbs_dummy_ops = {
    advise_mr,
    alloc_dm,
    alloc_mw,
    alloc_null_mr,
    alloc_parent_domain,
    alloc_pd,
    alloc_td,
    async_event,
    attach_counters_point_flow,
    attach_mcast,
    bind_mw,
    close_xrcd,
    cq_event,
    create_ah,
    create_counters,
    create_cq,
    create_cq_ex,
    create_flow,
    create_flow_action_esp,
    create_qp,
    create_qp_ex,
    create_rwq_ind_table,
    create_srq,
    create_srq_ex,
    create_wq,
    dealloc_mw,
    dealloc_pd,
    dealloc_td,
    dereg_mr,
    destroy_ah,
    destroy_counters,
    destroy_cq,
    destroy_flow,
    destroy_flow_action,
    destroy_qp,
    destroy_rwq_ind_table,
    destroy_srq,
    destroy_wq,
    detach_mcast,
    free_context,
    free_dm,
    get_srq_num,
    import_dm,
    import_mr,
    import_pd,
    modify_cq,
    modify_flow_action_esp,
    modify_qp,
    modify_qp_rate_limit,
    modify_srq,
    modify_wq,
    open_qp,
    open_xrcd,
    poll_cq,
    post_recv,
    post_send,
    post_srq_ops,
    post_srq_recv,
    query_device_ex,
    query_ece,
    query_port,
    query_qp,
    query_qp_data_in_order,
    query_rt_values,
    query_srq,
    read_counters,
    reg_dm_mr,
    reg_dmabuf_mr,
    reg_mr,
    req_notify_cq,
    rereg_mr,
    resize_cq,
    set_ece,
    unimport_dm,
    unimport_mr,
    unimport_pd,
};

设置rdma verbs操作:
static const struct verbs_context_ops mlx5_ctx_common_ops = {
    .query_port    = mlx5_query_port,
    .alloc_pd      = mlx5_alloc_pd,
    .async_event   = mlx5_async_event,
    .dealloc_pd    = mlx5_free_pd,
    .reg_mr	       = mlx5_reg_mr,
    .reg_dmabuf_mr = mlx5_reg_dmabuf_mr,
    .rereg_mr      = mlx5_rereg_mr,
    .dereg_mr      = mlx5_dereg_mr,
    .alloc_mw      = mlx5_alloc_mw,
    .dealloc_mw    = mlx5_dealloc_mw,
    .bind_mw       = mlx5_bind_mw,
    .create_cq     = mlx5_create_cq,
    .poll_cq       = mlx5_poll_cq,
    .req_notify_cq = mlx5_arm_cq,
    .cq_event      = mlx5_cq_event,
    .resize_cq     = mlx5_resize_cq,
    .destroy_cq    = mlx5_destroy_cq,
    .create_srq    = mlx5_create_srq,
    .modify_srq    = mlx5_modify_srq,
    .query_srq     = mlx5_query_srq,
    .destroy_srq   = mlx5_destroy_srq,
    .post_srq_recv = mlx5_post_srq_recv,
    .create_qp     = mlx5_create_qp,
    .query_qp      = mlx5_query_qp,
    .modify_qp     = mlx5_modify_qp,
    .destroy_qp    = mlx5_destroy_qp,
    .post_send     = mlx5_post_send,
    .post_recv     = mlx5_post_recv,
    .create_ah     = mlx5_create_ah,
    .destroy_ah    = mlx5_destroy_ah,
    .attach_mcast  = mlx5_attach_mcast,
    .detach_mcast  = mlx5_detach_mcast,

    .advise_mr = mlx5_advise_mr,
    .alloc_dm = mlx5_alloc_dm,
    .alloc_parent_domain = mlx5_alloc_parent_domain,
    .alloc_td = mlx5_alloc_td,
    .attach_counters_point_flow = mlx5_attach_counters_point_flow,
    .close_xrcd = mlx5_close_xrcd,
    .create_counters = mlx5_create_counters,
    .create_cq_ex = mlx5_create_cq_ex,
    .create_flow = mlx5_create_flow,
    .create_flow_action_esp = mlx5_create_flow_action_esp,
    .create_qp_ex = mlx5_create_qp_ex,
    .create_rwq_ind_table = mlx5_create_rwq_ind_table,
    .create_srq_ex = mlx5_create_srq_ex,
    .create_wq = mlx5_create_wq,
    .dealloc_td = mlx5_dealloc_td,
    .destroy_counters = mlx5_destroy_counters,
    .destroy_flow = mlx5_destroy_flow,
    .destroy_flow_action = mlx5_destroy_flow_action,
    .destroy_rwq_ind_table = mlx5_destroy_rwq_ind_table,
    .destroy_wq = mlx5_destroy_wq,
    .free_dm = mlx5_free_dm,
    .get_srq_num = mlx5_get_srq_num,
    .import_dm = mlx5_import_dm,
    .import_mr = mlx5_import_mr,
    .import_pd = mlx5_import_pd,
    .modify_cq = mlx5_modify_cq,
    .modify_flow_action_esp = mlx5_modify_flow_action_esp,
    .modify_qp_rate_limit = mlx5_modify_qp_rate_limit,
    .modify_wq = mlx5_modify_wq,
    .open_qp = mlx5_open_qp,
    .open_xrcd = mlx5_open_xrcd,
    .post_srq_ops = mlx5_post_srq_ops,
    .query_device_ex = mlx5_query_device_ex,
    .query_ece = mlx5_query_ece,
    .query_rt_values = mlx5_query_rt_values,
    .read_counters = mlx5_read_counters,
    .reg_dm_mr = mlx5_reg_dm_mr,
    .alloc_null_mr = mlx5_alloc_null_mr,
    .free_context = mlx5_free_context,
    .set_ece = mlx5_set_ece,
    .unimport_dm = mlx5_unimport_dm,
    .unimport_mr = mlx5_unimport_mr,
    .unimport_pd = mlx5_unimport_pd,
    .query_qp_data_in_order = mlx5_query_qp_data_in_order,
};



代码路径: rdma-core, libibverbs/device.c
ibv_get_device_list
    ibverbs_get_device_list -> verbs: 刷新缓存的 ibv_device 列表 问题 ======== 目前，libibverbs 仅在第一次调用 ibv_get_device_list 时构建缓存的 ibv_device 列表，因此无论硬件是否发生变化，该列表都不会更新。 系统。 解决方案======== 修改 ibv_get_device_list() 的实现，以便连续的调用将以与今天相同的方式重新扫描 sysfs，以便每次创建一个新的 ibv_device 列表。 为此，将缓存的设备列表更改为真正的链表而不是动态数组。 我们如何识别新设备​============================= 根据 /sys/class/infiniband_verbs/ 的时间戳创建来识别同一设备 uverbs%d/ibdev。 我们使用 stat 系统调用获取文件状态，并使用 st_mtime 字段来实现此目的。 当我们重新扫描 sysfs 设备时，我们会检查每个 sysfs 设备是否已经在上次扫描中，如果没有，则分配新的 ibv_device 并将其添加到缓存设备列表中。 本系列的下一个补丁处理设备不再使用的情况。 注意：此补丁根据上面 verbs_device 结构体注释中的要求更改了 IBVERBS_PRIVATE 符号
        find_sysfs_devs_nl -> verbs：使用 netlink 来发现 uverbs 设备而不是 sysfs，netlink 查询为我们提供了 ibdev idx，它对于设备来说大多是唯一的，并且在设备重命名时充当稳定的 id。 如果在 verbs 用户操作期间重命名设备，这会使 verbs 更加健壮。 此外，netlink 仅返回在进程的网络命名空间中实际可见的设备，从而简化了发现过程
            rdmanl_socket_alloc
                nl_socket_alloc
                nl_socket_disable_auto_ack
                nl_socket_disable_msg_peek
                nl_connect(nl, NETLINK_RDMA) -> rdma：允许按需加载 NETLINK_RDMA，提供模块别名，以便如果用户空间打开 RDMA 的 netlink 套接字，则会自动加载内核支持
            rdmanl_get_devices find_sysfs_devs_nl_cb
                nl_send_simple RDMA_NL_GET_TYPE(RDMA_NL_NLDEV, RDMA_NLDEV_CMD_GET) NLM_F_DUMP -> nldev_get_doit
                nl_socket_modify_err_cb
                nl_socket_modify_cb
                nl_recvmsgs_default
            find_uverbs_nl find_uverbs_sysfs try_access_device
                rdmanl_get_chardev(nl, sysfs_dev->ibdev_idx, "uverbs", find_uverbs_nl_cb
                    nlmsg_alloc_simple RDMA_NLDEV_CMD_GET_CHARDEV
                    ...
                    check_snprintf(path, sizeof(path), "%s/device/infiniband_verbs",
                    setup_sysfs_uverbs
                        abi_version
                    ...
                    stat(devpath, &cdev_stat)
            nl_socket_free
        find_sysfs_devs
            %s/class/infiniband_verbs
            ibv_read_sysfs_file_at(uv_dirfd, "ibdev", 
        check_abi_version
            "class/infiniband_verbs/abi_version"
        try_all_drivers
            try_drivers
                match_driver_id -> VERBS_MATCH_SENTINEL -> 动词：提供通用代码以将提供程序与内核设备进行匹配 根据表检查 PCI 设备基本上在每个驱动程序中都是重复的。 遵循内核的模式，并将匹配表附加到 verbs_device_ops 驱动程序入口点，该入口点描述提供程序可以处理的所有内核设备，并使核心代码与该表匹配。 驱动程序获取一个指向与分配函数中匹配的表条目的指针。 此实现基于模式别名，而不是读取 PCI 特定供应商和设备文件。 modalias 让我们支持 ACPI 和 OF 提供程序，并提供了一个简单的路径，使提供程序根据其支持的 modalias 字符串（如内核）进行需求加载
                try_driver
                    match_device
                    alloc_device -> mlx5_device_alloc
                    dev->transport_type = IBV_TRANSPORT_IB -> 传输类型
                    ...
        load_drivers
            dlhandle = dlopen(so_name, RTLD_NOW)
    ibverbs_device_hold




query_device_ex -> mlx5_query_device_ex
    



.alloc_context = irdma_ualloc_context
    verbs_init_and_alloc_context
    verbs_set_ops(&iwvctx->ibv_ctx, &irdma_uctx_ops)
    irdma_mmap
        mmap
        ibv_dontfork_range
            ibv_madvise_range(base, size, MADV_DONTFORK)
    irdma_ualloc_pd
        ibv_cmd_alloc_pd




static const struct verbs_context_ops irdma_uctx_ops = {
    .alloc_mw = irdma_ualloc_mw,
    .alloc_pd = irdma_ualloc_pd,
    .attach_mcast = irdma_uattach_mcast,
    .bind_mw = irdma_ubind_mw,
    .cq_event = irdma_cq_event,
    .create_ah = irdma_ucreate_ah,
    .create_cq = irdma_ucreate_cq,
    .create_cq_ex = irdma_ucreate_cq_ex,
    .create_qp = irdma_ucreate_qp,
    .dealloc_mw = irdma_udealloc_mw,
    .dealloc_pd = irdma_ufree_pd,
    .dereg_mr = irdma_udereg_mr,
    .destroy_ah = irdma_udestroy_ah,
    .destroy_cq = irdma_udestroy_cq,
    .destroy_qp = irdma_udestroy_qp,
    .detach_mcast = irdma_udetach_mcast,
    .modify_qp = irdma_umodify_qp,
    .poll_cq = irdma_upoll_cq,
    .post_recv = irdma_upost_recv,
    .post_send = irdma_upost_send,
    .query_device_ex = irdma_uquery_device_ex,
    .query_port = irdma_uquery_port,
    .query_qp = irdma_uquery_qp,
    .reg_dmabuf_mr = irdma_ureg_mr_dmabuf,
    .reg_mr = irdma_ureg_mr,
    .rereg_mr = irdma_urereg_mr,
    .req_notify_cq = irdma_uarm_cq,
    .resize_cq = irdma_uresize_cq,
    .free_context = irdma_ufree_context,
};


LATEST_SYMVER_FUNC(ibv_alloc_pd
.alloc_pd      = mlx5_alloc_pd
    ibv_cmd_alloc_pd
         execute_cmd_write(context, IB_USER_VERBS_CMD_ALLOC_PD -> 转到内核处理
    pthread_mutex_init(&pd->opaque_mr_mutex, NULL -> mlx5：引入 mlx5dv_wr_memcpy builder ，引入 mlx5dv_wr_memcpy 用于构建 DMA memcpy 请求。 DMA memcpy 是从 BlueField-2 开始提供的多种内存到内存卸载 (MMO) 之一。 它利用 DPU 上的 GGA 模块执行从 src 到 dest 的 DMA memcpy，从而提高性能。 src 和 dest 可以是主机和 SoC 的任意组合。 请注意，在 Host 到 SoC 或 SoC 到 Host memcpy 的情况下，需要特殊的跨 gvmi MKey




poll_cq
    mlx5_stall_cycles_poll_cq
    or mlx5_stall_poll_cq
    mlx5_poll_one
        mlx5_get_next_cqe -> 添加惰性CQ轮询，目前，当用户想要轮询CQ是否完成时，他别无选择，只能获得整个工作完成（WC）。 这有几个含义 - 例如： * 扩展 WC 是有限的，因为添加新字段会使 WC 更大并且可能占用更多缓存行。 * 每个字段都被复制到 WC - 甚至是用户不关心的字段。 此补丁添加了对以惰性方式处理 CQE 的一些支持。 新的惰性模式将在下游补丁中调用。 我们只解析必需的字段，以便找出 CQE，例如类型、状态、wr_id 等。为了与遗留模式共享代码而不影响性能，对遗留代码进行了重构，并使用了“always_inline”机制，以便 分支条件将在编译时被删除
            next_cqe_sw
                ...
                return cq->active_buf->buf + n * cq->cqe_sz
            VALGRIND_MAKE_MEM_DEFINED -> memory check
            dump_cqe
        mlx5_parse_cqe -> 多分支函数
            case MLX5_CQE_REQ
            ...
    update_cons_index
    mlx5_get_cycles



test:
man: https://man7.org/linux/man-pages/man1/ibv_rc_pingpong.1.html
libibverbs/examples/rc_pingpong.c -> main
...
ibv_get_device_list
pp_init_ctx
    ctx->buf = memalign(page_size, size)
    ibv_open_device
    ibv_create_comp_channel
    ctx->pd = ibv_alloc_pd(ctx->context)
    if (use_odp || use_ts || use_dm)
        ibv_query_device_ex(ctx->context, NULL, &attrx) -> 查询设备属性/支持的功能
        ctx->dm = ibv_alloc_dm(ctx->context, &dm_attr)
        access_flags |= IBV_ACCESS_ZERO_BASED -> 使用从 MR 开始的字节偏移量来访问该 MR，而不是指针地址
    ctx->mr = ibv_reg_mr
    or ibv_reg_dm_mr
    if (prefetch_mr)
        ibv_advise_mr
    ibv_create_cq_ex
    or ibv_create_cq
    ibv_create_qp_ex
    or ibv_create_qp
    ibv_qp_to_qp_ex
    ibv_query_qp
    IBV_QPS_INIT
    ibv_modify_qp
pp_post_recv
    for (i = 0; i < n; ++i)
        ibv_post_recv
ibv_req_notify_cq
pp_get_port_info -> 由于 IBoE 需要使用 GRH，因此更新 ibv_*_pinpong 示例以接受 GID。 GID 作为本地端口表的索引给出，并通过套接字连接在客户端和服务器之间交换
    ibv_query_port
ibv_query_gid
if (servername)
    pp_client_exch_dest
        getaddrinfo(servername, service, &hints, &res)
        socket
        connect
        gid_to_wire_gid
        (write(sockfd, msg
        read(sockfd, msg
        wire_gid_to_gid(gid, &rem_dest->gid)
or pp_server_exch_dest
    accept
    wire_gid_to_gid
    pp_connect_ctx
        IBV_QPS_RTR
        ibv_modify_qp
        IBV_QPS_RTS
        ...
pp_connect_ctx
客户端
    ibv_memcpy_to_dm
    pp_post_send
        struct ibv_send_wr wr
        .opcode     = IBV_WR_SEND,
        ibv_wr_start
        ibv_wr_send
        ibv_wr_set_sge
        ibv_wr_complete
        or ibv_post_send
ibv_get_cq_event
if (use_ts) -> RoCE 时间戳允许您在将数据包发送到线路或从线路接收数据包时对其进行标记。 时间戳以原始硬件周期给出，但可以轻松转换为硬件参考的基于纳秒的时间。 此外，它使您能够查询硬件的硬件时间，从而标记其他应用程序的事件并比较时间
    ibv_start_poll
parse_single_wc
or ibv_poll_cq
...



rdma_create_id
    rdma_create_id2
        ucma_init
        ucma_alloc_id
        write
        ucma_insert_id



librdmacm/cma.c

ibv_query_port -> __lib_query_port
    get_ops(context)->query_port


ibv_get_device_list
    ibverbs_init -> verbs：修改 init 的排序方式，将检查 uverbs ABI 移至从内核加载设备列表之后。 当通过 netlink 加载时，我们可以假设 ABI 是 6，而无需转到 sysfs。 这允许我们使用内核依赖项来初始化库，并且错误（例如缺少内核支持）是从 ibverbs_get_device_list() 而不是 ibverbs_init() 返回的。 如果内核支持 netlink，ibverbs 在启动期间不再读取 /sys/ 路径
        check_env("RDMAV_FORK_SAFE") || check_env("IBV_FORK_SAFE")
        ibv_fork_init -> libibverbs/memory.c
            getenv("RDMAV_HUGEPAGES_SAFE") -> 允许在多次调用 ibv_fork_init 中使用大页，设置环境变量 RDMAV_HUGEPAGES_SAFE 告诉库检查内核用于内存区域的基础页大小。 如果应用程序直接或通过 libhugetlbfs 等库间接使用大页，则这是必需的。 该变量的检查是在第一次调用 ibv_fork_init 时执行的。 这会导致具有多个底层库的复杂应用程序出现不可预测的行为。 提议的更改将允许支持大页面，而不依赖于 ibv_fork_init 调用顺序
            if (mm_root)
            get_page_size
                "/proc/%d/smaps", pid
                smaps_page_size
                    KernelPageSize
            madvise(tmp_aligned, size, MADV_DONTFORK) -> 在 ibv_fork_init() 和 madvise 跟踪中处理大页，当在 libibverbs 中启用 fork 支持时，将为注册为内存区域的每个内存页调用 madvise() 。 传递给 madvise() 的内存范围必须是页对齐的，并且大小必须是页大小的倍数。 libibverbs 使用 sysconf(_SC_PAGESIZE) 找出系统页面大小，并根据此页面大小对传递给 reg_mr() 的所有范围进行舍入。 当 libhugetlbfs 中的内存传递给 reg_mr() 时，这不起作用，因为该内存范围的页面大小可能不同（例如 16MB）。 因此 libibverbs 必须使用巨大的页面大小来计算 madvise 的页面对齐范围。 由于在预加载 libhugetlbfs 时向应用程序“在后台”提供大页面，因此应用程序不知道何时注册大页面或普通页面。 要解决此问题，请检测 libibverbs 中大页面的使用，并根据大页面大小调整传递给 madvise 的内存范围。 通过观察 madvise() 失败来确定给定内存范围的页面大小已被证明是不可靠的。 因此，我们引入 RDMAV_HUGEPAGES_SAFE 环境变量，让用户决定是否应在每次 reg_mr() 调用时检查页面大小。 这要求用户了解正在运行的应用程序是否使用大页面。 我没有添加额外的 API 调用来启用此功能，因为应用程序可以使用 setenv() + ibv_fork_init() 来启用检查代码中的大页面
            mm_root->color  = IBV_BLACK -> 初始化红黑树(会影响性能)
            ...
        verbs_allow_disassociate_destroy -> verbs：引入ENV来控制销毁命令时的EIO，引入环境变量（即RDMAV_ALLOW_DISASSOC_DESTROY）来控制销毁命令返回的代码。 一旦设置完毕，任何将从内核获取 EIO 的销毁命令都将被视为成功。 在这种情况下，该对象的底层内核资源必须已通过分离机制销毁，并且用户空间驱动程序和应用程序也可以安全地清理其资源。 这是为了防止用户空间区域的内存泄漏
        ibv_get_sysfs_path
        check_memlock_limit
            rlim.rlim_cur <= 32768
        verbs_set_log_level -> verbs：添加通用日志记录 API，调试打印机制在调试应用程序故障时非常有用。 此补丁添加了一个通用 API，可供所有提供商使用并替换特定于提供商的对应项。 调试消息通过名为 VERBS_LOG_LEVEL 的环境变量进行控制，其中值指示应启用哪些打印： enum { VERBS_LOG_LEVEL_NONE, VERBS_LOG_ERR, VERBS_LOG_WARN, VERBS_LOG_INFO, VERBS_LOG_DEBUG, }; 例如，要启用警告级别或更高级别的打印，VERBS_LOG_LEVEL 应设置为 2。输出应写入 VERBS_LOG_FILE 环境变量中提供的文件。 当在调试模式下编译库并且未提供文件时，输出应写入 stderr。 对于数据路径流，附加 if 语句的开销很重要，可以使用 verbs_*_datapath() 宏，该宏将在编译库以供发布时编译出来, 参考: https://github.com/ssbandjl/rdma-core/commit/5c3514eb87ca86e817a8b610ada3200bbcdde6f4, 编译开关: Enabling debug prints, 可作为日志实现的一个参考
        verbs_set_log_file
    ibverbs_get_device_list -> verbs: 刷新缓存的 ibv_device 列表，问题 ======== 目前，libibverbs 仅在第一次调用 ibv_get_device_list 时构建缓存的 ibv_device 列表，因此无论是否有硬件更改，该列表都不会更新 在系统中。 解决方案======== 修改 ibv_get_device_list() 的实现，以便连续的调用将以与今天相同的方式重新扫描 sysfs，以便每次创建一个新的 ibv_device 列表。 为此，将缓存的设备列表更改为真正的链表而不是动态数组。 我们如何识别新设备​============================= 根据 /sys/class/infiniband_verbs/ 的时间戳创建来识别同一设备 uverbs%d/ibdev。 我们使用 stat 系统调用获取文件状态，并使用 st_mtime 字段来实现此目的。 当我们重新扫描 sysfs 设备时，我们会检查每个 sysfs 设备是否已经在上次扫描中，如果没有，则分配新的 ibv_device 并将其添加到缓存设备列表中。 本系列的下一个补丁处理设备不再使用的情况。 注意：此补丁根据上面 verbs_device 结构体注释中的要求更改了 IBVERBS_PRIVATE 符号 -> verbs: 整理 ibverbs_get_device_list ，现在我们有了 ccan 列表，这里的逻辑可以大大简化。 消除令人困惑的used和have_driver值，而只是在我们运行进程时从sysfs列表中删除项目。 这直接保证了发现的 sysfs 项仅处理一次，并使 sysfs 指针的生命周期更加清晰
        find_sysfs_devs_nl(&sysfs_list) -> verbs：使用 netlink 来发现 uverbs 设备而不是 sysfs，netlink 查询为我们提供了 ibdev idx，它对于设备来说大多是唯一的，并且在设备重命名时充当稳定的 id。 如果在 verbs 用户操作期间重命名设备，这会使 verbs 更加健壮。 此外，netlink 仅返回在进程的网络命名空间中实际可见的设备，从而简化了发现过程
            rdmanl_socket_alloc
            rdmanl_get_devices(nl, find_sysfs_devs_nl_cb, tmp_sysfs_dev_list)
            list_for_each_safe (tmp_sysfs_dev_list
                find_uverbs_nl(nl, dev) && find_uverbs_sysfs(dev)
                try_access_device(dev)
                    stat(devpath, &cdev_stat)
            nl_socket_free(nl)
        find_sysfs_devs(&sysfs_list)
        check_abi_version
        list_for_each_safe(device_list
            same_sysfs_dev
            ibverbs_device_put
        try_all_drivers
        load_drivers()
        try_all_drivers
        return num_devices
    ibverbs_device_hold(l[i]) -> verbs: 避免 ibv_device 内存泄漏，现在，每次调用 ibv_get_device_list 时都会刷新 ibv_device 列表，因此我们需要从之前的扫描中释放不再绑定的设备，否则可能会导致 ibv_device 结构的内存泄漏。 仅当用户不再使用 ibv_device 的内存时，我们才能释放它。 我们如何识别设备是否仍在使用​============================================ 我们 将引用计数添加到动词设备结构中。 在以下情况下，该引用计数会增加： 设置为 1 以使该设备位于列表中，直到应将其删除为止。 b. 用户调用 ibv_get_device_list。 C。 用户调用 ibv_open_device。 在以下情况下，引用计数会减少： 用户调用 ibv_free_device_list。 b. 用户调用 ibv_close_device。 C。 设备不再存在于 sysfs 中。 当引用计数减少到零时，设备将被释放。 为了释放 ibv_device 结构，我们将 uninit_device 回调函数添加到 verbs_device_ops
        verbs_get_device
            container_of(dev, struct verbs_device, device)
        atomic_fetch_add(&verbs_device->refcount, 1) -> 加引用
    *num = num_devices




module_init(mlx5_ib_init);
    alloc_ordered_workqueue
    mlx5_ib_qp_event_init
    mlx5_ib_odp_init
    mlx5r_rep_init
    auxiliary_driver_register(&mlx5r_mp_driver)
    auxiliary_driver_register(&mlx5r_driver)
static struct auxiliary_driver mlx5r_driver = {
    .name = "rdma",
    .probe = mlx5r_probe,
    .remove = mlx5r_remove,
    .id_table = mlx5r_id_table,
};
mlx5r_probe
    mlx5_port_type_cap_to_rdma_ll -> {net, IB}/mlx5：管理多端口 RoCE 的端口关联，调用 mlx5_ib_add 时确定要添加的 mlx5 核心设备是否能够进行双端口 RoCE 操作。 如果是，请使用 num_vhca_ports 和affiliate_nic_vport_criteria 功能确定它是主设备还是从设备。 如果该设备是从属设备，请尝试找到与其关联的主设备。 可以关联的设备将共享系统映像 GUID。 如果没有找到，请将其放入非关联端口列表中。 如果找到主设备，则通过在 NIC vport 上下文中配置端口从属关系将端口绑定到它。 同样，当调用 mlx5_ib_remove 时确定端口类型。 如果它是从端口，则将其与主设备取消关联，否则只需将其从非关联端口列表中删除即可。 即使第二个端口不可用于关联，IB 设备也会注册为多端口设备。 当第二个端口稍后附属时，必须刷新 GID 缓存才能获取缓存中第二个端口的默认 GID。 导出roce_rescan_device以提供在绑定新端口后刷新缓存的机制。 在多端口配置中，所有 IB 对象（QP、MR、PD 等）相关命令应流经主站 mlx5_core_dev，其他命令必须发送到从端口 mlx5_core_mdev，提供一个接口来获取非 IB 对象命令的正确 mdev
    ib_alloc_device
    if (ll == IB_LINK_LAYER_ETHERNET && !mlx5_get_roce_state(mdev))
        profile = &raw_eth_profile;
    else
        profile = &pf_profile;
    __mlx5_ib_add
    auxiliary_set_drvdata


...
static const struct mlx5_ib_profile pf_profile
    mlx5_ib_counters_init
        ib_set_device_ops(&dev->ib_dev, &counters_ops)
        ib_set_device_ops(&dev->ib_dev, &hw_switchdev_stats_ops)
        or
        ib_set_device_ops(&dev->ib_dev, &hw_stats_ops);
        mlx5_ib_alloc_counters
            mlx5_ib_fill_counters
                basic_q_cnts
            mlx5_cmd_exec_inout


mlx5 counter:
static const struct counter_desc pport_802_3_stats_desc[] = {
    { "tx_packets_phy", PPORT_802_3_OFF(a_frames_transmitted_ok) },
    { "rx_packets_phy", PPORT_802_3_OFF(a_frames_received_ok) },
    { "rx_crc_errors_phy", PPORT_802_3_OFF(a_frame_check_sequence_errors) },
    { "tx_bytes_phy", PPORT_802_3_OFF(a_octets_transmitted_ok) },
    { "rx_bytes_phy", PPORT_802_3_OFF(a_octets_received_ok) },
    { "tx_multicast_phy", PPORT_802_3_OFF(a_multicast_frames_xmitted_ok) },
    { "tx_broadcast_phy", PPORT_802_3_OFF(a_broadcast_frames_xmitted_ok) },
    { "rx_multicast_phy", PPORT_802_3_OFF(a_multicast_frames_received_ok) },
    { "rx_broadcast_phy", PPORT_802_3_OFF(a_broadcast_frames_received_ok) },
    { "rx_in_range_len_errors_phy", PPORT_802_3_OFF(a_in_range_length_errors) },
    { "rx_out_of_range_len_phy", PPORT_802_3_OFF(a_out_of_range_length_field) },
    { "rx_oversize_pkts_phy", PPORT_802_3_OFF(a_frame_too_long_errors) },
    { "rx_symbol_err_phy", PPORT_802_3_OFF(a_symbol_error_during_carrier) },
    { "tx_mac_control_phy", PPORT_802_3_OFF(a_mac_control_frames_transmitted) },
    { "rx_mac_control_phy", PPORT_802_3_OFF(a_mac_control_frames_received) },
    { "rx_unsupported_op_phy", PPORT_802_3_OFF(a_unsupported_opcodes_received) },
    { "rx_pause_ctrl_phy", PPORT_802_3_OFF(a_pause_mac_ctrl_frames_received) },
    { "tx_pause_ctrl_phy", PPORT_802_3_OFF(a_pause_mac_ctrl_frames_transmitted) },
};

rx_write_requests
static const struct mlx5_ib_counter basic_q_cnts[] = {
    INIT_Q_COUNTER(rx_write_requests),
    INIT_Q_COUNTER(rx_read_requests),
    INIT_Q_COUNTER(rx_atomic_requests),
    INIT_Q_COUNTER(rx_dct_connect),
    INIT_Q_COUNTER(out_of_buffer),
};


MLX5E_DECLARE_STATS_GRP_OP_UPDATE_STATS



struct mlx5_ifc_query_q_counter_out_bits {
    u8         status[0x8];
    u8         reserved_at_8[0x18];

    u8         syndrome[0x20];

    u8         reserved_at_40[0x40];

    u8         rx_write_requests[0x20];


static const struct ib_device_ops hw_stats_ops = {
    .alloc_hw_port_stats = mlx5_ib_alloc_hw_port_stats,
    .get_hw_stats = mlx5_ib_get_hw_stats,
    .counter_bind_qp = mlx5_ib_counter_bind_qp,
    .counter_unbind_qp = mlx5_ib_counter_unbind_qp,
    .counter_dealloc = mlx5_ib_counter_dealloc,
    .counter_alloc_stats = mlx5_ib_counter_alloc_stats,
    .counter_update_stats = mlx5_ib_counter_update_stats,
    .modify_hw_stat = IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS) ?
              mlx5_ib_modify_stat : NULL,
};


rdma_counter_init
    alloc_hw_port_stats


nlmsg_put RDMA_NLDEV_CMD_STAT_SET
.doit = nldev_stat_set_doit
    nldev_stat_set_counter_dynamic_doit
        rdma_counter_modify -> RDMA/nldev：允许通过 RDMA netlink 进行可选计数器状态配置，提供允许用户通过 RDMA netlink 启用/禁用可选计数器的选项。 将其限制为仅具有管理员权限的用户。 示例： 1. 启用可选计数器 cc_rx_ce_pkts 和 cc_rx_cnp_pkts（并禁用所有其他计数器）： $ sudo rdma statistic set link rocep8s0f0/1 option-counters \ cc_rx_ce_pkts,cc_rx_cnp_pkts 2. 删除所有可选计数器： $ sudo rdma statistic unset link rocep8s0 f0/1 可选 -计数器




ib_modify_qp
    _ib_modify_qp
        rdma_counter_bind_qp_auto -> RDMA：支持超过 255 个 rdma 端口，当前代码在处理 RDMA 设备的端口时使用许多不同的类型：u8、unsigned int 和 u32。 切换到 u32 来清理逻辑。 这使我们（至少）能够使核心视图保持一致并使用相同的类型。 不幸的是，并非所有地方都可以转换。 许多 uverbs 函数期望端口为 u8，因此保留这些位置以免破坏 UAPI。 硬件/规范定义的值也不得更改。 通过切换到 u32，我们现在可以支持具有超过 255 个端口的设备。 U32_MAX 被保留以使控制逻辑更容易处理。 由于具有 U32_MAX 端口的设备可能不会很快发生这种情况，这似乎不是问题。 当创建具有超过 255 个端口的设备时，uverbs 将报告 RDMA 设备具有 255 个端口，因为这是当前支持的最大值。 verbs 接口尚未更改，因为 IBTA 规范在太多地方将端口大小限制为 u8，并且所有依赖 verbs 的应用程序将无法应对此更改。 在此阶段，我们正在扩展仅使用供应商通道的接口。一旦解除限制，switchdev 模式下的 mlx5 将能够拥有设备创建的数千个 SF。 由于报告超过 255 个端口的 RDMA 设备的唯一实例将是代表设备，并且它将自身暴露为仅原始以太网设备 CM/MAD/IPoIB 和其他 ULP 不受此更改的影响，并且它们的 sysfs/接口 暴露给用户空间的内容可以保持不变。 虽然在这里清理了一些对齐问题并删除了不需要的健全性检查（主要在 rdmavt 中）
            rdma_restrack_is_tracked
            rdma_is_port_valid
            rdma_get_counter_auto_mode -> qp 在初始化期间根据自动模式自动与计数器绑定（例如，qp 类型，...）
            __rdma_counter_bind_qp -> RDMA/计数器：结合分配和绑定逻辑，RDMA 计数器随后立即分配并绑定到 QP。 只有经过这两个步骤之后，它们才真正可用。 通过组合逻辑，我们确保一旦计数器返回给调用者，它将完成所有设置
                counter_bind_qp -> mlx5_ib_counter_bind_qp -> RDMA/mlx5：与 main.c 分开的计数器，mlx5_ib 中支持多种计数器类型：硬件计数器、拥塞计数器、Q 计数器和流量计数器。 几乎所有支持代码都放在 main.c 中，这使得几乎不可能再维护代码了。 让我们为计数器创建单独的代码命名空间，以方便将来的泛化工作
                    mlx5_cmd_exec_inout(dev->mdev, alloc_q_counter, in, out)
                    mlx5_ib_qp_set_counter -> IB/mlx5：支持设置qp计数器，支持将qp与计数器绑定。 如果 counter 为 null，则将 qp 绑定到默认计数器。 不同的QP状态有不同的操作： - RESET：设置计数器字段，使其在RST2INIT更改期间生效； - RTS：发出RTS2RTS更改以更新QP计数器； - 其他：设置计数器字段并标记 counter_pending 标志，当 QP 转移到 RTS 状态并设置该标志时，然后发出 RTS2RTS 修改来更新计数器
                        MLX5_CAP_GEN(dev->mdev, rts2rts_qp_counters_set_id)
                        if (mqp->state == IB_QPS_RTS)
                            __mlx5_ib_qp_set_counter
                                mlx5_ib_get_counters_id
                                __mlx5_ib_qp_set_raw_qp_counter
                                    mlx5_core_modify_rq
                                        MLX5_CMD_OP_MODIFY_RQ
                                        mlx5_cmd_exec_in(dev, modify_rq, in);
                                            ...
                                MLX5_SET(rts2rts_qp_in, in, opcode, MLX5_CMD_OP_RTS2RTS_QP)
                                return mlx5_cmd_exec_in(dev->mdev, rts2rts_qp, in)
            else -> alloc_and_bind




fill_res_counter_entry



rdma_counter_query_stats
    counter_update_stats


counter_history_stat_update -> RDMA/计数器：在释放之前查询计数器，在释放之前查询动态分配的计数器，以更新其硬件计数器并将所有计数器记录到历史数据中。 否则这些硬件计数器的所有值都将丢失



.modify_qp = mlx5_ib_modify_qp




uverbs
module_init(ib_uverbs_init) -> static int __init ib_uverbs_init(void) -> [PATCH] IB uverbs：核心实现，添加 InfiniBand 用户空间动词实现的核心，包括创建字符设备节点、从用户空间分派请求以及将事件通知传递回用户空间 -> commit: https://github.com/ssbandjl/linux/commit/bc38a6abdd5a50e007d0fcd9b9b6280132b79e62
drivers/infiniband/core/uverbs.h
drivers/infiniband/core/uverbs_cmd.c
drivers/infiniband/core/uverbs_main.c
    register_chrdev_region(IB_UVERBS_BASE_DEV, infiniband_verbs
    alloc_chrdev_region(&dynamic_uverbs_dev, 0,
    class_register(&uverbs_class)
    class_create_file(&uverbs_class, &class_attr_abi_version.attr);
    ib_register_client(&uverbs_client) -> ib_register_client - 注册 IB 客户端，@client:Client 来注册 IB 驱动程序的上层用户可以使用 ib_register_client() 来注册 IB 设备添加和删除的回调。 当添加 IB 设备时，将调用每个已注册客户端的 add 方法（按照客户端注册的顺序），而当删除设备时，将调用每个客户端的 remove 方法（按照客户端注册的相反顺序）。 此外，当调用 ib_register_client() 时，客户端将收到所有已注册设备的添加回调
        init_completion(&client->uses_zero)
        assign_client_id(client)
        xa_for_each_marked
            add_client_context(device, client)
                client->add(device) -> ib_uverbs_add_one


drivers/infiniband/core/device.c -> ib_register_device - 向 IB 核心注册 IB 设备 @device：要注册的设备 @name：唯一的字符串设备名称。 这可能包括“%”，这将导致将唯一索引添加到传递的设备名称中。 @dma_device：指向支持 DMA 的设备的指针。 如果%NULL，则将使用IB 设备。 在这种情况下，调用者应该为 DMA 完全设置 ibdev。 这通常意味着使用 dma_virt_ops。 低级驱动程序使用 ib_register_device() 将其设备注册到 IB 内核。 所有注册的客户端都将收到添加的每个设备的回调。 @device 必须使用 ib_alloc_device() 进行分配。 如果驱动程序使用 ops.dealloc_driver 并异步调用任何 ib_unregister_device() ，则一旦该函数返回，设备指针可能会被释放
int ib_register_device(struct ib_device *device, const char *name, struct device *dma_device) -> roce和IB注册的flow: https://blog.csdn.net/tiantao2012/article/details/77746141
    assign_name(device, name) -> DMA/devices：使用 xarray 来存储 client_data，现在我们为每个客户端都有了一个小 ID，我们可以使用 xarray 而不是线性搜索链表来获取客户端数据。 这将提供更快且可扩展的客户端数据查找，并使我们能够修改锁定方案。 由于xarray可以使用标记来存储'going_down'，因此完全消除了struct ib_client_data并将client_data值直接存储在xarray中。 然而，这确实需要一个特殊的迭代器，因为我们仍然必须迭代任何 NULL client_data 值。 还消除了 client_data_lock 以支持内部 xarray 锁定
        dev_set_name
            err = kobject_set_name_vargs(&dev->kobj, fmt, vargs)
        __ib_device_get_by_name <- static DEFINE_XARRAY_FLAGS(devices, XA_FLAGS_ALLOC);
            xa_for_each (&devices, index, device)
    setup_device(device) -> ib_register_device() 执行多个分配和初始化步骤。 将其拆分为更小、更易读的函数，以便于审查和维护 -> setup_device() 分配内存并设置需要调用设备操作的数据，这是在 ib_alloc_device 期间未完成这些操作的唯一原因。 它由 ib_dealloc_device() 撤消
        ib_device_check_mandatory -> must option
            IB_MANDATORY_FUNC
            mandatory_table
            IB_MANDATORY_FUNC(query_device),
            ...
        setup_port_data -> RDMA/device：将 ib_device per_port 数据合并到一个位置，没有理由对每个端口数据进行 3 次分配。 将它们组合在一起并使所有每端口数据的生命周期与 struct ib_device 匹配。 后续补丁将需要更多特定于端口的数据，现在有一个好地方可以放置它
            alloc_port_data
                rdma_end_port
                rdma_for_each_port
                    INIT_LIST_HEAD(&pdata->pkey_list)
                    INIT_HLIST_NODE(&pdata->ndev_hash_link)
            rdma_for_each_port
                get_port_immutable -> .get_port_immutable = irdma_roce_port_immutable -> 获取端口信息并固化
                    ib_query_port -> 校验端口有效性, 是否iwarp -> __ib_query_port
                        return device->ops.query_port(device, port_num, port_attr) -> or xtrdma_qeury_port
                            static int irdma_query_port(struct ib_device *ibdev, u32 port,
                                props->max_mtu = IB_MTU_4096
                                props->lid = 1;
                                props->lmc = 0;
                                props->sm_lid = 0;
                                props->sm_sl = 0;
                                props->state = IB_PORT_ACTIVE;
                                ib_get_eth_speed(ibdev, port, &props->active_speed,
                                    rdma_port_get_link_layer -> IB_LINK_LAYER_ETHERNET
                                    ib_device_get_netdev -> RDMA/device：添加 ib_device_set_netdev() 作为 get_netdev 的替代方案，关联的 netdev 实际上不应该非常动态，因此对于大多数驱动程序来说，没有理由进行这样的回调。 提供一个 API 来通知核心代码有关网络开发从属关系，并使用核心维护的数据结构。 这使得核心代码能够更加了解 ndev 关系，从而允许一些基于此的新 API。 这也使用了某种意义上的锁定，许多驱动程序都有令人困惑的 RCU 锁定，或者缺少不正确的锁定
                                        pdata = &ib_dev->port_data[port]
                                        ib_dev->ops.get_netdev(ib_dev, port) -> mlx5_ib_get_netdev -> IB/mlx5：支持 IB 设备的回调以获取其 netdev，仅适用于 Eth 端口：在 mlx5_ib_device 中维护网络设备指针，如果网络设备和 IB 设备具有相同的 PCI 父设备，则在 NETDEV_REGISTER 和 NETDEV_UNREGISTER 事件时更新它。 实现 get_netdev 回调以返回该网络设备
                                            mdev = mlx5_ib_get_native_port_mdev(ibdev, port_num, NULL)
                                                mlx5_ib_port_link_layer
                                                mlx5_core_mp_enabled
                                            ndev = mlx5_lag_get_roce_netdev(mdev) -> net/mlx5：获取 RoCE netdev，当 LAG 处于活动状态时，IB 驱动程序使用它来确定 IB 绑定设备的 netdev。 如果模式不是主动备份，则返回 PF0 的 netdev；如果模式是主动备份，则返回主动从机的 PF netdev
                                                ldev = mlx5_lag_dev(dev) -> net/mlx5：更改lag的所有权模型，Lag用于将同一HCA的两个PCI功能组合成单个逻辑单元。 这是核心功能，因此应由核心驱动程序管理。 目前情况并非如此。 当我们将滞后软件结构存储在较低设备内时，其生命周期（创建/销毁）由 mlx5e 部分决定。 更改所有权模型，使延迟与较低级别驱动程序的生命周期相关，而不是与 mlx5e 部分相关
                                                ldev && __mlx5_lag_is_roce(ldev)
                                            mlx5_ib_put_native_port_mdev(ibdev, port_num)
                                                mlx5_core_mp_enabled
                                                mpi = ibdev->port[port_num - 1].mp.mpi
                                        rcu_dereference_protected -> rcu_dereference_protected() - 当更新被阻止时获取 RCU 指针 @p：在解除引用之前要读取的指针 @c：发生解除引用的条件 返回指定 RCU 保护指针的值，但省略 READ_ONCE() 。 这在更新端锁阻止指针值更改的情况下很有用。 请注意，此原语不会阻止编译器重复此引用或将其与其他引用组合，因此不应在没有适当锁保护的情况下使用它。 该功能仅供更新端使用。 仅受 rcu_read_lock() 保护时使用此函数将导致罕见但非常难看的失败
                                            __rcu_dereference_protected
                                        如果我们开始通过防止传播取消注册的 netdev 来加快取消注册的速度
                                    __ethtool_get_link_ksettings -> net: ethtool: 添加新的 ETHTOOL_xLINKSETTINGS API，此补丁定义了新的 ETHTOOL_GLINKSETTINGS/SLINKSETTINGS API，由新的 get_link_ksettings/set_link_ksettings 回调处理。 此 API 提供对大多数旧版 ethtool_cmd 字段的支持，添加对更大链接模式掩码（最多 4064 位，可变长度）的支持，并删除 ethtool_cmd 已弃用的字段（transceiver/maxrxpkt/maxtxpkt）。 此 API 弃用了旧版 ETHTOOL_GSET/SSET API，并提供以下向后兼容性属性： - 带有旧版驱动程序的旧版 ethtool：没有变化，仍然使用 get_settings/set_settings 回调。 - 具有新 get/set_link_ksettings 驱动程序的旧版 ethtool：使用新的驱动程序回调，数据在内部转换为旧版 ethtool_cmd。 ETHTOOL_GSET 将仅返回每个链接模式掩码的第一个 32b。 如果用户尝试将 ethtool_cmd 弃用字段设置为非 0（收发器/maxrxpkt/maxtxpkt），ETHTOOL_SSET 将失败。 如果驱动程序设置较高位，则会记录内核警告。 - 未来的 ethtool 与遗留驱动程序：没有变化，仍然使用 get_settings/set_settings 回调，内部转换为新的数据结构。 不推荐使用的字段（transceiver/maxrxpkt/maxtxpkt）将被忽略，并在用户空间中被视为 0。 请注意，“未来”的 ethtool 工具将不允许更改这些已弃用的字段。 - 未来的 ethtool 具有新的驱动程序：直接调用新的回调。 “未来”ethtool 的含义是： - 查询：首先尝试 ETHTOOL_GLINKSETTINGS，如果失败则恢复到 ETHTOOL_GSET - 设置：首先查询并记住 ETHTOOL_GLINKSETTINGS 或 ETHTOOL_GSET 中哪一个成功了 + 如果 ETHTOOL_GLINKSETTINGS 成功，则使用 ETHTOOL_SLINKSETTINGS 更改配置。 失败是最终的（不要尝试 ETHTOOL_SSET）。 + 否则 ETHTOOL_GSET 成功，使用 ETHTOOL_SSET 更改配置。 失败是最终的（不要尝试 ETHTOOL_SLINKSETTINGS）。 通过新 API 的交互用户/内核首先需要进行一次小的 ETHTOOL_GLINKSETTINGS 握手，以就链接模式位图的长度达成一致。 如果内核不同意用户的要求，它将返回用户期望的位图长度作为负长度（并且 cmd 字段为 0）。 当内核和用户同意时，内核返回所有字段中的有效信息（即链接模式长度> 0且cmd为ETHTOOL_GLINKSETTINGS）。 跨越用户/内核边界的数据结构与 32/64 位无关。 在内部转换为合法的内核位图。 当第一个“link_settings”驱动程序开始出现时，内部 __ethtool_get_settings 内核帮助程序将逐渐被 __ethtool_get_link_ksettings 取代。 所以这个补丁并没有改变它，在需要改变之前它就会被删除
                                        dev->ethtool_ops->get_link_ksettings(dev, link_ksettings)
                                            cmd->base.duplex = DUPLEX_FULL;
                                    ib_get_width_and_speed -> 获取/计算RDMA网卡位宽和速度 -> RDMA/core：从netdev获取IB宽度和速度，以前无法查询网卡的通道数(lanes )，因此相同的netdev_speed会得到固定的位宽和速度。 随着网卡规格越来越多样化，这种固定模式已经不再适用，因此需要一种方法来根据通道数获取正确的宽度和速度。 该补丁从 net_device 检索 netdev 通道和速度，并将其转换为 IB 位宽和速度
                                props->gid_tbl_len = 32;
                                props->pkey_tbl_len = IRDMA_PKEY_TBL_SZ -> 1
                                props->max_msg_sz = iwdev->rf->sc_dev.hw_attrs.max_hw_outbound_msg_size
                            ib_get_cached_subnet_prefix -> IB/core：通过缓存读取ib_query_port中的subnet_prefix。 ib_query_port() 调用 device->ops.query_port() 来获取端口属性。 查询方法是特定于设备驱动程序的。 相同的函数调用device->ops.query_gid()来获取GID并提取subnet_prefix (gid_prefix)。 GID 和subnet_prefix 存储在缓存中。 但如果设备是 Infiniband 设备，则不会从缓存中读取它们。 以下更改利用了缓存的subnet_prefix。 RDBMS 测试表明，此更改使性能有了显着提高
                                *sn_pfx = device->port_data[port_num].cache.subnet_prefix;
                    immutable->max_mad_size = IB_MGMT_MAD_SIZE
                verify_immutable -> 校验固化的端口数据
                    rdma_cap_ib_mad -> rdma_cap_ib_mad - 检查设备的端口是否支持 Infiniband 管理数据报。 @device：要检查的设备 @port_num：要检查的端口号 管理数据报 (MAD) 是 InfiniBand 规范的必需部分，并且受所有 InfiniBand 设备支持。 OPA 接口还支持稍微扩展的版本。 返回：如果端口支持发送/接收MAD数据包，则返回true
                        device->port_data[port_num].immutable.core_cap_flags & RDMA_CORE_CAP_IB_MAD
                    rdma_max_mad_size -> 返回此 RDMA 端口所需的最大 MAD 大小。 @device：设备 @port_num：端口号 该 MAD 大小包括 MAD 标头和 MAD 负载。 不包含其他标头。 返回端口所需的最大 MAD 大小。 如果端口不支持 MAD，则返回 0
                         device->port_data[port_num].immutable.max_mad_size
        device->ops.query_device(device, &device->attrs, &uhw) -> irdma_query_device
    ib_cache_setup_one(device) -> 设置IB(GID)缓存 -> IB/核心：添加 RoCE GID 表管理，RoCE GID 基于与 RDMA (RoCE) 设备端口相关的以太网网络设备上配置的 IP 地址。 目前，每个支持 RoCE（ocrdma、mlx4）的低级驱动程序都管理自己的 RoCE 端口 GID 表。 由于本质上没有任何特定于供应商的内容，因此我们对其进行概括，并增强 RDMA 核心 GID 缓存来完成这项工作。 为了填充 GID 表，我们监听事件： (a) netdev up/down/change_addr 事件 - 如果 netdev 构建在我们的 RoCE 设备上，我们需要添加/删除其 IP。 这涉及添加与此 ndev 相关的所有 GID、添加默认 GID 等。 (b) inet 事件 - 将新 GID（根据 IP 地址）添加到表中。 为了对端口 RoCE GID 表进行编程，提供商必须实现 add_gid 和 del_gid 回调。 RoCE GID 管理要求我们在 GID 旁边声明关联的 net_device。 为了管理 GID 表，此信息是必需的。 例如，当删除 net_device 时，其关联的 GID 也需要删除。 RoCE 要求根据相关网络设备的 IPv6 本地链路为每个端口生成默认 GID。 与基于常规 IPv6 链路本地的 GID（因为我们为每个 IP 地址生成 GID）相反，当网络设备关闭时，默认 GID 也可用（为了支持环回）。 锁定的完成方式如下：该补丁修改了 GID 表代码，适用于实现 add_gid/del_gid 回调的新 RoCE 驱动程序以及未实现 add_gid/del_gid 回调的当前 RoCE 和 IB 驱动程序。 更新表的流程不同，因此锁定要求也不同。 更新 RoCE GID 表时，通过 mutex_lock(&table->lock) 实现针对多个写入者的保护。 由于写入表需要我们在表中查找一个条目（可能是空闲条目）然后修改它，因此该互斥锁保护 find_gid 和 write_gid 确保操作的原子性。 GID 缓存中的每个条目均受 rwlock 保护。 在 RoCE 中，写入（通常来自 netdev 通知程序的结果）涉及调用供应商的 add_gid 和 del_gid 回调，这些回调可能会休眠。 因此，为每个条目添加无效标志。 RoCE 的更新是通过工作队列完成的，因此允许休眠。 在IB中，更新是在write_lock_irq(&device->cache.lock)中完成的，因此write_gid不允许休眠并且add_gid/del_gid不会被调用。 当将网络设备传入/传出 GID 缓存时，该设备始终被传递为保持 (dev_hold)。 该代码使用单个工作项来更新所有 RDMA 设备，遵循 netdev 或 inet 通知程序。 该补丁将缓存从客户端（这是不正确的，因为缓存是 IB 基础设施的一部分）转变为在设备注册/删除时显式初始化/释放
        gid_table_setup_one
            _gid_table_setup_one
                struct ib_gid_table *table
                rdma_for_each_port (ib_dev, rdma_port)
                    table = alloc_gid_table(ib_dev->port_data[rdma_port].immutable.gid_tbl_len)
                    gid_table_reserve_default(ib_dev, rdma_port, table)
                        roce_gid_type_mask = roce_gid_type_mask_support(ib_dev, port)
                        num_default_gids = hweight_long(roce_gid_type_mask) -> 计算1的个数
                        table->default_gid_indices |= BIT(i)
                    ib_dev->port_data[rdma_port].cache.gid = table -> init gid table
            rdma_roce_rescan_device -> 重新扫描系统中的所有网络设备，并根据需要将其 gid 添加到相关 RoCE 设备 -> {net, IB}/mlx5：管理多端口 RoCE 的端口关联，调用 mlx5_ib_add 时确定要添加的 mlx5 核心设备是否能够进行双端口 RoCE 操作。 如果是，请使用 num_vhca_ports 和affiliate_nic_vport_criteria 功能确定它是主设备还是从设备。 如果该设备是从属设备，请尝试找到与其关联的主设备。 可以关联的设备将共享系统映像 GUID。 如果没有找到，请将其放入非关联端口列表中。 如果找到主设备，则通过在 NIC vport 上下文中配置端口从属关系将端口绑定到它。 同样，当调用 mlx5_ib_remove 时确定端口类型。 如果它是从端口，则将其与主设备取消关联，否则只需将其从非关联端口列表中删除即可。 即使第二个端口不可用于关联，IB 设备也会注册为多端口设备。 当第二个端口稍后附属时，必须刷新 GID 缓存才能获取缓存中第二个端口的默认 GID。 导出roce_rescan_device以提供在绑定新端口后刷新缓存的机制。 在多端口配置中，所有 IB 对象（QP、MR、PD 等）相关命令应流经主站 mlx5_core_dev，其他命令必须发送到从端口 mlx5_core_mdev，提供一个接口来获取非 IB 对象命令的正确 mdev
                ib_enum_roce_netdev pass_all_filter enum_all_gids_of_dev_cb
        rdma_for_each_port
            ib_cache_update -> IB/核心：仅在相应事件上更新 PKEY 和 GID 缓存，HCA 中的 PKEY 和 GID 表都可以保存数百个条目。 阅读它们是昂贵的。 部分原因是用于检索它们的 API 一次仅返回一个条目。 此外，在某些实现上，例如 CX-3，VF 在这方面是半虚拟化的，并且必须依赖 PF 驱动程序来执行读取。 这再次需要 VF 到 PF 的通信。 IB Core 的缓存会根据所有事件进行刷新。 因此，根据收到的事件分别为 IB_EVENT_PKEY_CHANGE 和 IB_EVENT_GID_CHANGE 来过滤 PKEY 和 GID 缓存的刷新
                rdma_is_port_valid
                ib_query_port(device, port, tprops)
                rdma_protocol_roce
                config_non_roce_gid_cache(device, port,	tprops) -> IB/核心：重构RoCE的GID修改代码，代码被重构为RoCE准备单独的函数，可以执行与引用计数相关的更复杂的操作，同时仍然保持代码的可读性。 这包括 (a) 简化为不执行 IB 链路层的网络设备检查和修改。 (b) 不要添加具有 NULL 网络设备的 RoCE GID 条目； 相反，返回一个错误。 (c) 如果 GID 添加在提供者级别 add_gid() 失败，则不要在缓存中添加该条目并保持该条目标记为 INVALID。 (d) 简化并重用 ib_cache_gid_add()/del() 例程，以便它们甚至可以用于修改默认 GID。 这避免了修改默认 GID 时的一些代码重复。 (e) find_gid() 例程引用数据条目标志来将 GID 限定为有效或无效 GID，而不是依赖于 GID 内容的属性和零。 (f) gid_table_reserve_default() 在设置 GID 表时一开始就设置 GID 默认属性。 无需在 write_gid()、add_gid()、del_gid() 等低级函数中使用 default_gid 标志，因为它们在 GID 表更新期间永远不需要更新 GID 条目的 DEFAULT 属性。 作为此重构的结果，保留的 GID 0:0:0:0:0:0:0:0 不再可搜索，如下所述。 根据 IB 规范版本 1.3 第 4.1.1 节第 (6) 点，单播 GID 条目 0:0:0:0:0:0:0:0 是保留 GID，其片段如下。 “单播 GID 地址 0:0:0:0:0:0:0:0 是保留的 - 称为保留 GID。它不得分配给任何终端端口。它不得用作目标地址或 全局路由标头（GRH）。” GID 表缓存现在仅存储有效的 GID 条目。 在此补丁之前，可以使用 ib_find_cached_gid_by_port() 和其他类似的查找例程在 GID 表中搜索保留 GID 0:0:0:0:0:0:0:0。 零 GID 不再可搜索，因为它不应出现在 GRH 或路径记录条目中，如 IB 规范版本 1.3 第 4.1.1 节第 (6) 点、第 12.7.10 节和第 12.7.20 节中所述。 ib_cache_update() 被简化为检查链路层一次，对所有链路层使用统一的锁定方案，删除临时 gid 表分配/释放逻辑。 此外，(a) 扩展 ib_gid_attr 以存储端口和索引，以便 GID 查询例程可以从属性结构中获取端口和索引信息。 (b) 扩展 ib_gid_attr 来存储设备，以便在将来的代码中，当完成 GID 引用计数时，设备用于返回到 GID 表条目
                    device->ops.query_gid(device, port, i, &gid_attr.gid)
                    rdma_protocol_iwarp(device, port)
                    add_modify_gid(table, &gid_attr)
                ib_query_pkey -> Get P_Key table entry
                    device->ops.query_pkey(device, port_num, index, pkey) -> irdma_query_pkey -> #define IRDMA_DEFAULT_PKEY		0xFFFF
                ib_security_cache_change -> IB/核心：在 QP 上强制执行 PKey 安全性，添加新的 LSM 挂钩以分配和释放安全上下文，并检查访问 PKey 的权限。 创建和销毁 QP 时分配和释放安全上下文。 此上下文用于控制对 PKey 的访问。 当请求修改 QP 来更改端口、PKey 索引或备用路径时，请检查 QP 是否具有对该端口子网前缀上的 PKey 表索引中的 PKey 的权限。 如果 QP 是共享的，请确保 QP 的所有句柄也具有访问权限。 存储 QP 正在使用的端口和 PKey 索引。 重置到初始化转换后，用户可以独立修改端口、PKey 索引和备用路径。 因此，端口和 PKey 设置更改可以是先前设置和新设置的合并。 为了在 PKey 表或子网前缀更改时维持访问控制，请保留每个端口上使用每个 PKey 索引的所有 QP 的列表。 如果发生更改，则使用该设备和端口的所有 QP 都必须强制执行新缓存设置的访问权限。 这些更改将事务添加到 QP 修改过程中。 如果修改失败，则必须保持与旧端口和 PKey 索引的关联；如果修改成功，则必须将其删除。 必须在修改之前建立与新端口和 PKey 索引的关联，如果修改失败则将其删除。 1. 当 QP 被修改为特定端口时，PKey 索引或备用路径将该 QP 插入到适当的列表中。 2. 检查访问新设置的权限。 3. 如果步骤 2 授予访问权限，则尝试修改 QP。 4a. 如果步骤 2 和 3 成功，则删除任何先前的关联。 4b. 如果以太失败，请删除新的设置关联。 如果 PKey 表或子网前缀发生更改，则遍历 QP 列表并检查它们是否具有权限。 如果没有，则将 QP 发送到错误状态并引发致命错误事件。 如果它是共享 QP，请确保共享 real_qp 的所有 QP 也具有权限。 如果拥有安全结构的 QP 被拒绝访问，则安全结构将被标记为此类，并且 QP 将被添加到 error_list 中。 一旦将 QP 移至错误完成，安全结构标记就会被清除。 正确维护列表会将 QP 销毁转变为事务。 设备的硬件驱动程序释放 ib_qp 结构，因此当销毁正在进行时，ib_qp_security 结构中的 ib_qp 指针未定义。 当销毁过程开始时，ib_qp_security 结构被标记为正在销毁。 这可以防止对 QP 指针采取任何操作。 QP 成功销毁后，它仍然可以列在 error_list 上，等待该流处理它，然后再清理结构。 如果销毁失败，则 QP 端口和 PKey 设置将重新插入到适当的列表中，销毁标志将被清除，并强制执行访问控制，以防在销毁流程期间发生任何缓存更改。 为了保持安全更改隔离，使用新文件来保存与安全相关的功能
                    list_for_each_entry (pkey, &device->port_data[port_num].pkey_list,
                        check_pkey_qps(pkey, device, port_num, subnet_prefix)
                            ib_get_cached_pkey
                            enforce_qp_pkey_security
                                security_ib_pkey_access -> Check if access to an IB pkey is allowed
                                    return call_int_hook(ib_pkey_access, 0, sec, subnet_prefix, pkey) -> selinux_ib_pkey_access
                                        sel_ib_pkey_sid(subnet_prefix, pkey_val, &sid)
                                        avc_has_perm(sec->sid, sid,
                            qp_to_error(pp->sec)
                                .qp_state = IB_QPS_ERR
                                .event = IB_EVENT_QP_FATAL
                                ib_modify_qp(sec->qp,
                                sec->qp->event_handler(&event,
                            list_del(&pp->to_error_list)
                            complete(&pp->sec->error_complete)
    device->groups[0] = &ib_dev_attr_group; -> RDMA/core：通过普通组机制创建设备 hw_counters，而不是调用 device_add_groups() 将组添加到通过 device_add() 管理的现有组数组中。 这需要在 device_add() 之前设置 hw_counters，以便它从已经分割的端口 sysfs 流中分割出来 -> 第一组用于设备属性，第二组用于驱动程序提供的属性（可选）。 第三组是 hw_stats 它是一个以 NULL 结尾的数组
    device->groups[1] = device->ops.device_group;
    ib_setup_device_attrs
        data = alloc_hw_stats_device(ibdev)
        ibdev->ops.get_hw_stats
        sysfs_attr_init(&attr->attr.attr)
        attr->attr.show = hw_stat_device_show
        attr->show = show_hw_stats
        attr->show = show_stats_lifespan;
        attr->attr.store = hw_stat_device_store;
        attr->store = set_stats_lifespan;
    ib_device_register_rdmacg
    rdma_counter_init
    dev_set_uevent_suppress
    ib_setup_port_attrs
    enable_device_and_get
        add_client_context
            client->add(device) -> .add    = ib_uverbs_add_one,
        add_compat_devs(device) -> RDMA/core：在net命名空间中实现compat device/sysfs树，实现ib_core的兼容层sysfs条目，以便非init_net net命名空间也可以发现rdma设备。 每个非 init_net 网络命名空间都在其中创建了 ib_core_device。 这样的 ib_core_device sysfs 树类似于 init_net 命名空间中找到的 rdma 设备。 这允许通过 sysfs 条目在多个非 init_net 网络命名空间中发现 rdma 设备，并且对 rdma-core 用户空间很有帮助
            add_one_compat_dev
    dev_set_uevent_suppress
    kobject_uevent(&device->dev.kobj, KOBJ_ADD)
    ib_device_put


static struct ib_client uverbs_client = {
    .name   = "uverbs",
    .no_kverbs_req = true,
    .add    = ib_uverbs_add_one,
    .remove = ib_uverbs_remove_one,
    .get_nl_info = ib_uverbs_get_nl_info,
};

ib_uverbs_add_one  -> RDMA：允许 ib_client 在调用 add() 时失败，添加客户端时不允许失败，但所有客户端在其添加例程中都有各种失败路径。 这会产生一种非常边缘的情况：添加客户端后，在添加过程中失败并且未设置 client_data。 然后，核心代码仍然会使用 NULL client_data 调用其他以 client_data 为中心的操作，例如 remove()、rename()、get_nl_info() 和 get_net_dev_by_params() - 这是令人困惑和意外的。 如果 add() 回调失败，则不要再为设备调用任何客户端操作，甚至删除。 删除操作回调中现在对 NULL client_data 的所有冗余检查。 更新所有 add() 回调以正确返回错误代码。 EOPNOTSUPP 用于 ULP 不支持 ib_device 的情况 - 例如，因为它仅适用于 IB
参考: https://www.cnblogs.com/vlhn/p/8301427.html
    device_initialize(&uverbs_dev->dev)
    init_completion(&uverbs_dev->comp)
    uverbs_dev->xrcd_tree = RB_ROOT
    INIT_LIST_HEAD(&uverbs_dev->uverbs_file_list) <- list_add_tail(&file->list, &dev->uverbs_file_list) <- ib_uverbs_open
    ib_uverbs_create_uapi
        uverbs_alloc_api
            uapi_merge_def(uapi, ibdev, uverbs_core_api, false)
                uapi_merge_obj_tree
                    uapi_merge_method
                case UAPI_DEF_WRITE:
		            rc = uapi_create_write(uapi, ibdev, def, cur_obj_key, &cur_method_key);
                        method_elm->handler = def->func_write -> 注册内核态uverbs接口
    dev_set_name uverbs/xxx
    cdev_init device->ops.mmap ? &uverbs_mmap_fops : &uverbs_fops);
    cdev_device_add
    ib_set_client_data
        xa_store(&device->client_data, client->client_id, data,


定义内核态供用户态使用的verbs内核接口
drivers/infiniband/core/uverbs_uapi.c
static const struct uapi_definition uverbs_core_api[] = {
	UAPI_DEF_CHAIN(uverbs_def_obj_counters),
	UAPI_DEF_CHAIN(uverbs_def_obj_cq),
	UAPI_DEF_CHAIN(uverbs_def_obj_device),
	UAPI_DEF_CHAIN(uverbs_def_obj_dm),
	UAPI_DEF_CHAIN(uverbs_def_obj_flow_action),
	UAPI_DEF_CHAIN(uverbs_def_obj_intf),
	UAPI_DEF_CHAIN(uverbs_def_obj_mr),
	UAPI_DEF_CHAIN(uverbs_def_write_intf),
	{},
};

rdma user/kernel api/abi:
const struct uapi_definition uverbs_def_write_intf[] = {
    ...
    DECLARE_UVERBS_OBJECT(
    UVERBS_OBJECT_PD,
    DECLARE_UVERBS_WRITE(
        IB_USER_VERBS_CMD_ALLOC_PD,
        ib_uverbs_alloc_pd,
        UAPI_DEF_WRITE_UDATA_IO(struct ib_uverbs_alloc_pd,
                    struct ib_uverbs_alloc_pd_resp),
        UAPI_DEF_METHOD_NEEDS_FN(alloc_pd)),
    DECLARE_UVERBS_WRITE(
        IB_USER_VERBS_CMD_DEALLOC_PD,
        ib_uverbs_dealloc_pd,
        UAPI_DEF_WRITE_I(struct ib_uverbs_dealloc_pd),
        UAPI_DEF_METHOD_NEEDS_FN(dealloc_pd))),
    ...
}
====>
{
    .kind = UAPI_DEF_OBJECT_START, 
    .object_start = { .object_id = UVERBS_OBJECT_PD }, 
},
{ 
    .kind = UAPI_DEF_WRITE, 
    .scope = UAPI_SCOPE_OBJECT, 
    .write = { 
        .is_ex = 0, 
        .command_num = IB_USER_VERBS_CMD_ALLOC_PD 
        }, 
        .func_write = ib_uverbs_alloc_pd,   <- method_elm->handler = def->func_write
        .write.has_resp = 1 + (sizeof(struct { int:(-!!(offsetof(struct ib_uverbs_alloc_pd, response) != 0)); })) + (sizeof(struct { int:(-!!(sizeof(((struct ib_uverbs_alloc_pd *)0)->response) != sizeof(u64))); })), 
        .write.req_size = sizeof(struct ib_uverbs_alloc_pd), .write.resp_size = sizeof(struct ib_uverbs_alloc_pd_resp), 
        .write.has_udata = 1 + (sizeof(struct { int:(-!!(offsetof(struct ib_uverbs_alloc_pd, driver_data) != sizeof(struct ib_uverbs_alloc_pd))); })) + (sizeof(struct { int:(-!!(offsetof(struct ib_uverbs_alloc_pd_resp, driver_data) != sizeof(struct ib_uverbs_alloc_pd_resp))); })), 
},
{ 
    .kind = UAPI_DEF_IS_SUPPORTED_DEV_FN, 
    .scope = UAPI_SCOPE_METHOD, 
    .needs_fn_offset = offsetof(struct ib_device_ops, alloc_pd) + (sizeof(struct { int:(-!!(sizeof(((struct ib_device_ops *)0)->alloc_pd) != sizeof(void *))); })), }, 
{ 
    .kind = UAPI_DEF_WRITE, 
    .scope = UAPI_SCOPE_OBJECT, 
    .write = { 
        .is_ex = 0, 
        .command_num = IB_USER_VERBS_CMD_DEALLOC_PD 
    }, 
    .func_write = ib_uverbs_dealloc_pd, 
    .write.req_size = sizeof(struct ib_uverbs_dealloc_pd), 
},
{ 
    .kind = UAPI_DEF_IS_SUPPORTED_DEV_FN, 
    .scope = UAPI_SCOPE_METHOD, 
    .needs_fn_offset = offsetof(struct ib_device_ops, dealloc_pd) + (sizeof(struct { int:(-!!(sizeof(((struct ib_device_ops *)0)->dealloc_pd) != sizeof(void *))); })), 
}


    

qemu guest vm:
ibv_alloc_pd
root@u20:~/project/rdma/rdma-core/build/bin# ./ibv_rc_pingpong -d rxe_ens3 -g 0
Thread 3 hit Breakpoint 2, ib_uverbs_alloc_pd (attrs=0xffffc900045f3c88) at drivers/infiniband/core/uverbs_cmd.c:406
406     {
(gdb) bt
#0  ib_uverbs_alloc_pd (attrs=0xffffc900045f3c88) at drivers/infiniband/core/uverbs_cmd.c:406
#1  0xffffffffa065c825 in ib_uverbs_handler_UVERBS_METHOD_INVOKE_WRITE (attrs=0xffffc900045f3c88) at drivers/infiniband/core/uverbs_std_types_device.c:41
#2  0xffffffffa0659a95 in ib_uverbs_run_method (num_attrs=<optimized out>, pbundle=<optimized out>) at drivers/infiniband/core/uverbs_ioctl.c:471
#3  ib_uverbs_cmd_verbs (ufile=<optimized out>, hdr=<optimized out>, user_attrs=<optimized out>) at drivers/infiniband/core/uverbs_ioctl.c:612
#4  0xffffffffa0659cc8 in ib_uverbs_ioctl (filp=<optimized out>, cmd=<optimized out>, arg=140726932025184) at drivers/infiniband/core/uverbs_ioctl.c:644
#5  0xffffffff81371f87 in vfs_ioctl (arg=<optimized out>, cmd=<optimized out>, filp=<optimized out>) at fs/ioctl.c:47
#6  file_ioctl (arg=<optimized out>, cmd=<optimized out>, filp=<optimized out>) at fs/ioctl.c:510
#7  do_vfs_ioctl (filp=0xffff8880aa0dff00, fd=<optimized out>, cmd=<optimized out>, arg=140726932025184) at fs/ioctl.c:697
#8  0xffffffff81372257 in ksys_ioctl (fd=3, cmd=3222805249, arg=140726932025184) at fs/ioctl.c:714
#9  0xffffffff8137229a in __do_sys_ioctl (arg=<optimized out>, cmd=<optimized out>, fd=<optimized out>) at fs/ioctl.c:721
#10 __se_sys_ioctl (arg=<optimized out>, cmd=<optimized out>, fd=<optimized out>) at fs/ioctl.c:719
#11 __x64_sys_ioctl (regs=<optimized out>) at fs/ioctl.c:719
#12 0xffffffff81005497 in do_syscall_64 (nr=<optimized out>, regs=0xffffc900045f3f58) at arch/x86/entry/common.c:290
#13 0xffffffff81e0008c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:175
#14 0x0000000000000004 in fixed_percpu_data ()
#15 0x00005596cd698260 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#16 0x0000000000000004 in fixed_percpu_data ()
#17 0x00007ffd8acb30ec in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#18 0x00007ffd8acb2f78 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#19 0x00007ffd8acb2f40 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#20 0x0000000000000246 in ib_umem_odp_unmap_dma_pages (umem_odp=0x0 <fixed_percpu_data>, virt=<optimized out>, bound=<optimized out>)

(gdb) info threads
  Id   Target Id                    Frame 
  1    Thread 1.1 (CPU#0 [running]) timerqueue_add (head=0xffff88813ba1dee0, node=0xffff88813ba1e3a0) at lib/timerqueue.c:37
  2    Thread 1.2 (CPU#1 [running]) vring_map_single (vq=0xffff88813a868a80, cpu_addr=0xffff888138762e00, size=432, direction=<optimized out>) at drivers/virtio/virtio_ring.c:342
* 3    Thread 1.3 (CPU#2 [running]) timerqueue_add (head=0xffff88813ba9dee0, node=0xffff88813ba9e3a0) at lib/timerqueue.c:47
  4    Thread 1.4 (CPU#3 [running]) 0xffffffff811e5125 in seccomp_run_filters (match=<optimized out>, sd=<optimized out>) at kernel/seccomp.c:272
  5    Thread 1.5 (CPU#4 [halted ]) 0xffffffff81c46cce in native_safe_halt () at ./arch/x86/include/asm/irqflags.h:60
  6    Thread 1.6 (CPU#5 [halted ]) 0xffffffff81c46cce in native_safe_halt () at ./arch/x86/include/asm/irqflags.h:60
  7    Thread 1.7 (CPU#6 [halted ]) 0xffffffff81c46cce in native_safe_halt () at ./arch/x86/include/asm/irqflags.h:60
  8    Thread 1.8 (CPU#7 [running]) 0x00007f99178f6142 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306


ibv_alloc_pd



ib_uverbs_ex_create_flow


static const struct file_operations uverbs_fops = {
	.owner	 = THIS_MODULE,
	.write	 = ib_uverbs_write,
	.open	 = ib_uverbs_open,
	.release = ib_uverbs_close,
	.llseek	 = no_llseek,
	.unlocked_ioctl = ib_uverbs_ioctl,
	.compat_ioctl = ib_uverbs_ioctl,
};

...
ib_uverbs_add_one
    cdev_init(&uverbs_dev->cdev,device->ops.mmap ? &uverbs_mmap_fops : &uverbs_fops);

ioctl:
...
ENTRY(entry_SYSCALL_64)
    movq	%rsp, %rsi
    call	do_syscall_64 /* returns with IRQs disabled */ <- entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:175 -> __visible void do_syscall_64
        enter_from_user_mode
        ti = current_thread_info()
        regs->ax = sys_call_table[nr](regs) -> SYSCALL_DEFINE3(ioctl, unsigned int, fd, unsigned int, cmd, unsigned long, arg)-> ksys_ioctl(fd, cmd, arg)
            security_file_ioctl
            error = do_vfs_ioctl(f.file, fd, cmd, arg)
                switch (cmd)
                default:
                    error = file_ioctl(filp, cmd, arg)
                        switch (cmd)
                        vfs_ioctl(filp, cmd, arg) -> error = filp->f_op->unlocked_ioctl(filp, cmd, arg) <- .unlocked_ioctl = ib_uverbs_ioctl
                            copy_from_user
                            srcu_read_lock
                            ib_uverbs_cmd_verbs
                                radix_tree_iter_lookup uapi_key_ioctl_method(hdr->method_id)
                                ib_uverbs_run_method -> ret = handler(&pbundle->bundle) -> static int UVERBS_HANDLER(UVERBS_METHOD_INVOKE_WRITE)
                                    return method_elm->handler(attrs)
                                        ib_uverbs_alloc_pd

                            srcu_read_unlock
        syscall_return_slowpath(regs)



#define DECLARE_UVERBS_NAMED_METHOD(_method_id, ...)                           \
	static const struct uverbs_attr_def *const UVERBS_METHOD_ATTRS(        \
		_method_id)[] = { __VA_ARGS__ };                               \
	static const struct uverbs_method_def UVERBS_METHOD(_method_id) = {    \
		.id = _method_id,                                              \
		.handler = UVERBS_HANDLER(_method_id),                         \
		.num_attrs = ARRAY_SIZE(UVERBS_METHOD_ATTRS(_method_id)),      \
		.attrs = &UVERBS_METHOD_ATTRS(_method_id),                     \
	}    


...
ib_uverbs_alloc_pd
    uverbs_request
    uobj_alloc(UVERBS_OBJECT_PD, attrs, &ib_dev) -> handle SIGTRAP nostop noprint ignore
    rdma_zalloc_drv_obj(ib_dev, ib_pd)
    pd->res.type = RDMA_RESTRACK_PD
    ret = ib_dev->ops.alloc_pd(pd, &attrs->driver_udata) -> rxe_alloc_pd
        rxe_add_to_pool
            might_sleep_if -> _cond_resched
                should_resched -> unlikely(raw_cpu_read_4(__preempt_count) == preempt_offset)
                preempt_schedule_common
                do
                    preempt_latency_start
                    __schedule(true)
                    preempt_latency_stop(1)
                    preempt_enable_no_resched_notrace()
                rcu_all_qs
            kref_get
            ib_device_try_get
            elem->pool = pool
            kref_init
    uobj->object = pd
    rdma_restrack_uadd(&pd->res)
    uverbs_response
    uobj_alloc_commit

...
.create_qp = rxe_create_qp,
rxe_create_qp
    rxe_qp_from_init
        rxe_qp_init_req
            rxe_init_task(rxe, &qp->comp.task, qp, rxe_completer, "comp")
            timer_setup(&qp->rnr_nak_timer, rnr_nak_timer, 0)
            timer_setup(&qp->retrans_timer, retransmit_timer, 0) <- mod_timer(&qp->retrans_timer
        rxe_qp_init_resp
            rxe_init_task(rxe, &qp->resp.task, qp, rxe_responder, "resp");
                check_resource
                    if (pkt->mask & RXE_RWR_MASK)
                        get_srq_wqe
                            wqe = queue_head(q)
                            memcpy(&qp->resp.srq_wqe, wqe, sizeof(qp->resp.srq_wqe))
                            qp->resp.wqe = &qp->resp.srq_wqe.wqe
                            advance_consumer(q)
                            srq->ibsrq.event_handler(&ev, srq->ibsrq.srq_context)
                        qp->resp.wqe = queue_head(qp->rq.queue);
rxe_completer
    case COMPST_GET_WQE
        state = get_wqe(qp, pkt, &wqe)



bool timerqueue_add
    rb_link_node(&node->node, parent, p)



virtqueue_add_split
    static dma_addr_t vring_map_single


(gdb) thread 2
[Switching to thread 2 (Thread 1.2)]
#0  vring_map_single (vq=0xffff88813a868a80, cpu_addr=0xffff888138762e00, size=432, direction=<optimized out>) at drivers/virtio/virtio_ring.c:342
342     static dma_addr_t vring_map_single(const struct vring_virtqueue *vq,
(gdb) bt
#0  vring_map_single (vq=0xffff88813a868a80, cpu_addr=0xffff888138762e00, size=432, direction=<optimized out>) at drivers/virtio/virtio_ring.c:342
#1  0xffffffff8174396e in virtqueue_add_split (gfp=<optimized out>, ctx=<optimized out>, data=<optimized out>, in_sgs=<optimized out>, out_sgs=<optimized out>, total_sg=<optimized out>, sgs=<optimized out>, _vq=<optimized out>) at drivers/virtio/virtio_ring.c:512
#2  virtqueue_add (gfp=<optimized out>, ctx=<optimized out>, data=<optimized out>, in_sgs=<optimized out>, out_sgs=<optimized out>, total_sg=<optimized out>, sgs=<optimized out>, _vq=<optimized out>) at drivers/virtio/virtio_ring.c:1706
#3  virtqueue_add_sgs (_vq=0xffff88813a868a80, sgs=<optimized out>, out_sgs=<optimized out>, in_sgs=947269120, data=<optimized out>, gfp=<optimized out>) at drivers/virtio/virtio_ring.c:1740
#4  0xffffffffa0016d7b in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#5  0x0000000000000010 in fixed_percpu_data ()
#6  0x0000000100000000 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#7  0xffff88813a868a80 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#8  0xffffc90001143a18 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#9  0x0000000000000286 in consumer_addr (q=<optimized out>) at drivers/infiniband/sw/rxe/rxe_resp.c:923
#10 queue_head (q=<optimized out>) at drivers/infiniband/sw/rxe/rxe_queue.h:171
#11 check_resource (pkt=<optimized out>, qp=<optimized out>) at drivers/infiniband/sw/rxe/rxe_resp.c:395
#12 rxe_responder (arg=0x2 <fixed_percpu_data+2>) at drivers/infiniband/sw/rxe/rxe_resp.c:1264
#13 0xffffffff815a2426 in __blk_mq_issue_directly (last=<optimized out>, cookie=<optimized out>, rq=<optimized out>, hctx=<optimized out>) at block/blk-mq.c:1809
#14 __blk_mq_try_issue_directly (hctx=0xffff888035689000, rq=0xffff8880363363c0, cookie=0xffffc90001143a74, bypass_insert=true, last=<optimized out>) at block/blk-mq.c:1861
#15 0xffffffff815a30eb in blk_mq_request_issue_directly (rq=0xffff8880363363c0, last=<optimized out>) at block/blk-mq.c:1897
#16 0xffffffff815a31c6 in blk_mq_try_issue_list_directly (hctx=0xffff888035689000, list=0xffffc90001143b50) at ./include/linux/list.h:268
#17 0xffffffff815a880e in blk_mq_sched_insert_requests (hctx=0xffff888035689000, ctx=0xffffe8ffffc47bc0, list=<optimized out>, run_queue_async=false) at block/blk-mq-sched.c:437
#18 0xffffffff815a2ff2 in blk_mq_flush_plug_list (plug=<optimized out>, from_schedule=<optimized out>) at block/blk-mq.c:1772
#19 0xffffffff815977d3 in blk_flush_plug_list (plug=0xffffc90001143c70, from_schedule=<optimized out>) at block/blk-core.c:1769
#20 0xffffffff81597826 in blk_finish_plug (plug=<optimized out>) at block/blk-core.c:1786
#21 blk_finish_plug (plug=<optimized out>) at block/blk-core.c:1782
#22 0xffffffff8143cd58 in ext4_writepages (mapping=<optimized out>, wbc=<optimized out>) at fs/ext4/inode.c:2939
#23 0xffffffff812973e3 in do_writepages (mapping=0xffff8881153170d8, wbc=0xffffc90001143dc0) at mm/page-writeback.c:2344
#24 0xffffffff8128d0c5 in __filemap_fdatawrite_range (mapping=0xffff8881153170d8, start=<optimized out>, end=<optimized out>, sync_mode=<optimized out>) at mm/filemap.c:421
#25 0xffffffff8128e574 in file_write_and_wait_range (file=0xffff888138ae7d00, lstart=0, lend=9223372036854775807) at mm/filemap.c:782
#26 0xffffffff8142a023 in ext4_sync_file (file=0xffff888138ae7d00, start=<optimized out>, end=9223372036854775807, datasync=0) at fs/ext4/fsync.c:128
#27 0xffffffff81398449 in vfs_fsync_range (file=0xffff888138ae7d00, start=0, end=<optimized out>, datasync=<optimized out>) at fs/sync.c:197
#28 0xffffffff813984dd in vfs_fsync (datasync=<optimized out>, file=<optimized out>) at fs/sync.c:221
#29 do_fsync (fd=<optimized out>, datasync=0) at fs/sync.c:221
#30 0xffffffff81398524 in __do_sys_fsync (fd=<optimized out>) at fs/sync.c:229
#31 __se_sys_fsync (fd=<optimized out>) at fs/sync.c:227
#32 __x64_sys_fsync (regs=<optimized out>) at fs/sync.c:227
#33 0xffffffff81005497 in do_syscall_64 (nr=<optimized out>, regs=0xffffc90001143f58) at arch/x86/entry/common.c:290
#34 0xffffffff81e0008c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:175
#35 0x0000000000000000 in ?? ()





(gdb) bt
#0  ib_uverbs_alloc_pd (attrs=0xffffc90004243c88) at drivers/infiniband/core/uverbs_cmd.c:406
#1  0xffffffffa065c825 in ib_uverbs_handler_UVERBS_METHOD_INVOKE_WRITE (attrs=0xffffc90004243c88) at drivers/infiniband/core/uverbs_std_types_device.c:41
#2  0xffffffffa0659a95 in ib_uverbs_run_method (num_attrs=<optimized out>, pbundle=<optimized out>) at drivers/infiniband/core/uverbs_ioctl.c:471
#3  ib_uverbs_cmd_verbs (ufile=<optimized out>, hdr=<optimized out>, user_attrs=<optimized out>) at drivers/infiniband/core/uverbs_ioctl.c:612
#4  0xffffffffa0659cc8 in ib_uverbs_ioctl (filp=<optimized out>, cmd=<optimized out>, arg=140737488346176) at drivers/infiniband/core/uverbs_ioctl.c:644
#5  0xffffffff81371f87 in vfs_ioctl (arg=<optimized out>, cmd=<optimized out>, filp=<optimized out>) at fs/ioctl.c:47
#6  file_ioctl (arg=<optimized out>, cmd=<optimized out>, filp=<optimized out>) at fs/ioctl.c:510
#7  do_vfs_ioctl (filp=0xffff8880b6aa8600, fd=<optimized out>, cmd=<optimized out>, arg=140737488346176) at fs/ioctl.c:697
#8  0xffffffff81372257 in ksys_ioctl (fd=3, cmd=3222805249, arg=140737488346176) at fs/ioctl.c:714
#9  0xffffffff8137229a in __do_sys_ioctl (arg=<optimized out>, cmd=<optimized out>, fd=<optimized out>) at fs/ioctl.c:721
#10 __se_sys_ioctl (arg=<optimized out>, cmd=<optimized out>, fd=<optimized out>) at fs/ioctl.c:719
#11 __x64_sys_ioctl (regs=<optimized out>) at fs/ioctl.c:719
#12 0xffffffff81005497 in do_syscall_64 (nr=<optimized out>, regs=0xffffc90004243f58) at arch/x86/entry/common.c:290
#13 0xffffffff81e0008c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:175
#14 0x0000000000000004 in fixed_percpu_data ()
#15 0x0000555555567260 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#16 0x0000000000000004 in fixed_percpu_data ()
#17 0x00007fffffffddcc in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#18 0x00007fffffffdc58 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#19 0x00007fffffffdc20 in ?? () at drivers/infiniband/core/uverbs_cmd.c:3306
#20 0x0000000000000246 in consumer_addr (q=<optimized out>) at drivers/infiniband/sw/rxe/rxe_resp.c:974
#21 queue_head (q=<optimized out>) at drivers/infiniband/sw/rxe/rxe_queue.h:171
#22 get_srq_wqe (qp=<optimized out>) at drivers/infiniband/sw/rxe/rxe_resp.c:328
#23 check_resource (pkt=<optimized out>, qp=<optimized out>) at drivers/infiniband/sw/rxe/rxe_resp.c:393
#24 rxe_responder (arg=0x0 <fixed_percpu_data>) at drivers/infiniband/sw/rxe/rxe_resp.c:1264








rxe:
commit: https://github.com/ssbandjl/linux/commit/8700e3e7c4857d28ebaa824509934556da0b3e76

Soft RoCE 驱动程序 Soft RoCE (RXE) - 软件 RoCE 驱动程序 ib_rxe 实现 RDMA 传输并作为内核动词提供程序注册到 RDMA 核心设备。 它还实现了数据包IO层。 另一方面，ib_rxe 作为 udp 封装协议（在这种情况下为 RDMA）注册到 Linux netdev 堆栈，用于通过任何以太网设备发送和接收数据包。 这会在 UDP/以太网网络层上产生 RDMA 传输，形成 RoCEv2 兼容设备。 Soft RoCE 驱动程序的配置过程需要绑定到任何现有的以太网网络设备。 这是通过 /sys 接口完成的。 用户空间 Soft RoCE 库 (librxe) 为用户应用程序提供了与 Soft RoCE 设备一起运行的能力。 在用户空间中使用 rxe 动词需要包含 librxe 作为 libibverbs 的设备特定插件。 librxe是单独打包的

Architecture:

     +-----------------------------------------------------------+
     |                          Application                      |
     +-----------------------------------------------------------+
                            +-----------------------------------+
                            |             libibverbs            |
User                        +-----------------------------------+
                            +----------------+ +----------------+
                            | librxe         | | HW RoCE lib    |
                            +----------------+ +----------------+
+---------------------------------------------------------------+
     +--------------+                           +------------+
     | Sockets      |                           | RDMA ULP   |
     +--------------+                           +------------+
     +--------------+                  +---------------------+
     | TCP/IP       |                  | ib_core             |
     +--------------+                  +---------------------+
                             +------------+ +----------------+
Kernel                       | ib_rxe     | | HW RoCE driver |
                             +------------+ +----------------+
     +------------------------------------+
     | NIC driver                         |
     +------------------------------------+





late_initcall(rxe_module_init); -> rxe_module_init -> rdma_rxe：确保rdma_rxe init在正确的时间发生，当CONFIG_RDMA_RXE=y且CONFIG_IPV6=y时出现问题。 这会导致 rdma_rxe 初始化在 IPv6 服务准备就绪之前发生。 该补丁将 rdma_rxe 的初始化延迟到 IPv6 服务准备就绪之后。 此修复基于 Logan Gunthorpe 在更旧的代码库上提出的修复
    rxe_alloc_wq
        rxe_wq = alloc_workqueue("rxe_wq", WQ_UNBOUND, WQ_MAX_ACTIVE)
    rxe_net_init
        rxe_net_ipv4_init
            rxe_setup_udp_tunnel
                udp_sock_create
                    udp_sock_create4
                        sock_create_kern
                        kernel_bind
                    or udp_sock_create6
                tnl_cfg.encap_rcv = rxe_udp_encap_recv
                    rxe_get_dev_from_net
                    if (skb_linearize(skb))
                    udph = udp_hdr(skb)
                    pkt->paylen = be16_to_cpu(udph->len) - sizeof(*udph)
                    skb_pull(skb, sizeof(struct udphdr))
                    rxe_rcv(skb)
                        rxe_chk_dgid
                        pkt->opcode = bth_opcode(pkt)
                        pkt->psn = bth_psn(pkt)
                        pkt->mask |= rxe_opcode[pkt->opcode].mask -> struct rxe_opcode_info rxe_opcode[RXE_NUM_OPCODE]
                        hdr_check
                        rxe_icrc_check
                            rxe_icrc_hdr
                            rxe_crc32
                                SHASH_DESC_ON_STACK
                                crypto_shash_update
                                shash_desc_ctx
                                barrier_data
                            icrc = ~icrc
                        rxe_counter_inc
                            atomic64_inc(&rxe->stats_counters[index])
                        rxe_rcv_pkt(pkt, skb)
                            rxe_resp_queue_pkt
                            or rxe_comp_queue_pkt
                                skb_queue_tail(&qp->resp_pkts, skb)
                                rxe_sched_task(&qp->comp.task)
                                or rxe_run_task(&qp->comp.task)
                setup_udp_tunnel_sock
        rxe_net_ipv6_init
        register_netdevice_notifier(&rxe_net_notifier)
    rdma_link_register(&rxe_link_ops) -> RDMA/core：添加 RDMA_NLDEV_CMD_NEWLINK/DELLINK 支持，添加对新 LINK 消息的支持以允许添加和删除 rdma 接口。 这最初将用于软 rdma 驱动程序，该驱动程序由管理员指定要使用的 netdev 设备动态实例化设备实例。 rdma_rxe 模块将是这些消息的第一个用户。 该设计是根据 RTNL_NEWLINK/DELLINK 建模的：如果 rdma 驱动程序提供链接添加/删除功能，则它们会向 rdma 内核注册。 每个驱动程序都注册一个唯一的“类型”字符串，用于调度来自用户空间的消息。 为“type”字符串定义了新的 RDMA_NLDEV_ATTR。 用户模式将在 NEWLINK 消息中传递 3 个属性：RDMA_NLDEV_ATTR_DEV_NAME 表示要创建的所需 rdma 设备名称，RDMA_NLDEV_ATTR_LINK_TYPE 表示要添加的链接“类型”，RDMA_NLDEV_ATTR_NDEV_NAME 表示用于此链接的 net_device 接口。 DELLINK 消息将包含要删除的设备的 RDMA_NLDEV_ATTR_DEV_INDEX
        down_write(&link_ops_rwsem)
        list_add(&ops->list, &link_ops)
        up_write(&link_ops_rwsem)
    pr_info("loaded\n")


static struct rdma_link_ops rxe_link_ops = {
	.type = "rxe",
	.newlink = rxe_newlink,
};
rxe_newlink -> 添加对 RDMA_NLDEV_CMD_NEWLINK/DELLINK 消息的支持，允许动态添加新的 RXE 链接。 暂时弃用旧的模块选项
    is_vlan_dev -> RDMA/rxe：防止在 vlan 接口之上创建 rxe，在 vlan 接口之上创建 rxe 设备将创建一个无功能的设备，该设备具有空的 gids 表，并且不能用于 rdma cm 通信。 这是由 enum_all_gids_of_dev_cb()/is_eth_port_of_netdev() 中的逻辑引起的，该逻辑仅考虑连接到已配置网络设备的“上层设备”的网络，导致 vlan 接口的 gid 集为空，并尝试通过此 rdma 连接 由于无法解析 gid，设备在 cm_init_av_for_response 中失败。 显然，实现此行为是为了适应为每个端口创建 RoCE 设备的 HW-RoCE 设备，因此 RXE 的行为必须与 HW-RoCE 设备相同，并且仅为每个真实设备创建 rxe 设备。 为了通过 vlan 接口进行通信，用户必须使用 vlan 地址的 gid 索引，而不是通过 vlan 创建 rxe
    rxe_get_dev_from_net
    rxe_net_add
        ib_alloc_device
        rxe_add
            rxe_init -> RDMA/rxe：用xarray替换红黑树，当前rxe驱动程序使用红黑树向rxe对象池添加索引。 Linux xarrays 提供了一种更好的方法来实现索引的相同功能。 此补丁将池对象的红黑树替换为 xarray。 由于 xarray 已经有一个自旋锁，请使用它来代替池 rwlock。 确保 xarray(index) 和 kref(ref count) 中的所有更改均以原子方式发生
                rxe_init_device_param
                    rxe->attr.vendor_id			= RXE_VENDOR_ID
                    addrconf_addr_eui48((unsigned char *)&rxe->attr.sys_image_guid -> RDMA/rxe：将 sys_image_guid 设置为与 HW IB 设备对齐，RXE 驱动程序不设置 sys_image_guid，并且用户空间应用程序看到零。 这会导致 pyverbs 测试失败并出现以下回溯，因为 IBTA 规范要求具有有效的 sys_image_guid。 回溯（最近一次调用最后一次）：文件“./tests/test_device.py”，第 51 行，在 test_query_device self.verify_device_attr(attr) 文件“./tests/test_device.py”，第 74 行，在 verify_device_attr 中断言 attr.sys_image_guid != 0 为了修复它，请将 sys_image_guid 设置为等于 node_guid
                rxe_init_ports -> RDMA/rxe：删除 pkey 表，RoCE 规范要求 RoCE 设备仅支持默认 pkey。 然而，rxe 驱动程序维护一个 64 个实体的 pkey 表，并且仅使用第一个条目。 删除 pkey 表并使用默认 pkey 硬连接长度为 1 的表进行硬编码。 将 pkey_table 的所有检查替换为与 default_pkey 的比较
                    rxe_init_port_param
                        port->attr.state		= IB_PORT_DOWN
                        ...
                rxe_init_pools
                    rxe_pool_init(rxe, &rxe->uc_pool, RXE_TYPE_UC)
                        pool->rxe		= rxe
                        pool->elem_size		= ALIGN(info->size, RXE_POOL_ALIGN)
                        xa_init_flags(&pool->xa, XA_FLAGS_ALLOC)
                rxe->mcg_tree = RB_ROOT
            rxe_set_mtu
                eth_mtu_int_to_enum
                mtu = mtu ? min_t(enum ib_mtu, mtu, IB_MTU_4096) : IB_MTU_256
            rxe_register_device(rxe, ibdev_name)
                dev->node_type = RDMA_NODE_IB_CA
                ib_set_device_ops(dev, &rxe_dev_ops)
                ib_device_set_netdev(&rxe->ib_dev, rxe->ndev, 1)
                    alloc_port_data
                    add_ndev_hash
                        hash_add_rcu(ndev_hash, &pdata->ndev_hash_link, -> RDMA/device：添加 ib_device_get_by_netdev()，多个驱动程序需要从给定的 netdev 查找 ib_device。 rxe 在无法入睡的情况下需要快速完成此操作，因此选择使用 RCU 安全哈希表来实现转换。 哈希表可以具有多对一的映射。 这是为了支持未来多个 IB 驱动程序（即 iWarp 和 RoCE）连接到相同网络设备的情况。 driver_ids 需要不同才能支持这一点。 在此过程中，这通过推迟其 kfree 使 struct ib_device 和 ib_port_data RCU 变得安全
                        hash_add_rcu(ndev_hash, &pdata->ndev_hash_link,(uintptr_t)pdata->netdev); -> add an object to a rcu enabled hashtable
                rxe_icrc_init
                    tfm = crypto_alloc_shash("crc32", 0, 0)
                ib_register_device -> 注册IB设备
                

rxe设备操作表
static const struct ib_device_ops rxe_dev_ops = {
	.owner = THIS_MODULE,
	.driver_id = RDMA_DRIVER_RXE,
	.uverbs_abi_ver = RXE_UVERBS_ABI_VERSION,

	.alloc_hw_port_stats = rxe_ib_alloc_hw_port_stats,
	.alloc_mr = rxe_alloc_mr,
	.alloc_mw = rxe_alloc_mw,
	.alloc_pd = rxe_alloc_pd,
	.alloc_ucontext = rxe_alloc_ucontext,
	.attach_mcast = rxe_attach_mcast,
	.create_ah = rxe_create_ah,
	.create_cq = rxe_create_cq,
	.create_qp = rxe_create_qp,
	.create_srq = rxe_create_srq,
	.create_user_ah = rxe_create_ah,
	.dealloc_driver = rxe_dealloc,
	.dealloc_mw = rxe_dealloc_mw,
	.dealloc_pd = rxe_dealloc_pd,
	.dealloc_ucontext = rxe_dealloc_ucontext,
	.dereg_mr = rxe_dereg_mr,
	.destroy_ah = rxe_destroy_ah,
	.destroy_cq = rxe_destroy_cq,
	.destroy_qp = rxe_destroy_qp,
	.destroy_srq = rxe_destroy_srq,
	.detach_mcast = rxe_detach_mcast,
	.device_group = &rxe_attr_group,
	.enable_driver = rxe_enable_driver,
	.get_dma_mr = rxe_get_dma_mr,
	.get_hw_stats = rxe_ib_get_hw_stats,
	.get_link_layer = rxe_get_link_layer,
	.get_port_immutable = rxe_port_immutable,
	.map_mr_sg = rxe_map_mr_sg,
	.mmap = rxe_mmap,
	.modify_ah = rxe_modify_ah,
	.modify_device = rxe_modify_device,
	.modify_port = rxe_modify_port,
	.modify_qp = rxe_modify_qp,
	.modify_srq = rxe_modify_srq,
	.peek_cq = rxe_peek_cq,
	.poll_cq = rxe_poll_cq,
	.post_recv = rxe_post_recv,
	.post_send = rxe_post_send,
	.post_srq_recv = rxe_post_srq_recv,
	.query_ah = rxe_query_ah,
	.query_device = rxe_query_device,
	.query_pkey = rxe_query_pkey,
	.query_port = rxe_query_port,
	.query_qp = rxe_query_qp,
	.query_srq = rxe_query_srq,
	.reg_user_mr = rxe_reg_user_mr,
	.req_notify_cq = rxe_req_notify_cq,
	.rereg_user_mr = rxe_rereg_user_mr,
	.resize_cq = rxe_resize_cq,

	INIT_RDMA_OBJ_SIZE(ib_ah, rxe_ah, ibah),
	INIT_RDMA_OBJ_SIZE(ib_cq, rxe_cq, ibcq),
	INIT_RDMA_OBJ_SIZE(ib_pd, rxe_pd, ibpd),
	INIT_RDMA_OBJ_SIZE(ib_qp, rxe_qp, ibqp),
	INIT_RDMA_OBJ_SIZE(ib_srq, rxe_srq, ibsrq),
	INIT_RDMA_OBJ_SIZE(ib_ucontext, rxe_ucontext, ibuc),
	INIT_RDMA_OBJ_SIZE(ib_mw, rxe_mw, ibmw),
};


check_resource
    get_srq_wqe
        queue_advance_consumer -> RDMA/rxe：向内核队列添加内存屏障，早期补丁添加内存屏障以保护用户空间到内核空间的通信。 先前显示用户空间队列偶尔会出现内存同步错误，这些错误通过添加 smp_load_acquire、smp_store_release 屏障来消除。 该补丁将其扩展到内核空间线程之间使用队列的情况。 此补丁还扩展了队列类型以包括内核 ULP 队列，这些队列在内核动词调用（如 poll_cq 和 post_send/recv）中访问队列的另一端
            switch (type)
            case QUEUE_TYPE_FROM_CLIENT
            ...



[RDMA_NLDEV_CMD_NEWLINK] = {
    .doit = nldev_newlink,
    .flags = RDMA_NL_ADMIN_PERM,
},
static int nldev_newlink
    nlmsg_parse_deprecated
    ops = link_ops_get(type)
    ops->newlink(ibdev_name, ndev)


ib端口状态及位宽等:
enum ib_port_state {
	IB_PORT_NOP		= 0,
	IB_PORT_DOWN		= 1,
	IB_PORT_INIT		= 2,
	IB_PORT_ARMED		= 3,
	IB_PORT_ACTIVE		= 4,
	IB_PORT_ACTIVE_DEFER	= 5
};

enum ib_port_phys_state {
	IB_PORT_PHYS_STATE_SLEEP = 1,
	IB_PORT_PHYS_STATE_POLLING = 2,
	IB_PORT_PHYS_STATE_DISABLED = 3,
	IB_PORT_PHYS_STATE_PORT_CONFIGURATION_TRAINING = 4,
	IB_PORT_PHYS_STATE_LINK_UP = 5,
	IB_PORT_PHYS_STATE_LINK_ERROR_RECOVERY = 6,
	IB_PORT_PHYS_STATE_PHY_TEST = 7,
};




rxe ib_alloc_mr -> static struct ib_mr *rxe_alloc_mr(struct ib_pd *ibpd, enum ib_mr_type mr_type,
rxe_add_to_pool(&rxe->mr_pool, mr) -> RDMA/rxe：删除rxe_alloc()，目前rxe驱动程序中除MR之外的所有对象类型都在rdma-core中分配。 通过将 kzalloc() 调用移到池代码之外，可以消除 rxe_alloc() 子例程，并且可以删除作为特殊情况的 MR 代码检查。 此补丁将 kzalloc() 和 kfree_rcu() 调用移至 mr 注册和销毁动词中。 它从 rxe_pool.c 中删除了该代码，包括不再使用的 rxe_alloc() 子例程 -> RDMA/rxe：停止查找部分构建的对象，目前 rdma_rxe 驱动程序存在安全漏洞，因为提供了部分初始化索引的对象，允许外部参与者通过发送引用其索引的数据包来访问它们（例如 qpn、rkey、 等）导致不可预测的结果。 此补丁添加了一个新的 API rxe_finalize(obj)，它允许使用 rxe_pool_get_index() 从 AH、QP、MR 和 MW 的索引中查找池对象。 仅在对象完全初始化后，它们才会添加到 create 动词中。 它还添加了等待销毁/释放动词完成的操作，以确保在返回 rdma_core 之前已删除所有引用，方法是实现新的 rxe_pool API rxe_cleanup()，该 API 将删除对对象的引用，然后等待删除所有其他引用。 当最后一个引用被删除时，该对象由 kref 完成。 之后，它会清理对象，如果是本地分配的，则会释放内存。 在地址句柄对象的特殊情况下，如果 destroy_ah 调用不可休眠，则延迟将单独实现。 与延迟清理代码相结合以键入特定的清理例程，这允许引用对象的所有挂起活动在返回 rdma_core 之前完成
    init_completion(&elem->complete)
    xa_alloc_cyclic
rxe_get(pd)
rxe_mr_init_fast(max_num_sg, mr)
    rxe_mr_init
        u32 key = mr->elem.index << 8 | rxe_get_next_key(-1) -> get_random_bytes
        mr->state = RXE_MR_STATE_INVALID
    rxe_mr_alloc
        XA_STATE(xas, &mr->page_list, 0
        xa_init(&mr->page_list)
        do
            xas_lock(&xas)
            xas_store(&xas, XA_ZERO_ENTRY)
            xas_next(&xas)
        while (xas_nomem(&xas, GFP_KERNEL))
    mr->state = RXE_MR_STATE_FREE
    mr->ibmr.type = IB_MR_TYPE_MEM_REG
rxe_finalize(mr)
    xa_store(&elem->pool->xa, elem->index, elem, GFP_KERNEL)



memory type:
IB/core：添加任意 sg_list 支持，能够注册具有间隙的 SG 列表的设备现在可以使用新的设备功能 IB_DEVICE_SG_GAPS_REG 将其在核心中公开给 ULP（在设备属性中的新字段 device_cap_flags_ex 中，因为我们用完了位） )，以及一个新的 mr_type IB_MR_TYPE_SG_GAPS_REG，它分配一个能够处理带间隙的 SG 列表的内存区域。
/**
 * enum ib_mr_type - memory region type
 * @IB_MR_TYPE_MEM_REG:       memory region that is used for
 *                            normal registration
 * @IB_MR_TYPE_SG_GAPS:       memory region that is capable to
 *                            register any arbitrary sg lists (without
 *                            the normal mr constraints - see
 *                            ib_map_mr_sg)
 * @IB_MR_TYPE_DM:            memory region that is used for device
 *                            memory registration
 * @IB_MR_TYPE_USER:          memory region that is used for the user-space
 *                            application
 * @IB_MR_TYPE_DMA:           memory region that is used for DMA operations
 *                            without address translations (VA=PA)
 * @IB_MR_TYPE_INTEGRITY:     memory region that is used for
 *                            data integrity operations
 */
enum ib_mr_type {
	IB_MR_TYPE_MEM_REG,
	IB_MR_TYPE_SG_GAPS,
	IB_MR_TYPE_DM,
	IB_MR_TYPE_USER,
	IB_MR_TYPE_DMA,
	IB_MR_TYPE_INTEGRITY,
};



.reg_user_mr = rxe_reg_user_mr,
mr = kzalloc(sizeof(*mr), GFP_KERNEL)
rxe_add_to_pool(&rxe->mr_pool, mr)
rxe_mr_init_user(rxe, start, length, iova, access, mr)
    rxe_mr_init
    xa_init
    umem = ib_umem_get(&rxe->ib_dev, start, length, access)
    rxe_mr_fill_pages_from_sgt(mr, &umem->sgt_append.sgt)
        XA_STATE(xas, &mr->page_list, 0)
        __sg_page_iter_start -> lib/scatterlist：添加简单页面迭代器，添加一个迭代器以从特定页面偏移量开始一次遍历分散列表一页。 与映射迭代器相反，它很小，即使在简单的循环中也能表现良好，例如将分散列表上的所有页面收集到数组中或根据页面的 DMA 地址设置 iommu 表。
        sg_page_iter_page -> lib/scatterlist: sg_page_iter: 支持不带支持页面的 sg 列表，i915 驱动程序使用 sg 列表作为内存，而不支持“struct page”页面，与其他 IO 内存区域类似，仅设置这些内存区域的 DMA 地址。 它这样做是为了能够以统一的方式对带有和不带有后备页的 sg 列表的 HW MMU 表进行编程。 如果没有有效的页面指针，我们无法调用 nth_page 来获取 __sg_page_iter_next 中的当前页面，因此添加一个相关用户可以单独调用的帮助程序。 还添加一个助手来获取当前页面的 DMA 地址（来自 Daniel 的想法）。 转换 i915 中的所有位置，以使用新的 API
        is_pmem_page
            unsigned long paddr = page_to_phys(pg) -> physical
            region_intersects -> Region_intersects() - 确定区域与已知资源的交集， @start：区域起始地址 @size：区域大小 @flags：资源标志（在 iomem_resource 中） @desc：资源描述符（在 iomem_resource 中）或 IORES_DESC_NONE 检查是否指定 区域部分重叠或完全遮蔽由 @flags 和 @desc 标识的资源（IORES_DESC_NONE 可选）。 如果该区域不与 @flags/@desc 重叠，则返回 REGION_DISJOINT；如果该区域与 @flags/@desc 和其他资源重叠，则返回 REGION_MIXED；如果该区域与 @flags/@desc 重叠并且没有其他定义的资源，则返回 REGION_INTERSECTS。 请注意，当指定区域与 RAM 和未定义的内存孔重叠时，也会返回 REGION_INTERSECTS。 内存重新映射函数使用region_intersect()来确保用户不会重新映射RAM，并且比逐页遍历资源表的速度要快得多
    mr->ibmr.type = IB_MR_TYPE_USER
rxe_finalize(mr)


auto load modules, like: ib_code.ko
[NETLINK]：为内核 netlink 套接字添加正确的模块引用计数。 - 删除将 netlink 编译为模块的虚假代码 - 为实现 netlink 协议的模块添加模块引用计数支持 - 添加对实现 netlink 协议的自动加载模块的支持，只要有人打开该协议的套接字
MODULE_ALIAS_NET_PF_PROTO(PF_NETLINK, NETLINK_RDMA);
NETLINK_RDMA -> https://github.com/ssbandjl/linux/commit/4fdb3bb723db469717c6d38fda667d8b0fa86ebd
#define MODULE_ALIAS_NET_PF_PROTO(pf, proto) \
	MODULE_ALIAS("net-pf-" __stringify(pf) "-proto-" __stringify(proto))


drivers/infiniband/core/device.c
fs_initcall(ib_core_init); -> RDMA/core：将 sysfs 条目视图限制为 init_net，这是一个准备补丁，用于在网络命名空间中提供 rdma 设备的隔离。 第一步，使 rdma 设备仅在 init net 命名空间中可见。 后续补丁将使用 compat ib_core_device 设备/sysfs 树在多个网络命名空间中启用 rdma 设备可见性。 由于IB子系统依赖于net stack，因此需要在netdev之后初始化，并且由于它支持设备，因此需要在设备子系统之前初始化； 因此，将 initcall 顺序更改为 fs_initcall，以便在内核映像中编译 ib_core 时遵循正确的 init 顺序
static int __init ib_core_init(void)
    ib_wq = alloc_workqueue("infiniband", 0, 0)
    ib_comp_unbound_wq -> IB/core：向新的 CQ API 添加未绑定的 WQ 类型，下面引用的上游内核提交将新的 CQ API 中的工作队列修改为绑定到特定的 CPU（而不是未绑定）。 这导致新 CQ API 的所有用户都使用相同的绑定 WQ。 具体来说，当绑定到 WQ 的 CPU 忙于处理（更高优先级）中断时，MAD 处理会严重延迟。 这导致 MAD“心跳”响应处理延迟，从而导致端口被错误地分类为“关闭”。 要解决此问题，请向新的 CQ API 添加新的“未绑定”WQ 类型，以便用户可以选择绑定 WQ 或未绑定 WQ。 对于 MAD，选择新的“未绑定”WQ
    class_register(&ib_class) -> int class_register(const struct class *cls)
        pr_debug("device class '%s': registering\n", cls->name)
        error = sysfs_create_groups(&cp->subsys.kobj, cls->class_groups)
    rdma_nl_init -> IB/core：在 netlink 消息处理期间避免死锁，当未加载 rdmacm 模块时，以及当接收 netlink 消息以获取 char 设备信息时，由于使用以下调用序列对 rdma_nl_mutex 进行递归锁定，因此会导致死锁。 [..] rdma_nl_rcv() mutex_lock() [..] rdma_nl_rcv_msg() ib_get_client_nl_info() request_module() iw_cm_init() rdma_nl_register() mutex_lock(); <- 死锁，再次获取互斥体 由于上述调用序列，观察到以下调用跟踪和死锁。 内核：__mutex_lock+0x35e/0x860 内核：？ __mutex_lock+0x129/0x860 内核：？ rdma_nl_register+0x1a/0x90 [ib_core] 内核： rdma_nl_register+0x1a/0x90 [ib_core] 内核：？ 0xffffffffc029b000 内核：iw_cm_init+0x34/0x1000 [iw_cm] 内核：do_one_initcall+0x67/0x2d4 内核：？ kmem_cache_alloc_trace+0x1ec/0x2a0 内核：do_init_module+0x5a/0x223 内核：load_module+0x1998/0x1e10 内核：？ __symbol_put+0x60/0x60 内核：__do_sys_finit_module+0x94/0xe0 内核：do_syscall_64+0x5a/0x270 内核：entry_SYSCALL_64_after_hwframe+0x49/0xbe 进程堆栈跟踪：[<0>] __request_module+0x1c9/0x460 [<0>] ib_get_client_nl _信息+0x5e/0xb0 [ib_core] [<0>] nldev_get_chardev+0x1ac/0x320 [ib_core] [<0>] rdma_nl_rcv_msg+0xeb/0x1d0 [ib_core] [<0>] rdma_nl_rcv+0xcd/0x120 [ib_core] [<0>] netlink_unicast+0x179 /0x220 [<0>] netlink_sendmsg+0x2f6/0x3f0 [<0>] sock_sendmsg+0x30/0x40 [<0>] ___sys_sendmsg+0x27a/0x290 [<0>] __sys_sendmsg+0x58/0xa0 [<0>] do_syscall_64+0x5a /0x270 [<0>]entry_SYSCALL_64_after_hwframe+0x49/0xbe 为了克服此死锁并允许多个 netlink 消息并行处理，实施了以下方案。 1. 将保护cb_table 的锁拆分为per-index 锁，并使其成为rwlock。 此锁用于确保取消注册返回后不会运行任何回调。 由于模块一旦已经运行回调就不会被注册，这避免了死锁。 2. 注册时使用smp_store_release()更新cb_table，这样就不需要锁了。 这避免了认为所有 rwsem 都是相同锁类的 lockdep 问题
        init_rwsem(&rdma_nl_types[idx].sem)
    addr_init -> IB/core：将IB地址解析模块集成到核心中，IB地址解析被声明为一个模块（ib_addr.ko），该模块在IB核心模块（ib_core.ko）之前加载自身。 这会导致由IB core初始化的IB netlink无法被ib_addr.ko使用的情况。 为了解决这个问题，我们将 ib_addr.ko 转换为 IB 核心模块的一部分
        alloc_ordered_workqueue("ib_addr", 0)
        register_netevent_notifier(&nb) -> netevent_callback
            NETEVENT_NEIGH_UPDATE
            set_timeout(req, jiffies)
    ib_mad_init
        INIT_LIST_HEAD(&ib_mad_port_list) <- ib_mad_port_open
            list_add_tail(&port_priv->port_list, &ib_mad_port_list)
        ib_register_client(&mad_client)
    ib_sa_init -> 中间核心层:Mid-layer Core , 核心服务包括管理接口（MAD）、连接管理器（CM）接口和子网管理员（SA）接口。 该堆栈包括用于用户模式和内核应用程序的组件。 核心服务在内核中运行，并为动词、CM 和管理向用户模式公开接口 -> 第 5 章 配置 INFINIBAND 子网管理器, 所有 InfiniBand 网络都必须运行子网管理器才能正常工作。即使两台机器没有使用交换机直接进行连接， 也是如此。 有可能有一个以上的子网管理器。在那种情况下，当主子网管理器出现故障时，另外一个作为从网管理器 的系统会接管。 大多数 InfiniBand 交换机都包含一个嵌入式子网管理器。然而，如果您需要一个更新的子网管理器，或者 您需要更多控制，请使用 Red Hat Enterprise Linux 提供的 OpenSM 子网管理器
        get_random_bytes(&tid, sizeof tid)
        ib_register_client(&sa_client)
        mcast_init -> IB/sa：跟踪多播加入/离开请求，IB SA 以每个端口为基础跟踪多播加入/离开请求，并且不执行任何引用计数：如果同一端口的两个用户加入同一组，并且其中一个用户离开该组 ，那么 SA 将从组中删除该端口，即使有一个用户想要保留成员身份。 因此，为了支持来自同一端口的同一组播组的多个用户，我们需要在本地执行引用计数。 为此，向 ib_sa 添加一个多播子模块以执行多播加入/离开操作的引用计数。 修改ib_ipoib（多播的唯一内核用户）以使用新接口
            ib_sa_register_client(&sa_client)
            ib_register_client(&mcast_client) -> mcast_add_one -> InfiniBand 子网管理 (SA) 服务是由子网管理器 (SM) 提供的预定义通用服务代理 (GSA)。 在 InfiniBand 结构上，设备应通过联系 SA 查询正确的路由来解析到其他主机的路由
                rdma_cap_ib_mcast -> rdma_cap_ib_mcast - 检查设备端口是否具有 Infiniband、组播功能。 @device：要检查的设备 @port_num：要检查的端口号 * InfiniBand 多播注册比普通 IPv4 或 IPv6 多播注册更复杂。 当每个主机通道适配器希望加入多播组时，必须向子网管理器注册。 无论它订阅该组有多少队列对，它都应该只执行一次。 只有在附加到该组的所有队列对都已分离后，它才应该离开该组。 * 返回：如果端口必须承担向 SM 注册/取消注册以及跟踪附加到多播组的队列对总数的额外管理开销，则返回 true
                ib_set_client_data(device, &mcast_client, dev)
                INIT_IB_EVENT_HANDLER(&dev->event_handler, device, mcast_event_handler)
                    switch (event->event)
                    mcast_groups_event
                        rb_first
                        rb_next
                        rb_entry
                ib_register_event_handler(&dev->event_handler)
        alloc_ordered_workqueue("ib_nl_sa_wq", WQ_MEM_RECLAIM)
        INIT_DELAYED_WORK(&ib_nl_timed_work, ib_nl_request_timeout) -> ib_nl_request_timeout
            queue_delayed_work(ib_nl_wq, &ib_nl_timed_work, delay)
            ib_sa_disable_local_svc
            send_handler -> callback
    register_blocking_lsm_notifier(&ibdev_lsm_nb) -> LSM：切换到阻止策略更新通知程序，原子策略更新程序不是很有用，因为它们通常无法自行执行策略更新。 由于似乎对原子性没有严格的要求，因此切换到阻塞变体。 执行此操作时，相应地重命名函数
        blocking_notifier_chain_register
    register_pernet_device(&rdma_dev_net_ops)
    nldev_init()
    rdma_nl_register(RDMA_NL_LS, ibnl_ls_cb_table) -> rdma_nl_register(RDMA_NL_NLDEV, nldev_cb_table)
        down_write(&rdma_nl_types[index].sem)
        rdma_nl_types[index].cb_table = NULL
    roce_gid_mgmt_init -> IB/核心：添加 RoCE GID 表管理，RoCE GID 基于与 RDMA (RoCE) 设备端口相关的以太网网络设备上配置的 IP 地址。 目前，每个支持 RoCE（ocrdma、mlx4）的低级驱动程序都管理自己的 RoCE 端口 GID 表。 由于本质上没有任何特定于供应商的内容，因此我们对其进行概括，并增强 RDMA 核心 GID 缓存来完成这项工作。 为了填充 GID 表，我们监听事件： (a) netdev up/down/change_addr 事件 - 如果 netdev 构建在我们的 RoCE 设备上，我们需要添加/删除其 IP。 这涉及添加与此 ndev 相关的所有 GID、添加默认 GID 等。 (b) inet 事件 - 将新 GID（根据 IP 地址）添加到表中。 为了对端口 RoCE GID 表进行编程，提供商必须实现 add_gid 和 del_gid 回调。 RoCE GID 管理要求我们在 GID 旁边声明关联的 net_device。 为了管理 GID 表，此信息是必需的。 例如，当删除 net_device 时，其关联的 GID 也需要删除。 RoCE 要求根据相关网络设备的 IPv6 本地链路为每个端口生成默认 GID。 与基于常规 IPv6 链路本地的 GID（因为我们为每个 IP 地址生成 GID）相反，当网络设备关闭时，默认 GID 也可用（为了支持环回）。 锁定的完成方式如下：该补丁修改了 GID 表代码，适用于实现 add_gid/del_gid 回调的新 RoCE 驱动程序以及未实现 add_gid/del_gid 回调的当前 RoCE 和 IB 驱动程序。 更新表的流程不同，因此锁定要求也不同。 更新 RoCE GID 表时，通过 mutex_lock(&table->lock) 实现针对多个写入者的保护。 由于写入表需要我们在表中查找一个条目（可能是空闲条目）然后修改它，因此该互斥锁保护 find_gid 和 write_gid 确保操作的原子性。 GID 缓存中的每个条目均受 rwlock 保护。 在 RoCE 中，写入（通常来自 netdev 通知程序的结果）涉及调用供应商的 add_gid 和 del_gid 回调，这些回调可能会休眠。 因此，为每个条目添加无效标志。 RoCE 的更新是通过工作队列完成的，因此允许休眠。 在IB中，更新是在write_lock_irq(&device->cache.lock)中完成的，因此write_gid不允许休眠并且add_gid/del_gid不会被调用。 当将网络设备传入/传出 GID 缓存时，该设备始终被传递为保持 (dev_hold)。 该代码使用单个工作项来更新所有 RDMA 设备，遵循 netdev 或 inet 通知程序。 该补丁将缓存从客户端（这是不正确的，因为缓存是 IB 基础设施的一部分）转变为在设备注册/删除时显式初始化/释放, commit: https://github.com/ssbandjl/linux/commit/03db3a2d81e6e84f3ed3cb9e087cae17d762642b, drivers/infiniband/core/cache.c
        gid_cache_wq = alloc_ordered_workqueue("gid-cache-wq", 0) -> 串行
        register_inetaddr_notifier(&nb_inetaddr) -> 注册网络地址事件 -> blocking_notifier_chain_register -> 将通知程序添加到阻塞通知程序链 @nh：指向阻塞通知程序链头部的指针 @n：通知程序链中的新条目 将通知程序添加到阻塞通知程序链。 必须在进程上下文中调用。 成功时返回 0，错误时返回 %-EEXIST
            notifier_chain_register(&nh->head, n, unique_priority)
                trace_notifier_register((void *)n->notifier_call)
        register_inet6addr_notifier(&nb_inet6addr)
        register_netdevice_notifier(&nb_netdevice) -> 我们依靠 netdevice 通知程序来枚举系统中所有现有的设备。 最后注册到此通知程序以确保我们不会错过任何 IP 添加/删除回调


IPv4网络事件
static struct notifier_block nb_inetaddr = {
	.notifier_call = inetaddr_event
};
static struct notifier_block nb_inet6addr = {
	.notifier_call = inet6addr_event
};

IPv6网络事件
inetaddr_event
    addr_event(struct notifier_block *this, unsigned long event, struct sockaddr *sa, struct net_device *ndev)
        case NETDEV_UP:
            gid_op = GID_ADD
        case NETDEV_DOWN:
            gid_op = GID_DEL
        INIT_WORK(&work->work, update_gid_event_work_handler)
        rdma_ip2gid(sa, &work->gid)
        queue_work(gid_cache_wq, &work->work) -> 端口UP/Down时触发事件并更新GID
update_gid_event_work_handler
    ib_enum_all_roce_netdevs(is_eth_port_of_netdev_filter, work->gid_attr.ndev, callback_for_addr_gid_device_scan, work) -> callback_for_addr_gid_device_scan
        update_gid(parsed->gid_op, device, port, &parsed->gid, &parsed->gid_attr)





notifier_call_chain - 通知已注册的通知程序有关事件的信息。 @nl：指向阻塞通知器链头的指针 @val：未修改地传递给通知器函数的值 @v：未修改地传递给通知器函数的指针 @nr_to_call：要调用的通知器函数的数量。 不在乎这个参数的值为-1。 @nr_calls：记录发送的通知数量。 不关心该字段的值为 NULL。 返回：notifier_call_chain 返回最后一个调用的通知函数的返回值。 */
    ret = nb->notifier_call(nb, val, v)


static struct class ib_class = {
	.name    = "infiniband",
	.dev_release = ib_device_release,
	.dev_uevent = ib_device_uevent,
	.ns_type = &net_ns_type_operations,
	.namespace = net_namespace,
};



static struct notifier_block nb = {
	.notifier_call = netevent_callback
};


static struct ib_client mad_client = {
	.name   = "mad",
	.add = ib_mad_init_device,
	.remove = ib_mad_remove_device
};


ib_mad_init_device
    rdma_start_port
    ib_mad_port_open
    ib_agent_port_open



static struct ib_client sa_client = {
	.name   = "sa",
	.add    = ib_sa_add_one,
	.remove = ib_sa_remove_one
};

ib_sa_add_one -> RDMA：允许 ib_client 在调用 add() 时失败，添加客户端时不允许失败，但所有客户端在其添加例程中都有各种失败路径。 这会产生一种非常边缘的情况：添加客户端后，在添加过程中失败并且未设置 client_data。 然后，核心代码仍然会使用 NULL client_data 调用其他以 client_data 为中心的操作，例如 remove()、rename()、get_nl_info() 和 get_net_dev_by_params() - 这是令人困惑和意外的。 如果 add() 回调失败，则不要再为设备调用任何客户端操作，甚至删除。 删除操作回调中现在对 NULL client_data 的所有冗余检查。 更新所有 add() 回调以正确返回错误代码。 EOPNOTSUPP 用于 ULP 不支持 ib_device 的情况 - 例如，因为它仅适用于 IB
    ib_register_mad_agent(device, i + s, IB_QPT_GSI, send_handler recv_handler
        get_spl_qp_index
        INIT_DELAYED_WORK(&mad_agent_priv->timed_work, timeout_sends)
        INIT_WORK(&mad_agent_priv->local_work, local_completions);
        ib_mad_agent_security_setup
            security_ib_alloc_security
            security_ib_endport_manage_subnet
                security_ib_endport_sid
                avc_has_perm
            list_add(&agent->mad_agent_sec_list, &mad_agent_list)
    INIT_WORK(&sa_dev->port[i].update_task, update_sm_ah);
    INIT_DELAYED_WORK(&sa_dev->port[i].ib_cpi_work, update_ib_cpi
    ib_set_client_data
    INIT_IB_EVENT_HANDLER(&sa_dev->event_handler, device, ib_sa_event)
    ib_register_event_handler(&sa_dev->event_handler)
    update_sm_ah



send_handler
    query->callback




static struct notifier_block ibdev_lsm_nb = {
	.notifier_call = ib_security_change,
};



static struct pernet_operations rdma_dev_net_ops = {
	.init = rdma_dev_init_net,
	.exit = rdma_dev_exit_net,
	.id = &rdma_dev_net_id,
	.size = sizeof(struct rdma_dev_net),
};
rdma_dev_init_net
    write_pnet
    rdma_nl_net_init
        rdma_init_coredev
        ib_setup_port_attrs
            rdma_for_each_port
                ib_query_port
                setup_port
                     alloc_port_table_group("gids", &p->groups[0], p->attrs_list,
                     alloc_port_table_group("pkeys",
                     setup_hw_port_stats
                     sysfs_create_groups
                     list_add_tail(&p->kobj.entry, &coredev->port_list)
                setup_gid_attrs -> RDMA/core：简化端口 sysfs 的创建方式，使用与 gid_attrs 现在用于管理端口 sysfs 相同的技术。 将所有内容捆绑到三个分配中，并使用单个 sysfs_create_groups() 一次性构建所有内容。 所有内存始终在 kobj 释放函数中释放，消除了大部分错误展开。 gid_attr 技术和 hw_counters 非常相似，将两者合并在一起，并将 hw_counters 的 sysfs_create_group() 调用与单个 sysfs 组设置相结合
                    alloc_port_table_group("ndevs", show_port_gid_attr_ndev
                    alloc_port_table_group("types", show_port_gid_attr_gid_type
    net_eq
    add_one_compat_dev -> RDMA/core：在net命名空间中实现compat device/sysfs树，实现ib_core的兼容层sysfs条目，以便非init_net net命名空间也可以发现rdma设备。 每个非 init_net 网络命名空间都在其中创建了 ib_core_device。 这样的 ib_core_device sysfs 树类似于 init_net 命名空间中找到的 rdma 设备。 这允许通过 sysfs 条目在多个非 init_net 网络命名空间中发现 rdma 设备，并且对 rdma-core 用户空间很有帮助
        cdev = xa_load(&device->compat_devs, rnet->id)
         xa_reserve(&device->compat_devs, rnet->id, GFP_KERNEL)
        rdma_init_coredev
            device_initialize
        cdev->dev.release = compatdev_release
        ret = dev_set_name(&cdev->dev, "%s", dev_name(&device->dev))
        ret = device_add(&cdev->dev) -> int device_add(struct device *dev) -> 将设备添加到设备层次结构中。 @dev：设备。 这是 device_register() 的第 2 部分，尽管可以单独调用 _iff_ device_initialize() 已被单独调用。 这通过 kobject_add() 将 @dev 添加到 kobject 层次结构中，将其添加到设备的全局列表和同级列表中，然后将其添加到驱动程序模型的其他相关子系统中。 对于任何设备结构，请勿多次调用此例程或 device_register()。 驱动程序模型核心不适用于未注册然后又恢复正常的设备。 （除此之外，很难保证对 @dev 的先前化身的所有引用都已被删除。）而是分配并注册一个全新的结构设备。 注意：_决不_在调用此函数后直接释放@dev，即使它返回错误！ 始终使用 put_device() 来放弃您的引用。 经验法则是：如果 device_add() 成功，当您想要删除它时，应该调用 device_del()。 如果 device_add() *未*成功，则 *仅* 使用 put_device() 删除引用计数
            dev = get_device(dev)
            device_private_init(dev)
            get_device_parent
            kobject_add(&dev->kobj, dev->kobj.parent, NULL)
            device_platform_notify(dev)
            device_create_file(dev, &dev_attr_uevent) -> sysfs_create_file
                kobject_get_ownership
                sysfs_add_file_mode_ns
                    kn = __kernfs_create_file(parent, attr->name, mode & 0777, uid, gid, PAGE_SIZE, ops, (void *)attr, ns, key);
                        kernfs_new_node -> kernfs：允许使用任意 uid/gid 创建 kernfs 对象，此更改允许使用任意 uid/gid 创建 kernfs 文件和目录，而不是通过使用 uid/gid 参数扩展 kernfs_create_dir_ns() 和 kernfs_create_file_ns() 来始终使用 GLOBAL_ROOT_UID/GID。 “简单”的 kernfs_create_file() 和 kernfs_create_dir() 被单独保留，并且始终创建属于全局根的对象。 创建符号链接时，所有权 (uid/gid) 取自目标 kernfs 对象
                            __kernfs_new_node(kernfs_root(parent), parent,
                                name = kstrdup_const(name, GFP_KERNEL)
                                kn = kmem_cache_zalloc(kernfs_node_cache, GFP_KERNEL) -> kmem_cache_zalloc( )函数与kmem_cache_alloc( )函数功能类似，都是用来从一个给定的缓存分配一个对象。但kmem_cache_zalloc( )除了分配内存对象之外，还把内存对象所代表的内存空间初始化为0
                                idr_preload(GFP_KERNEL);
                                idr_alloc_cyclic(&root->ino_idr, kn, 1, 0, GFP_ATOMIC)
                                idr_preload_end()
                                RB_CLEAR_NODE(&kn->rb)
                                __kernfs_setattr -> xattrs->rb_root = RB_ROOT
                                security_kernfs_init_security -> Init LSM context for a kernfs node
                                    call_int_hook(kernfs_init_security, 0, kn_dir, kn) -> LSM_HOOK_INIT(kernfs_init_security, selinux_kernfs_init_security)
                        kernfs_add_one(kn)
            device_add_class_symlinks
            device_add_attrs
            bus_add_device
            dpm_sysfs_add
            device_pm_add
            bus_notify(dev, BUS_NOTIFY_ADD_DEVICE)
            bus_probe_device(dev)
            class_to_subsys
        ib_setup_port_attrs
        xa_store(&device->compat_devs, rnet->id, -> store device -> static DEFINE_XARRAY_FLAGS(devices, XA_FLAGS_ALLOC);




nldev_get_doit
    nlmsg_parse_deprecated
    nla_get_u32
    ib_device_get_by_index -> RDMA/core：扩展 ib_device_get_by_index 以获取网络命名空间，扩展 ib_device_get_by_index() API 以检查设备对网络命名空间的访问，以提供 netlink 命令。 还对 dumpit 命令强制执行 net ns 检查，这些命令迭代所有注册的 rdma 设备并且不调用 ib_device_get_by_index()
        device = xa_load(&devices, index) -> 三个 rwsem 锁（devices、clients、client_data）中的每一个都保护同名的 xarray。 具体来说，它允许调用者断言 MARK 在锁定下将/不会改变，并且对于设备和客户端而言，xarray 中的值仍然是有效的指针。 MARK 的更改与对象状态相关联，因此持有锁并测试 MARK 也断言所包含的对象处于某种状态。 这用于构建两阶段注册/取消注册流程，其中对象可以继续位于 xarray 中，即使它们仍在注册/取消注册过程中。 xarray本身提供了额外的锁定，以及可重启的迭代，这也是值得依赖的。 锁不应该嵌套，但 client_data 除外，它允许嵌套在其他两个锁的读取端下方。 devices_rwsem 还保护设备名称列表，设备名称的任何更改或分配也必须保留写入端以保证名称唯一。 */ devices 包含已分配名称的设备。 设备可能未注册。 关心注册状态的用户需要在设备上调用 ib_device_try_get() 以确保其已注册，并在所需的时间内保持注册状态 -> this devices from register, static DEFINE_XARRAY_FLAGS(devices, XA_FLAGS_ALLOC)
        rdma_dev_access_netns
            net_eq(read_pnet(&dev->coredev.rdma_net), net)
        ib_device_try_get -> RDMA/device：公开 ib_device_try_get(()，事实证明，未来的补丁现在非常广泛地需要此功能，而不仅仅是 netlink，因此提供两个全局函数来管理注册锁引用计数。这也将锁变为 1 的点移至以内 ib_register_device() 使得公共 API 的语义非常健全和清晰，在仅分配但尚未注册的设备上调用 ib_device_try_get() 将失败。 -> ib_device_try_get：持有注册锁，设备：要锁定的设备处于活动注册锁下的设备无法取消注册。 只有在完全注册的设备上才能获得注册锁，否则该函数返回 false。 仅当需要设备仍处于注册状态时才需要注册锁。 仅要求设备指针有效的用途应使用 get_device(&ibdev->dev) 来保存内存
            refcount_inc_not_zero(&dev->refcount)
    nlmsg_new
    rdma_nl_unicast(sock_net(skb->sk), msg, NETLINK_CB(skb).portid)


fs_initcall(ib_core_init);
register_pernet_device(&rdma_dev_net_ops)
static struct pernet_operations rdma_dev_net_ops = {
    .init = rdma_dev_init_net,
    .exit = rdma_dev_exit_net,
    .id = &rdma_dev_net_id,
    .size = sizeof(struct rdma_dev_net),
};
rdma_dev_init_net
    ...
    rdma_nl_net_init
        read_pnet
        .input	= rdma_nl_rcv
        netlink_kernel_create(net, NETLINK_RDMA, &cfg)


static const struct rdma_nl_cbs nldev_cb_table[RDMA_NLDEV_NUM_OPS] = {
    [RDMA_NLDEV_CMD_GET] = {
        .doit = nldev_get_doit,
        .dump = nldev_get_dumpit,
    },
如果用户提供特定索引，我们可以使用 .doit 回调加速查询，并在之后保存完整转储和过滤
nldev_get_dumpit _nldev_get_dumpit
    rdma_dev_access_netns
    _nldev_get_dumpit
        nlmsg_end




qemu_vm:
/root/project/rdma/iproute2/rdma
gdb --args ./rdma link add rxe_ens3 type rxe netdev ens3
main
filename = basename(argv[0]);
err = rd_init(&rd, filename);
    rd_prepare_msg
err = rd_batch(&rd, batch_file, force)
rd_cmd(&rd, argc, argv)
    rd_exec_cmd
        rd_argv_match
        c->func(rd) -> int cmd_link
            rd_exec_cmd -> link_add
link_add -> link_add_type -> link_add_netdev
    rd_prepare_msg(rd, RDMA_NLDEV_CMD_NEWLINK, &seq, -> to kernel 通过Netlink转到内核态
    mnl_attr_put_strz(rd->nlh, RDMA_NLDEV_ATTR_DEV_NAME, rd->link_name);
    ...


kernel: RDMA_NLDEV_CMD_NEWLINK
static const struct rdma_nl_cbs nldev_cb_table[RDMA_NLDEV_NUM_OPS] = {
	[RDMA_NLDEV_CMD_GET] = {
		.doit = nldev_get_doit,
		.dump = nldev_get_dumpit,
	},
	[RDMA_NLDEV_CMD_GET_CHARDEV] = {
		.doit = nldev_get_chardev,
	},
	[RDMA_NLDEV_CMD_SET] = {
		.doit = nldev_set_doit,
		.flags = RDMA_NL_ADMIN_PERM,
	},
	[RDMA_NLDEV_CMD_NEWLINK] = {
		.doit = nldev_newlink,
		.flags = RDMA_NL_ADMIN_PERM,
	},



#0  nldev_newlink (skb=0xffff88813772c800, nlh=0xffff888036b87000, extack=0xffffc90003aabc18) at drivers/infiniband/core/nldev.c:1670
#1  0xffffffffc0787dc0 in rdma_nl_rcv_msg (extack=0xffffc90003aabc18, nlh=0xffff888036b87000, skb=0xffff88813772c800) at drivers/infiniband/core/netlink.c:195 -> err = cb_table[op].doit(skb, nlh, extack)
#2  rdma_nl_rcv_skb (cb=<optimized out>, skb=0xffff88813772c800) at drivers/infiniband/core/netlink.c:239
#3  rdma_nl_rcv (skb=0xffff88813772c800) at drivers/infiniband/core/netlink.c:259
#4  0xffffffff81aeb4a5 in netlink_unicast_kernel (ssk=0xffff888117765800, skb=0xffff88813772c800, sk=0xffff88811b1cb000) at net/netlink/af_netlink.c:1319
#5  netlink_unicast (ssk=ssk@entry=0xffff888117765800, skb=skb@entry=0xffff88813772c800, portid=portid@entry=0, nonblock=<optimized out>) at net/netlink/af_netlink.c:1345
#6  0xffffffff81aeb796 in netlink_sendmsg (sock=<optimized out>, msg=0xffffc90003aabd88, len=<optimized out>) at net/netlink/af_netlink.c:1935
#7  0xffffffff81a3db52 in sock_sendmsg_nosec (msg=0xffff888036b87000, sock=0xffff88813772c800) at ./include/linux/uio.h:255
#8  sock_sendmsg (sock=0xffff88813772c800, sock@entry=0xffff88800473ce00, msg=0xffff888036b87000, msg@entry=0xffffc90003aabd88) at net/socket.c:724
#9  0xffffffff81a3f5c3 in __sys_sendto (fd=<optimized out>, buff=<optimized out>, len=<optimized out>, flags=0, addr=0x7ffff7db39e0, addr_len=12) at net/socket.c:2036
#10 0xffffffff81a3f669 in __do_sys_sendto (addr_len=<optimized out>, addr=<optimized out>, flags=<optimized out>, len=<optimized out>, buff=<optimized out>, fd=<optimized out>) at net/socket.c:2048
#11 __se_sys_sendto (addr_len=<optimized out>, addr=<optimized out>, flags=<optimized out>, len=<optimized out>, buff=<optimized out>, fd=<optimized out>) at net/socket.c:2044
#12 __x64_sys_sendto (regs=<optimized out>) at net/socket.c:2044
#13 0xffffffff81cff979 in do_syscall_x64 (nr=<optimized out>, regs=0xffffc90003aabf58) at arch/x86/entry/common.c:50
#14 do_syscall_64 (regs=0xffffc90003aabf58, nr=<optimized out>) at arch/x86/entry/common.c:80
#15 0xffffffff81e0007c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:113
#16 0x0000000000000001 in fixed_percpu_data ()
#17 0x00007fffffffe000 in ?? () at drivers/infiniband/core/device.c:2857
#18 0x0000000000000000 in ?? ()



rdma_dev_init_net
    rdma_nl_net_init
        .input	= rdma_nl_rcv
        nls = netlink_kernel_create(net, NETLINK_RDMA, &cfg)


nldev_newlink
    nlmsg_parse_deprecated
    dev_get_by_name
    link_ops_get
    CONFIG_MODULES
    request_module("rdma-link-%s", type) <- #define MODULE_ALIAS_RDMA_LINK(type) MODULE_ALIAS("rdma-link-" type) -> MODULE_ALIAS_RDMA_LINK("rxe");
    ops->newlink(ibdev_name, ndev)

static struct rdma_link_ops rxe_link_ops = {
	.type = "rxe",
	.newlink = rxe_newlink,
};
rxe_newlink
    is_vlan_dev -> 判断是否VLAN设备
        return dev->priv_flags & IFF_802_1Q_VLAN
    rxe_get_dev_from_net
        ib_device_get_by_netdev(ndev, RDMA_DRIVER_RXE)
            hash_for_each_possible_rcu (ndev_hash, cur, ndev_hash_link,
            ib_device_try_get(cur->ib_dev))
            res = cur->ib_dev
    rxe_net_add
        ib_alloc_device(rxe_dev, ib_dev)
        rxe_add(rxe, ndev->mtu, ibdev_name)
            rxe_init
            rxe_set_mtu
            rxe_register_device

rxe_post_send
    rxe_run_task
    rxe_post_send_kernel
        post_one_send
            validate_send_wr
                wr_opcode_mask
            queue_full -> RDMA/rxe：向内核队列添加内存屏障，早期补丁添加内存屏障以保护用户空间到内核空间的通信。 先前显示用户空间队列偶尔会出现内存同步错误，这些错误通过添加 smp_load_acquire、smp_store_release 屏障来消除。 该补丁将其扩展到内核空间线程之间使用队列的情况。 此补丁还扩展了队列类型以包括内核 ULP 队列，这些队列在内核动词调用（如 poll_cq 和 post_send/recv）中访问队列的另一端
                u32 prod = queue_get_producer(q, type)
                u32 cons = queue_get_consumer(q, type)
                return ((prod + 1 - cons) & q->index_mask) == 0
            queue_producer_addr
                return q->buf->data + (prod << q->log2_elem_size)
            init_send_wqe -> RDMA/rxe：使用 qp->state_lock 保护 QP 状态，目前 rxe 驱动程序很少努力对 qp 状态（包括 qp->attr.qp_state、qp->attr.sq_draining 和 qp->valid）进行原子更改 不同的客户端线程和IO线程之间。 特别是，RDMA 应用程序的通用模板是调用 ib_modify_qp() 将 qp 移至 ERR 状态，然后等到所有数据包和工作队列都已耗尽，然后再调用 ib_destroy_qp()。 这些状态更改均不受锁保护，以确保更改以原子方式执行并且包含内存屏障。 据观察，这会导致 qp 清理方面的错误行为。 该补丁延续了本系列之前补丁的工作，并添加了围绕 qp 状态更改和查找的锁定代码
                init_send_wr
                copy_inline_data_to_wqe(wqe, ibwr)
                    memcpy(p, ib_virt_dma_to_page(sge->addr), sge->length) -> RDMA：添加 ib_virt_dma_to_page()，通过添加一个从“虚拟”dma_addr 返回到 kva 和另一个返回到结构页的函数，可以更清楚地了解发生的情况。 这用于 ib_uses_virt_dma() 样式驱动程序（siw、rxe、hfi、qib）。 当使用由各种 ib_map 函数编码的 dma_addr 值时，调用它们而不是裸转换和 virt_to_page() 。 这也解决了 Linus Walleij 一直在追求的 virt_to_page() 转换问题
                        return virt_to_page(ib_virt_dma_to_ptr(dma_addr))
                            return (void *)(uintptr_t)dma_addr;
                or memcpy(wqe->dma.sge, ibwr->sg_list,
                wqe->state		= wqe_state_posted
        rxe_sched_task(&qp->req.task) -> rxe_requester
            ...
            if (unlikely(qp->req.need_retry && !qp->req.wait_for_rnr_timer)) -> RDMA/rxe：修复 rnr 重试行为，当前，当重传计时器或 rnr 计时器触发相同标志 (qp->req.need_retry) 时，完成者微线程被设置，以便如果任一计时器触发，它将尝试在 发送队列。 这具有在第一次重传定时器事件时响应 RNR NAK 的效果，这可能不允许请求的 rnr 超时。 此补丁添加了一个新标志 (qp->req.wait_for_rnr_timer)，如果设置该标志，则会阻止重试流程，直到 rnr nak 计时器触发。 此补丁修复了 rnr 重试错误，可以通过多次运行 pyverbs test_rdmacm_async_traffic_external_qp 来观察到这些错误。 应用此补丁后，它们不会发生
                req_retry(qp)
            req_next_wqe
            rxe_wqe_is_fenced(qp, wqe)
                wqe->wr.send_flags & IB_SEND_FENCE
            rxe_do_local_ops or -> RDMA/rxe：将本地操作移至子例程，通过将本地操作移至子例程来简化 rxe_requester()。 添加非法发送 WR 操作码的错误返回。 将 next_index 移至 rxe_run_task 之前，这修复了一个小错误，即工作完成被延迟到下一个 wqe 之后，这不是预期的行为。 让错误返回它们自己的 WC 状态。 以前，所有错误都被报告为保护错误，这是不正确的。 将错误返回从 rxe_do_local_ops() 更改为 err: ，这会导致立即完成。 如果没有这个，最后一个 WR 上的错误可能会丢失。 将 fill_packet() 更改为 finish_packet() 更准确
                switch (opcode)
                case IB_WR_LOCAL_INV
                    rxe_invalidate_mw
                    or rxe_invalidate_mr
                case IB_WR_REG_MR
                    rxe_reg_fast_mr
                case IB_WR_BIND_MW
                    ret = rxe_bind_mw(qp, wqe)
            psn_compare
            next_opcode
                next_opcode_rc
            check_init_depth
            if (payload > mtu)
                queue_next_index
                wqe->status = IB_WC_SUCCESS
                rxe_sched_task(&qp->comp.task)
            save_state(wqe, qp, &rollback_wqe, &rollback_psn) -> RDMA/rxe：修复 rxe_requester 中不完整的状态保存，如果发送数据包被 rxe_requester() 中的 IP 层丢弃，则对 rxe_xmit_packet() 的调用可能会失败，并出现 err == -EAGAIN。 为了恢复，wqe 的状态将恢复到数据包发送之前的状态，以便可以重新发送。 然而，保存和恢复状态的例程错过了 wqe（用于处理 sge 表的 dma 结构）中变量状态的重要部分。 并且，在构建修改 dma 结构的数据包之前不会保存状态。 在快速节点上的许多 QP 向慢速节点发送大消息的重压力测试下，会观察到丢弃的数据包，并且由于 dma 结构未恢复，重新发送的数据包已损坏。 此补丁修复了此行为并允许测试用例成功
                rollback_wqe->state = wqe->state;
                *rollback_psn = qp->req.psn
            rxe_get_av(&pkt, &ah) -> RDMA/rxe：修复 rxe_av.c 中的引用错误，下面引用的提交可以引用永远不会被删除的 AH。 这仅发生在 UD 请求路径中。 该补丁可以选择将该 AH 传递回调用者，以便它可以在访问 AV 时保存引用，然后删除它。 执行此操作的代码已添加到 rxe_req.c 中。 AV 还传递给 rxe_net.c 中的 rxe_prepare 作为优化
                return &pkt->qp->pri_av
                rxe_pool_get_index
                    elem = xa_load(xa, index)
                rxe_ah_pd
            init_req_packet
                int			pad = (-payload) & 0x3
                paylen = rxe_opcode[opcode].length + payload + pad + RXE_ICRC_SIZE
                rxe_init_packet
                    rdma_get_gid_attr -> RDMA：支持超过 255 个 rdma 端口，当前代码在处理 RDMA 设备的端口时使用许多不同的类型：u8、unsigned int 和 u32。 切换到 u32 来清理逻辑。 这使我们（至少）能够使核心视图保持一致并使用相同的类型。 不幸的是，并非所有地方都可以转换。 许多 uverbs 函数期望端口为 u8，因此保留这些位置以免破坏 UAPI。 硬件/规范定义的值也不得更改。 通过切换到 u32，我们现在可以支持具有超过 255 个端口的设备。 U32_MAX 被保留以使控制逻辑更容易处理。 由于具有 U32_MAX 端口的设备可能不会很快发生这种情况，这似乎不是问题。 当创建具有超过 255 个端口的设备时，uverbs 将报告 RDMA 设备具有 255 个端口，因为这是当前支持的最大值。 verbs 接口尚未更改，因为 IBTA 规范在太多地方将端口大小限制为 u8，并且所有依赖 verbs 的应用程序将无法应对此更改。 在此阶段，我们正在扩展仅使用供应商通道的接口。一旦解除限制，switchdev 模式下的 mlx5 将能够拥有设备创建的数千个 SF。 由于报告超过 255 个端口的 RDMA 设备的唯一实例将是代表设备，并且它将自身暴露为仅原始以太网设备 CM/MAD/IPoIB 和其他 ULP 不受此更改的影响，并且它们的 sysfs/接口 暴露给用户空间的内容可以保持不变。 虽然在这里清理了一些对齐问题并删除了不需要的健全性检查（主要在 rdmavt 中
                        rdma_gid_table
                        get_gid_entry
                    rdma_read_gid_attr_ndev_rcu
                    skb = alloc_skb(paylen + hdr_len + LL_RESERVED_SPACE(ndev), -> rdma_rxe：使 rxe 在 802.1q VLAN 设备上工作，此补丁修复了 802.1q VLAN 设备上的 RDMA/rxe。 如果没有它，我会观察到以下行为：a) 通过 rxe_net_add() 将 VLAN 设备添加到 RXE 会创建一个无法正常工作的 RDMA 设备。 这是由 enum_all_gids_of_dev_cb() / is_eth_port_of_netdev() 中的逻辑引起的，该逻辑仅考虑连接到已配置网络设备的“上层设备”的网络，导致本身就是“上层设备”的 VLAN 接口的 gid 集为空 。 稍后尝试通过此 rdma 设备进行连接会在 cma_acuire_dev() 中失败，因为无法解析 gids。 b) 添加 VLAN 设备的主设备似乎最初可以正常工作，通过 VLAN 设备的目标地址已成功解析。 但连接超时，因为以太网数据包中没有插入 802.1q VLAN 标头，因此永远不会收到以太网数据包。 发生这种情况是因为 RXE 层通过主设备而不是 VLAN 设备发送数据包。 该问题可以通过更改 a) 或 b) 来解决。 我的想法是a）中的逻辑是故意创建的，因此我决定在b）上工作。 事实证明，有关当前 gid 的 VLAN 接口的信息在 AV 信息中可用。 我的补丁将 RXE 代码转换为使用此 netdev 而不是 rxe->ndev。 通过此更改，RXE over vlan 可在我的测试系统上运行
                    skb_reserve(skb, hdr_len + LL_RESERVED_SPACE(ndev)) -> RDMA/rxe：根据GID的netdev考虑skb预留空间，始终根据GID属性的netdevice考虑skb预留空间，无论vlan还是非vlan netdevice
                    pkt->hdr	= skb_put(skb, paylen)
                bth_init(pkt, pkt->opcode, solicited, 0, pad, IB_DEFAULT_PKEY_FULL
                    bth->opcode = opcode;
                reth_set_rkey -> RDMA/rxe：在请求方实现RC RDMA FLUSH服务，在请求方实现FLUSH请求操作
                reth_set_va
                reth_set_len -> IB/rxe：修复了 rdma 读取重试问题，当对剩余部分数据重试读取请求时，响应可能会首先从读取响应或仅读取响应重新启动。 所以支持这些案例。 不要将 comp psn 推进到当前 wqe 的 last_psn 之外，因为这可能会跳过整个读取 wqe，并导致 req_retry() 逻辑设置不正确的 req psn。 示例序列如下： 写入 PSN 40——这是当前的 WQE。 读取请求 PSN 41 写入 PSN 42 接收 ACK PSN 42——这将完成 PSN 40 的当前 WQE，并将 comp psn 设置为 42，这是一个问题，因为 PSN 41 处的读取请求已被跳过。 因此，当 req_retry() 尝试重新传输读取请求时，它将 req psn 设置为 42，这是不正确的。 重试读请求时，根据 dma resid 而不是 wqe first_psn 计算完成的 psn 数。 如果多次重试读取请求，则 wqe first_psn 可能已移动。 将reth长度设置为dma resid以处理剩余部分数据的读取重试
                feth_init
                immdt_set_imm
                ieth_set_rkey
                deth_set_qkey
                deth_set_sqp
            finish_packet
                rxe_prepare
                    ether_addr_equal(skb->dev->dev_addr, av->dmac) -> 比较两个以太网地址，如果相等则返回 true
                bth_pad(pkt) -> rxe：正确计算未对齐有效负载的 iCRC，如果发送或接收的 RoCE PDU 包含填充字节，则 iCRC 计算错误，导致 RXE 发出具有不正确 iCRC 的 PDU，以及由于错误检测到入口 PDU 而被丢弃 PDU 中的 iCRC 错误。 解决方法是在 iCRC 计算中包含填充字节（如果有）。 注意：自从软 RoCE 驱动程序首次放入主流内核以来，此错误已导致与实际硬件 RoCE 设备的在线兼容性损坏。 修复它会导致与原始软 RoCE 设备不兼容，但对于与真实硬件设备兼容是必要的, commit: https://github.com/ssbandjl/linux/commit/2030abddec6884aaf5892f5724c48fc340e6826f
                     rxe_crc32(rxe, crc, pad, bth_pad(pkt))
            update_wqe_state(qp, wqe, &pkt) -> IB/rxe：修复请求者和完成者之间的竞争条件，rxe_requester() 使用 rxe_xmit_packet() 发送 pkt，然后调用 rxe_update() 来更新 wqe 和 qp 的 psn 值。 但有时，在请求者有时间更新 wqe 之前就收到了响应，在这种情况下，完成者会对错误的 wqe 值采取行动。 此修复在实际发送请求之前更新 wqe 和 qp，并在 xmit 失败时回滚
            update_wqe_psn(qp, wqe, &pkt, payload)
                int num_pkt = (wqe->dma.resid + payload + qp->mtu - 1) / qp->mtu
                qp->req.psn = (wqe->first_psn + num_pkt) & BTH_PSN_MASK
            rxe_xmit_packet(qp, &pkt, skb)
                rxe_icrc_generate -> compute pkt icrc
                    rxe_icrc_hdr
                    rxe_crc32
                rxe_loopback
                    skb_pull(skb, sizeof(struct iphdr)) -> RDMA/rxe：纠正环回路径上的 skb，rxe_net.c 在 IP 层发送数据包，其中 skb->data 指向 IP 标头，但从 UDP 隧道接收数据包，其中 skb->data 指向 UDP 标头。 在环回路径上，没有正确考虑这一点。 此补丁通过使用 sbk_pull() 从接收到的数据包的 skb 中剥离 IP 标头来纠正此问题 -> 从数据区头部移除数据
                    or skb_pull(skb, sizeof(struct ipv6hdr))
                    skb_pull(skb, sizeof(struct udphdr))
                    rxe_rcv(skb) -> RDMA/rxe：修复 rxe_send 和 rxe_loopback，修复 rxe_net.c 中的 rxe_send() 和 rxe_loopback() 以具有相同的调用序列。 这个补丁使它们静态并具有相同的参数列表和返回值
                        
                or rxe_send
                rxe_sched_task(&qp->comp.task)
                rxe_counter_inc(rxe, RXE_CNT_SENT_PKTS)
            update_state(qp, &pkt)



struct rxe_wr_opcode_info rxe_wr_opcode_info[] = {
	[IB_WR_RDMA_WRITE]				= {
		.name	= "IB_WR_RDMA_WRITE",
		.mask	= {
			[IB_QPT_RC]	= WR_INLINE_MASK | WR_WRITE_MASK,
			[IB_QPT_UC]	= WR_INLINE_MASK | WR_WRITE_MASK,
		},
	},



qp type:
enum ib_qp_type {
	/*
	 * IB_QPT_SMI and IB_QPT_GSI have to be the first two entries
	 * here (and in that order) since the MAD layer uses them as
	 * indices into a 2-entry table.
	 */
	IB_QPT_SMI,
	IB_QPT_GSI,

	IB_QPT_RC = IB_UVERBS_QPT_RC,
	IB_QPT_UC = IB_UVERBS_QPT_UC,
	IB_QPT_UD = IB_UVERBS_QPT_UD,
	IB_QPT_RAW_IPV6,
	IB_QPT_RAW_ETHERTYPE,
	IB_QPT_RAW_PACKET = IB_UVERBS_QPT_RAW_PACKET,
	IB_QPT_XRC_INI = IB_UVERBS_QPT_XRC_INI,
	IB_QPT_XRC_TGT = IB_UVERBS_QPT_XRC_TGT,
	IB_QPT_MAX,
	IB_QPT_DRIVER = IB_UVERBS_QPT_DRIVER,
	/* Reserve a range for qp types internal to the low level driver.
	 * These qp types will not be visible at the IB core layer, so the
	 * IB_QPT_MAX usages should not be affected in the core layer
	 */
	IB_QPT_RESERVED1 = 0x1000,
	IB_QPT_RESERVED2,
	IB_QPT_RESERVED3,
	IB_QPT_RESERVED4,
	IB_QPT_RESERVED5,
	IB_QPT_RESERVED6,
	IB_QPT_RESERVED7,
	IB_QPT_RESERVED8,
	IB_QPT_RESERVED9,
	IB_QPT_RESERVED10,
};


wqe state:
enum wqe_state {
	wqe_state_posted,
	wqe_state_processing,
	wqe_state_pending,
	wqe_state_done,
	wqe_state_error,
};



rxe opcode:
struct rxe_opcode_info rxe_opcode[RXE_NUM_OPCODE] = {
	[IB_OPCODE_RC_SEND_FIRST]			= {
		.name	= "IB_OPCODE_RC_SEND_FIRST",
		.mask	= RXE_PAYLOAD_MASK | RXE_REQ_MASK | RXE_RWR_MASK |
			  RXE_SEND_MASK | RXE_START_MASK,
		.length = RXE_BTH_BYTES,
		.offset = {
			[RXE_BTH]	= 0,
			[RXE_PAYLOAD]	= RXE_BTH_BYTES,
		}
	},
    ...


bth, Base Transport Header -> IBA 标头类型和方法，其中一些仅供参考和完整性，因为 rxe 目前不支持 RD 传输，其中大部分可以移至 IB 核心中。 ib_pack.h 包含其中的一部分，但不完整 用于向标头插入值或从标头中提取值的标头特定例程 名为 __hhh_(set_)fff() 的例程采用指向 hhh 标头的指针并获取（设置） fff 字段。 名为 hhh_(set_)fff 的例程采用数据包信息结构，并根据数据包中的操作码查找标头和字段。 还完成了从 cpu 顺序到网络字节顺序的转换
struct rxe_bth {
	u8			opcode;
	u8			flags;
	__be16			pkey;
	__be32			qpn;
	__be32			apsn;
};


wqe state:
enum wqe_state {
	wqe_state_posted,
	wqe_state_processing,
	wqe_state_pending,
	wqe_state_done,
	wqe_state_error,
};


link script:
arch/x86/kernel/vmlinux.lds.S
do_initcall_level




modprobe rdma_rxe
ls -alh /lib/modules/
drivers/infiniband/sw/rxe/Makefile
obj-$(CONFIG_RDMA_RXE) += rdma_rxe.o


drivers/infiniband/core/Makefile



rdma_nl_rcv_msg
    unsigned int index = RDMA_NL_GET_CLIENT(type)
    get_cb_table




MODULE_AUTHOR("Roland Dreier");
MODULE_DESCRIPTION("InfiniBand userspace verbs access");
MODULE_LICENSE("Dual BSD/GPL");


static const struct class uverbs_class = {
	.name = "infiniband_verbs",
	.devnode = uverbs_devnode,
        kasprintf(GFP_KERNEL, "infiniband/%s", dev_name(dev))
};



static int ib_uverbs_open(struct inode *inode, struct file *filp) -> ib_uverbs_device 结构进行了正确的引用计数，并且其他所有内容都纯粹是正在创建的文件的本地内容，因此与其他打开调用的竞争不是问题； 没有可与之竞争的 ioctl 方法； open 方法将立即运行 -ENXIO，或者将完成所有必需的初始化
    get_device(&dev->dev)
    rdma_dev_access_netns(ib_dev, current->nsproxy->net_ns)
    list_add_tail(&file->list, &dev->uverbs_file_list)
    setup_ufile_idr_uobject(file)
        xa_init_flags(&ufile->idr, XA_FLAGS_ALLOC)
    stream_open -> Stream_open 由需要类流文件描述符的子系统使用。 此类文件描述符不可查找，并且没有位置概念（file.f_pos 始终为 0，传递给 .read()/.write() 的 ppos 始终为 NULL）。 与其他常规文件的文件描述符相反，.read() 和 .write() 可以同时运行。 Stream_open 永远不会失败，并被标记为返回 int，以便它可以直接用作 file_operations.open -> fs：stream_open - 类似流文件的打开器，以便读取和写入……可以同时运行而不会出现死锁 Commit 9c225f2（“vfs：按照 POSIX 的原子 f_pos 访问”）为 file.f_pos 访问添加了锁定，特别是并发读取和写入 write 不可能 - 现在这两个函数在整个运行过程中都采用 f_pos 锁定，因此如果例如 读取被阻塞等待数据，写入将死锁等待读取完成。 这导致了类似流的文件的回归，以前的读取和写入可以同时运行，但在该补丁之后就不能再这样做了。 参见例如 提交 581d21a（“xenbus：修复写入 /proc/xen/xenbus 时的死锁”），它修复了 /proc/xen/xenbus 特定情况下的这种回归。 2014 年添加 f_pos 锁的补丁是为了保证读/写/lseek 的 POSIX 线程安全，并将锁定添加到所有常规文件的文件描述符。 在 2014 年，线程安全问题并不是什么新鲜事，因为它已经在 2006 年早些时候讨论过。然而，即使 Linus 补丁的 2006 版本添加了 f_pos 锁定，“仅适用于用 FMODE_LSEEK 标记为可查找的文件（从而避免了类似流的情况） 管道和套接字等对象）”，2014 年版本 - 实际上将其作为 9c225f2 放入树中 - 无论文件是否可查找，都会这样做。 请参阅 https://lore.kernel.org/lkml/53022DB1.4070805@gmail.com/ https://lwn.net/Articles/180387 https://lwn.net/Articles/180396 了解历史背景。 这样做的原因可能是有许多文件被标记为不可查找，但是例如 他们的读取实现实际上取决于了解当前位置以正确处理读取。 一些示例： kernel/power/user.c snapshot_read fs/debugfs/file.c u32_array_read fs/fuse/control.c fusion_conn_waiting_read + ... drivers/hwmon/asus_atk0110.c atk_debugfs_ggrp_read arch/s390/hypfs/inode.c hypfs_read_iter 。 .. 尽管如此，许多 nonseekable_open 用户使用纯流语义实现读写 - 他们根本不依赖于传递的 ppos。 对于那些读取可能等待内部某些内容的情况，它会创建类似于 xenbus 的情况 - 在读取完成之前写入可能永远不会进行，并且读取正在等待一些可能是外部的事件，时间可能不受限制 - > 僵局。 除了xenbus之外，我还通过语义补丁在内核中发现了14个这样的地方（见下文）： drivers/xen/evtchn.c:667:8-24: ERROR: evtchn_fops: .read() can deadlock .write () drivers/isdn/capi/capi.c:963:8-24: 错误: capi_fops: .read() 可能会死锁 .write() drivers/input/evdev.c:527:1-17: 错误: evdev_fops: .read() 可能死锁 .write() drivers/char/pcmcia/cm4000_cs.c:1685:7-23: 错误：cm4000_fops: .read() 可能死锁 .write() net/rfkill/core.c:1146: 8-24：错误：rfkill_fops：.read（）可以死锁.write（）驱动程序/s390/char/fs3270.c：488：1-17：错误：fs3270_fops：.read（）可以死锁.write（）驱动程序/ usb/misc/ldusb.c:310:1-17: 错误: ld_usb_fops: .read() 可能死锁 .write() drivers/hid/uhid.c:635:1-17: 错误: uhid_fops: .read() 可以死锁 .write() net/batman-adv/icmp_socket.c:80:1-17: 错误：batadv_fops: .read() 可以死锁 .write() drivers/media/rc/lirc_dev.c:198:1- 17：错误：lirc_fops：.read（）可以死锁.write（）drivers/leds/uleds.c：77：1-17：错误：uleds_fops：.read（）可以死锁.write（）drivers/input/misc/ uinput.c：400：1-17：错误：uinput_fops：.read（）可以死锁.write（）drivers / infiniband / core / user_mad.c：985：7-23：错误：umad_fops：.read（）可以死锁 .write() drivers/gnss/core.c:45:1-17: ERROR: gnss_fops: .read() can deadlock .write() 除了上述情况之外，由 f_pos 锁定引起的另一个回归是现在 FUSE 文件系统 使用 FOPEN_NONSEEKABLE 标志实现打开，不能再实现双向流式文件 - 原因与上述相同，例如 读可能会死锁内核中 file.f_pos 上的写锁定。 FUSE 的 FOPEN_NONSEEKABLE 于 2008 年在 a7c1b99 中添加（“fuse：实现不可查找打开”）以支持 OSSPD。 OSSPD 在用户空间中使用 FOPEN_NONSEEKABLE 标志实现 /dev/dsp，相应的读写例程根本不依赖于当前位置，并且读写都可能是阻塞操作：请参阅 https://github.com/libfuse/osspd https ://lwn.net/Articles/308445 https://github.com/libfuse/osspd/blob/14a9cff0/osspd.c#L1406 https://github.com/libfuse/osspd/blob/14a9cff0/osspd.c #L1438-L1477 https://github.com/libfuse/osspd/blob/14a9cff0/osspd.c#L1479-L1510 相应的 libfuse 示例/测试也将 FOPEN_NONSEEKABLE 描述为“有点类似管道的文件...”，读取处理程序不 使用偏移量。 然而，该测试仅实现读而不写，无法执行死锁场景：https://github.com/libfuse/libfuse/blob/fuse-3.4.2-3-ga1bff7d/example/poll.c#L124-L131 https： //github.com/libfuse/libfuse/blob/fuse-3.4.2-3-ga1bff7d/example/poll.c#L146-L163 https://github.com/libfuse/libfuse/blob/fuse-3.4.2-3-ga1bff7d/example/poll.c#L209-L216 我实际上在实现我的 FUSE 文件系统时遇到了读与写死锁，其中 / head/watch 文件，其中 open 在文件系统与其用户之间创建单独的双向套接字流，并且稍后同时执行读取和写入。 从语义上讲，将流分成两个单独的只读和只写通道并不容易：https://lab.nexedi.com/kirr/wendelin.core/blob/f13aa600/wcfs/wcfs.go#L88 -169 让我们修复这个回归。 计划是： 1. 我们无法更改 nonseekable_open 以包含 &~FMODE_ATOMIC_POS - 这样做会破坏许多在读/写处理程序中实际使用 ppos 的内核内 nonseekable_open 用户。 2. 将stream_open()添加到内核以打开类似流的不可查找文件描述符。 对此类文件描述符的读写永远不会使用或更改 ppos。 并且通过类似流的文件的该属性，读取和写入将在不获取 f_pos 锁定的情况下运行 - 即读取和写入可以同时运行。 3. 使用语义补丁搜索并将所有内核中的 nonseekable_open 用户转换为stream_open，这些用户的读写实际上不依赖于 ppos，并且 file_operations 中没有其他方法假定@offset 访问。 4. 将 FOPEN_STREAM 添加到 fs/fuse/ 并通过 steam_open 打开内核文件描述符（如果该位存在于文件系统打开回复中）。 人们很想将 fs/fuse/ open 处理程序更改为仅在 FOPEN_NONSEEKABLE 标志上使用 stream_open 而不是 nonseekable_open，但是通过 Debian codesearch 进行 grep 显示了 FOPEN_NONSEEKABLE 的用户，特别是 GVFS，它实际上在其读写处理程序中使用了偏移量 https:// codesearch.debian.net/search?q=-%3Enonseekable+%3D https://gitlab.gnome.org/GNOME/gvfs/blob/1.40.0-6-gcbc54396/client/gvfsfusedaemon.c#L1080 https:// gitlab.gnome.org/GNOME/gvfs/blob/1.40.0-6-gcbc54396/client/gvfsfusedaemon.c#L1247-1346 https://gitlab.gnome.org/GNOME/gvfs/blob/1.40.0-6 -gcbc54396/client/gvfsfusedaemon.c#L1399-1481 因此，如果我们进行这样的更改，它将破坏真实用户。 5. 从 v3.14+（9c225f2 首次出现的内核）开始，向稳定内核添加stream_open 和 FOPEN_STREAM 处理。 这将允许修补 OSSPD 和其他提供类似流文件的 FUSE 文件系统以返回 FOPEN_STREAM | FOPEN_NONSEEKABLE 在其打开处理程序中，这样可以避免所有内核版本上的死锁。 这应该可行，因为 fs/fuse/ 忽略从文件系统返回的未知打开标志，因此将 FOPEN_STREAM 传递给不知道该标志的内核不会造成伤害。 反过来，不知道 FOPEN_STREAM 的内核将是 < v3.14，其中仅 FOPEN_NONSEEKABLE 就足以实现没有读与写死锁的流。 此补丁添加了stream_open，将/proc/xen/xenbus转换为它，并添加语义补丁以自动定位内核中的位置，这些位置要么由于读与写死锁而需要转换，要么因为读和写而可以安全地转换 write 不使用 ppos，并且 file_operations 中没有其他时髦的方法。 关于语义补丁，我已经手动验证了每个生成的更改 - 转换是正确的 - 以及剩下的每个 nonseekable_open 实例 - 在那里转换不正确，或者由于当前的stream_open.cocci限制而没有转换。 该脚本也不会转换应该有效转换但当前具有 .llseek = noop_llseek 或 generic_file_llseek 的文件，原因未知，尽管文件是使用 nonseekable_open 打开的（例如 drivers/input/mousedev.c）-> commit: https://github.com/ssbandjl/linux/commit/10dce8af34226d90fa56746a934f8da5dcdba3df
    



    


root@u20:~/project/linux/linux-5.15# modinfo rdma_rxe
filename:       /lib/modules/5.15.0/kernel/drivers/infiniband/sw/rxe/rdma_rxe.ko
alias:          rdma-link-rxe
license:        Dual BSD/GPL
description:    Soft RDMA transport
author:         Bob Pearson, Frank Zago, John Groves, Kamal Heib
srcversion:     2F508E948313DB64B26EC87
depends:        ib_core,ip6_udp_tunnel,udp_tunnel,ib_uverbs

# depends define in drivers/infiniband/sw/rxe/Kconfig

MODULE_AUTHOR("Bob Pearson, Frank Zago, John Groves, Kamal Heib");
MODULE_DESCRIPTION("Soft RDMA transport");
MODULE_LICENSE("Dual BSD/GPL");


drivers/infiniband/sw/rxe/Kconfig, 
config RDMA_RXE
	tristate "Software RDMA over Ethernet (RoCE) driver"
	depends on INET && PCI && INFINIBAND
	depends on INFINIBAND_VIRT_DMA


MODULE_ALIAS
MODULE_ALIAS_RDMA_NETLINK(RDMA_NL_LS, 4); -> MODULE_ALIAS("rdma-netlink-subsys-" __stringify(_val))


MODULE_ALIAS_RDMA_CLIENT("uverbs");



get_cb_table
    if (sock_net(skb->sk) != &init_net && type != RDMA_NL_NLDEV)
    request_module("rdma-netlink-subsys-%u", type);



root@u20:/sys/class/infiniband# modinfo ib_core
filename:       /lib/modules/5.15.0/kernel/drivers/infiniband/core/ib_core.ko
alias:          rdma-netlink-subsys-4
license:        Dual BSD/GPL
description:    core kernel InfiniBand API
author:         Roland Dreier
alias:          net-pf-16-proto-20
alias:          rdma-netlink-subsys-5


root@u20:/sys/class/infiniband# modinfo ib_uverbs
filename:       /lib/modules/5.15.0/kernel/drivers/infiniband/core/ib_uverbs.ko
alias:          rdma-client-uverbs
license:        Dual BSD/GPL
description:    InfiniBand userspace verbs access
author:         Roland Dreier
srcversion:     6E9922C32F5205C45103434
depends:        ib_core



rdma netlink type:
enum {
	RDMA_NL_IWCM = 2,
	RDMA_NL_RSVD,
	RDMA_NL_LS,	/* RDMA Local Services */
	RDMA_NL_NLDEV,	/* RDMA device interface */
	RDMA_NL_NUM_CLIENTS
};



异步事件流程:
mlx5_ib_handle_event()
  ib_dispatch_event()
    ib_cache_event()
       queue_work() -> slow cache update

    [..]
    ipoib_event()
     queue_work()
       [..]
       work handler
         ipoib_ib_dev_flush_light()
           __ipoib_ib_dev_flush()
              ipoib_dev_addr_changed_valid()
                rdma_query_gid() <- Returns old GID, cache not updated





IB事件类型
enum ib_event_type {
	IB_EVENT_CQ_ERR,
	IB_EVENT_QP_FATAL,
	IB_EVENT_QP_REQ_ERR,
	IB_EVENT_QP_ACCESS_ERR,
	IB_EVENT_COMM_EST,
	IB_EVENT_SQ_DRAINED,
	IB_EVENT_PATH_MIG,
	IB_EVENT_PATH_MIG_ERR,
	IB_EVENT_DEVICE_FATAL,
	IB_EVENT_PORT_ACTIVE,
	IB_EVENT_PORT_ERR,
	IB_EVENT_LID_CHANGE,
	IB_EVENT_PKEY_CHANGE,
	IB_EVENT_SM_CHANGE,
	IB_EVENT_SRQ_ERR,
	IB_EVENT_SRQ_LIMIT_REACHED,
	IB_EVENT_QP_LAST_WQE_REACHED,
	IB_EVENT_CLIENT_REREGISTER,
	IB_EVENT_GID_CHANGE,  -> GID改变, 存储GID, 
	IB_EVENT_WQ_FATAL,
};


rdma_resolve_route
    cma_resolve_ib_route
        cma_init_resolve_route_work
        cma_query_ib_route
            ib_sa_path_rec_get cma_query_handler
                query->sa_query.callback = callback ? ib_sa_path_rec_callback : NULL



ibv_open_device
...
IB_USER_VERBS_CMD_QUERY_DEVICE
ib_uverbs_query_device
    ib_uverbs_get_ucontext
    uverbs_request
    copy_query_dev_fields
        struct ib_device *ib_dev = ucontext->device;

        resp->fw_ver		= attr->fw_ver;
        resp->node_guid		= ib_dev->node_guid;
        resp->sys_image_guid	= attr->sys_image_guid;
        resp->max_mr_size	= attr->max_mr_size;
        resp->page_size_cap	= attr->page_size_cap;
        resp->vendor_id		= attr->vendor_id;
        resp->vendor_part_id	= attr->vendor_part_id;
        resp->hw_ver		= attr->hw_ver;
        resp->max_qp		= attr->max_qp;
        resp->max_qp_wr		= attr->max_qp_wr;
        resp->device_cap_flags  = lower_32_bits(attr->device_cap_flags);
        resp->max_sge		= min(attr->max_send_sge, attr->max_recv_sge);
        resp->max_sge_rd	= attr->max_sge_rd;
        resp->max_cq		= attr->max_cq;
        resp->max_cqe		= attr->max_cqe;
        resp->max_mr		= attr->max_mr;
        resp->max_pd		= attr->max_pd;
        resp->max_qp_rd_atom	= attr->max_qp_rd_atom;
        resp->max_ee_rd_atom	= attr->max_ee_rd_atom;
        resp->max_res_rd_atom	= attr->max_res_rd_atom;
        resp->max_qp_init_rd_atom	= attr->max_qp_init_rd_atom;
        resp->max_ee_init_rd_atom	= attr->max_ee_init_rd_atom;
        resp->atomic_cap		= attr->atomic_cap;
        resp->max_ee			= attr->max_ee;
        resp->max_rdd			= attr->max_rdd;
        resp->max_mw			= attr->max_mw;
        resp->max_raw_ipv6_qp		= attr->max_raw_ipv6_qp;
        resp->max_raw_ethy_qp		= attr->max_raw_ethy_qp;
        resp->max_mcast_grp		= attr->max_mcast_grp;
        resp->max_mcast_qp_attach	= attr->max_mcast_qp_attach;
        resp->max_total_mcast_qp_attach	= attr->max_total_mcast_qp_attach;
        resp->max_ah			= attr->max_ah;
        resp->max_srq			= attr->max_srq;
        resp->max_srq_wr		= attr->max_srq_wr;
        resp->max_srq_sge		= attr->max_srq_sge;
        resp->max_pkeys			= attr->max_pkeys;
        resp->local_ca_ack_delay	= attr->local_ca_ack_delay;
        resp->phys_port_cnt = min_t(u32, ib_dev->phys_port_cnt, U8_MAX);
    uverbs_response



ibv_cmd_get_context
IB_USER_VERBS_CMD_GET_CONTEXT -> ib_uverbs_get_context
ib_alloc_ucontext(attrs)
    struct ib_ucontext *ucontext;
    ucontext = rdma_zalloc_drv_obj(ib_dev, ib_ucontext)
        kzalloc_node(size, gfp, dev->ops.get_numa_node(dev))
        or kzalloc(size, gfp)
    xa_init_flags(&ucontext->mmap_xa, XA_FLAGS_ALLOC)
    rdma_restrack_new(&ucontext->res, RDMA_RESTRACK_CTX) -> RDMA/restrack：计算对动词对象的引用，重构重新跟踪代码以确保重新跟踪条目内的 kref 正确地是其嵌入的对象。 这一细微的变化对于 MR 和 QP 的未来转换是必要的，这些转换在发布和 kfree 之前会重新计数。 从ib_core角度来看，理想的流程如下： * 使用rdma_zalloc_*分配ib_*结构。 * 将 ib_core 已知的所有内容设置为新创建的对象。 * 使用 retrack 帮助初始化 kref * 调用驱动程序特定的分配函数。 * 插入retrack DB .... * 使用retrack_put 返回并释放retrack。 很大程度上，这意味着应该在分配包含结构时调用 rdma_restrack_new()
        kref_init(&res->kref)
        init_completion(&res->comp)
    rdma_restrack_set_name(&ucontext->res, NULL)
        rdma_restrack_attach_task
            put_task_struct -> static inline void put_task_struct
            get_task_struct
    attrs->context = ucontext
ib_init_ucontext(attrs)
    ib_rdmacg_try_charge RDMACG_RESOURCE_HCA_HANDLE -> rdmacg_try_charge - 分层尝试对 rdma 资源进行充电 @rdmacg：指向将拥有此资源的 rdma cgroup 的指针 @device：指向 rdmacg 设备的指针 @index：cgroup（资源池）中要充电的资源的索引 * 此函数遵循以下中的充电资源 分层方式。 如果收费会导致新值超出层级限制，则会失败。 如果充电成功则返回 0，否则返回 -EAGAIN、-ENOMEM 或 -EINVAL。 当充电成功时，返回指向该资源的 rdmacg 的指针。 * Charger需要根据两个标准来计算资源。 (a) 每个 cgroup 和 (b) 每个设备资源使用情况。 每个 cgroup 资源使用情况可确保 cgroup 的任务不会超出配置的限制。 每设备提供多设备使用的精细配置。 它在层次结构中为其遇到的第一个资源的每个父级分配资源池。 稍后资源池将可用。 因此充电/放电会更快
        get_current_rdmacg
        parent_rdmacg
        get_cg_rpool_locked
    alloc_ucontext -> .alloc_ucontext = irdma_alloc_ucontext,
        struct irdma_uk_attrs *uk_attrs = &iwdev->rf->sc_dev.hw_attrs.uk_attrs;
    rdma_restrack_add
        xa_insert(&rt->xa, res->id, res, GFP_KERNEL)
ib_uverbs_init_async_event_file
    INIT_IB_EVENT_HANDLER(&async_file->event_handler, ib_dev, ib_uverbs_event_handler);
rdma_alloc_commit_uobject(uobj, attrs)
    uobj->uapi_object->type_class->alloc_commit(uobj)


[补丁] IB uverbs：核心 API 扩展，一系列补丁中的第一个，添加了对用户空间直接访问 InfiniBand 硬件的支持 - 所谓的“用户空间动词”。 我相信这些补丁已经准备好合并，但最终审查会很有用。 这些补丁应该包含我四月份发布早期版本时讨论中的所有反馈（有关线程的开头，请参阅 http://lkml.org/lkml/2005/4/4/267）。 特别是，由用户空间使用的固定内存在 current->mm->vm_locked 中进行说明，并且根据 RLIMIT_MEMLOCK 检查固定内存的请求。 此补丁：修改 ib_verbs.h 头文件，进行 InfiniBand 用户空间动词支持所需的更改。 我们添加了一些结构来跟踪用户空间上下文，并扩展驱动程序 API，以便低级驱动程序知道何时创建将从用户空间使用的资源
commit: https://github.com/ssbandjl/linux/commit/e2773c062e41f710d8ef1e8a790c7e558aff663d
struct ib_ucontext {
	struct ib_device       *device;
	struct ib_uverbs_file  *ufile;

	struct ib_rdmacg_object	cg_obj;
	/*
	 * Implementation details of the RDMA core, don't use in drivers:
	 */
	struct rdma_restrack_entry res;
	struct xarray mmap_xa;
};



IB_USER_VERBS_CMD_ALLOC_PD -> ib_uverbs_alloc_pd
pd = rdma_zalloc_drv_obj(ib_dev, ib_pd)
rdma_restrack_new(&pd->res, RDMA_RESTRACK_PD)
ret = ib_dev->ops.alloc_pd(pd, &attrs->driver_udata) -> irdma_alloc_pd
    irdma_alloc_rsrc
    irdma_sc_pd_init
    


struct ib_umem {
	struct ib_device       *ibdev;
	struct mm_struct       *owning_mm;
	u64 iova;
	size_t			length;
	unsigned long		address;
	u32 writable : 1;
	u32 is_odp : 1;
	u32 is_dmabuf : 1;
	struct sg_append_table sgt_append;
};



sysfs:
Documentation/translations/zh_CN/filesystems/sysfs.txt



struct device_attribute - Interface for exporting device attributes



ib port atrribute
struct ib_port_attr {
	u64			subnet_prefix;
	enum ib_port_state	state; -> 端口状态
	enum ib_mtu		max_mtu;
	enum ib_mtu		active_mtu;
	u32                     phys_mtu;
	int			gid_tbl_len;
	unsigned int		ip_gids:1;
	/* This is the value from PortInfo CapabilityMask, defined by IBA, IB规范定义的端口信息/能力掩码 */
	u32			port_cap_flags;
	u32			max_msg_sz;
	u32			bad_pkey_cntr;
	u32			qkey_viol_cntr;
	u16			pkey_tbl_len;
	u32			sm_lid;
	u32			lid;
	u8			lmc;
	u8			max_vl_num;
	u8			sm_sl;
	u8			subnet_timeout;
	u8			init_type_reply;
	u8			active_width;
	u16			active_speed;
	u8          phys_state; -> 物理状态
	u16			port_cap_flags2;
};






irdma_query_device -> get device attributes
    addrconf_addr_eui48((u8 *)&props->sys_image_guid, iwdev->netdev->dev_addr)
    props->fw_ver = (u64)irdma_fw_major_ver(&rf->sc_dev) << 32 |
    props->max_mr_size = hw_attrs->max_mr_size
    props->hw_ver = rf->pcidev->revision;
	props->page_size_cap = hw_attrs->page_size_cap;
	props->max_mr_size = hw_attrs->max_mr_size;
	props->max_qp = rf->max_qp - rf->used_qps;
	props->max_qp_wr = hw_attrs->max_qp_wr;
	props->max_send_sge = hw_attrs->uk_attrs.max_hw_wq_frags;
	props->max_recv_sge = hw_attrs->uk_attrs.max_hw_wq_frags;
	props->max_cq = rf->max_cq - rf->used_cqs;
	props->max_cqe = rf->max_cqe - 1;
	props->max_mr = rf->max_mr - rf->used_mrs;
	props->max_mw = props->max_mr;
	props->max_pd = rf->max_pd - rf->used_pds;
	props->max_sge_rd = hw_attrs->uk_attrs.max_hw_read_sges;
	props->max_qp_rd_atom = hw_attrs->max_hw_ird;
	props->max_qp_init_rd_atom = hw_attrs->max_hw_ord;
    ...



irdma_get_hw_stats


sysfs_attr_init
sysfs_create_files
device_create_file
sysfs_create_group
kobject_create_and_add -> create a directory
struct kobject *kobj_ref;

/*Creating a directory in /sys/kernel/ */
kobj_ref = kobject_create_and_add("etx_sysfs",kernel_kobj); //sys/kernel/etx_sysfs

/*Freeing Kobj*/
kobject_put(kobj_ref);

struct kobj_attribute etx_attr = __ATTR(etx_value, 0660, sysfs_show, sysfs_store);



(gdb) bt
#0  0xffffffff81181821 in sysfs_create_file (attr=<optimized out>, kobj=<optimized out>) at ./include/linux/fortify-string.h:191
#1  module_add_modinfo_attrs (mod=0xffffffffc080c300) at kernel/module.c:1769
#2  mod_sysfs_setup (mod=mod@entry=0xffffffffc080c300, info=info@entry=0xffffc90002f5fdf0, kparam=<optimized out>, num_params=<optimized out>) at kernel/module.c:1866
#3  0xffffffff81184e50 in load_module (info=info@entry=0xffffc90002f5fdf0, uargs=uargs@entry=0x55d886f62358 "", flags=flags@entry=0) at kernel/module.c:4080
#4  0xffffffff8118571f in __do_sys_finit_module (fd=0, uargs=0x55d886f62358 "", flags=0) at kernel/module.c:4187
#5  0xffffffff8118579a in __se_sys_finit_module (flags=<optimized out>, uargs=<optimized out>, fd=<optimized out>) at kernel/module.c:4164
#6  __x64_sys_finit_module (regs=<optimized out>) at kernel/module.c:4164
#7  0xffffffff81cff979 in do_syscall_x64 (nr=<optimized out>, regs=0xffffc90002f5ff58) at arch/x86/entry/common.c:50
#8  do_syscall_64 (regs=0xffffc90002f5ff58, nr=<optimized out>) at arch/x86/entry/common.c:80
#9  0xffffffff81e0007c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:113



(gdb) bt
#0  sysfs_create_file (attr=0xffffffff83111e00 <dev_attr_uevent>, kobj=0xffff88811b6ee008) at ./include/linux/sysfs.h:607
#1  device_create_file (dev=dev@entry=0xffff88811b6ee008, attr=attr@entry=0xffffffff83111e00 <dev_attr_uevent>) at drivers/base/core.c:2764
#2  0xffffffff8181690e in device_add (dev=dev@entry=0xffff88811b6ee008) at drivers/base/core.c:3340
#3  0xffffffff8181700b in device_register (dev=dev@entry=0xffff88811b6ee008) at drivers/base/core.c:3477
#4  0xffffffff810da071 in workqueue_sysfs_register (wq=wq@entry=0xffff888115161a00) at kernel/workqueue.c:5743
#5  0xffffffff810da39c in alloc_workqueue (fmt=<optimized out>, flags=<optimized out>, max_active=<optimized out>) at kernel/workqueue.c:4351
#6  0xffffffffc058205c in ?? ()
#7  0xffffffffc0582000 in ?? ()
#8  0xffffc90002f5fc68 in ?? ()
#9  0xffffffff81003926 in do_one_initcall (fn=0xfffffff4) at init/main.c:1304

ib-comp-unb-wq


#0  device_create_file (dev=dev@entry=0xffff88810bba6510, attr=attr@entry=0xffffffff83111e00 <dev_attr_uevent>) at drivers/base/core.c:2754
#1  0xffffffff8181690e in device_add (dev=dev@entry=0xffff88810bba6510) at drivers/base/core.c:3340
#2  0xffffffffc07d5235 in ib_register_device (name=<optimized out>, dma_device=<optimized out>, device=0xffff88810bba6000) at drivers/infiniband/core/device.c:1408
#3  ib_register_device (device=0xffff88810bba6000, name=<optimized out>, dma_device=<optimized out>) at drivers/infiniband/core/device.c:1365
#4  0xffffffffc066cd70 in rxe_register_device () at drivers/infiniband/core/device.c:2859
#5  0xffffffffc0664628 in rxe_add () at drivers/infiniband/core/device.c:2859
#6  0xffffffffc0672772 in rxe_net_add () at drivers/infiniband/core/device.c:2859
#7  0xffffffffc0664063 in rxe_newlink () at drivers/infiniband/core/device.c:2859
#8  0xffffffffc07eafdc in nldev_newlink (skb=<optimized out>, nlh=<optimized out>, extack=0xffffc90000e07bd8) at drivers/infiniband/core/nldev.c:1701
#9  0xffffffffc07d8dc0 in rdma_nl_rcv_msg (extack=0x0 <fixed_percpu_data>, nlh=0xffff88811351be00, skb=0xffff88808b4a1000) at drivers/infiniband/core/netlink.c:195
#10 rdma_nl_rcv_skb (cb=<optimized out>, skb=0xffff88808b4a1000) at drivers/infiniband/core/netlink.c:239
#11 rdma_nl_rcv (skb=0xffff88808b4a1000) at drivers/infiniband/core/netlink.c:259
#12 0xffffffff81aeb4a5 in netlink_unicast_kernel (ssk=0xffff88812f965000, skb=0xffff88808b4a1000, sk=0xffff888119134000) at net/netlink/af_netlink.c:1319
#13 netlink_unicast (ssk=ssk@entry=0xffff88812f965000, skb=skb@entry=0xffff88808b4a1000, portid=portid@entry=0, nonblock=<optimized out>) at net/netlink/af_netlink.c:1345
#14 0xffffffff81aeb796 in netlink_sendmsg (sock=<optimized out>, msg=0xffffc90000e07d48, len=<optimized out>) at net/netlink/af_netlink.c:1935
#15 0xffffffff81a3db52 in sock_sendmsg_nosec (msg=0xffffffff83111e00 <dev_attr_uevent>, sock=0xffff88810bba6510) at ./include/linux/uio.h:255
#16 sock_sendmsg (sock=0xffff88810bba6510, sock@entry=0xffff888036e36e80, msg=0xffffffff83111e00 <dev_attr_uevent>, msg@entry=0xffffc90000e07d48) at net/socket.c:724
#17 0xffffffff81a3f5c3 in __sys_sendto (fd=<optimized out>, buff=<optimized out>, len=<optimized out>, flags=0, addr=0x7fb4023199e0, addr_len=12) at net/socket.c:2036
#18 0xffffffff81a3f669 in __do_sys_sendto (addr_len=<optimized out>, addr=<optimized out>, flags=<optimized out>, len=<optimized out>, buff=<optimized out>, fd=<optimized out>) at net/socket.c:2048
#19 __se_sys_sendto (addr_len=<optimized out>, addr=<optimized out>, flags=<optimized out>, len=<optimized out>, buff=<optimized out>, fd=<optimized out>) at net/socket.c:2044
#20 __x64_sys_sendto (regs=<optimized out>) at net/socket.c:2044
#21 0xffffffff81cff979 in do_syscall_x64 (nr=<optimized out>, regs=0xffffc90000e07f58) at arch/x86/entry/common.c:50
#22 do_syscall_64 (regs=0xffffc90000e07f58, nr=<optimized out>) at arch/x86/entry/common.c:80
#23 0xffffffff81e0007c in entry_SYSCALL_64 () at arch/x86/entry/entry_64.S:113




attribute,  Use DEVICE_ATTR_RO() instead of a "raw" __ATTR macro,
static DEVICE_ATTR_RO
static DEVICE_ATTR_RO(node_guid);
static DEVICE_ATTR_RO(node_type);

create, dev_attr_

static struct attribute *ib_dev_attrs[] = {
	&dev_attr_node_type.attr,
	&dev_attr_node_guid.attr,
	&dev_attr_sys_image_guid.attr,
	&dev_attr_fw_ver.attr,
	&dev_attr_node_desc.attr,
	NULL,
};
const struct attribute_group ib_dev_attr_group = {
	.attrs = ib_dev_attrs,
};


classes_init(void)
    kset_create_and_add("class"



vxworks,

iosDrvInstall


gid
drivers/infiniband/core/cache.c
store_gid_entry
add_roce_gid
make_default_gid






static int mlx5_ib_add_gid
    mlx5r_add_gid_macsec_operations(const struct ib_gid_attr *attr)
        mlx5_is_macsec_roce_supported
        get_macsec_device
        rdma_find_gid
        set_roce_addr
            rdma_read_gid_l2_fields
            ipv6_addr_v4mapped
            mlx5_core_roce_gid_set
        mlx5_macsec_add_roce_rule
        mlx5_macsec_save_roce_gid


通过扫描设备的回调枚举设备所有的GIDs(根据IP计算GID,并缓存GID)
static void enum_all_gids_of_dev_cb(struct ib_device *ib_dev, u32 port, struct net_device *rdma_ndev,void *cookie)
    for_each_net(net) -> 两层for循环
        for_each_netdev(net, ndev)
    当不处于绑定模式时，过滤并添加主网络设备的默认 GID，或者当处于绑定模式时，添加绑定主设备的默认 GID
    is_ndev_for_default_gid_filter
        add_default_gids(ib_dev, port, rdma_ndev, ndev) -> ib_cache_gid_set_default_gid
            mask = GID_ATTR_FIND_MASK_GID_TYPE | -> IB/core：修复了更改 mac 地址时删除默认 GID 的问题，在 [1] 之前，当网络设备的 MAC 地址更改时，默认 GID 应该被删除并添加回来，这会按以下顺序影响节点和/或端口 GUID。 netdevice_event() -> NETDEV_CHANGEADDR default_del_cmd() del_netdev_default_ips() bond_delete_netdev_default_gids() ib_cache_gid_set_default_gid() ib_cache_gid_del() add_cmd() [..] 但是，在非绑定场景中不会调用 ib_cache_gid_del()，因为 event_ndev 和 rdma_ndev 相同。 因此，修复这种情况，当事件 ndev 和 rdma_dev 相同时忽略检查上层设备； 类似于 bond_set_netdev_default_gids()。 此修复 ib_cache_gid_del() 被正确调用； 但是 ib_cache_gid_del() 找不到要删除的默认 GID，因为 find_gid() 被赋予 default_gid = false 并设置了 GID_ATTR_FIND_MASK_DEFAULT。 但后来它被 ib_cache_gid_set_default_gid() 覆盖，作为 add_cmd() 的一部分。 因此，mac 地址更改通常适用于默认 GID。 通过重构系列 [1]，可以检测到这种不正确的行为。 因此，删除默认GID时，请设置default_gid并设置MASK标志。 当删除基于IP的GID时，清除default_gid并设置MASK标志。 [1] https://patchwork.kernel.org/patch/10319151/
            for (gid_type = 0; gid_type < IB_GID_TYPE_SIZE; ++gid_type) -> 遍历3种GID类型
                if (1UL << gid_type & ~gid_type_mask)
            make_default_gid(ndev, &gid)
                gid->global.subnet_prefix = cpu_to_be64(0xfe80000000000000LL)
                addrconf_ifid_eui48(&gid->raw[8], dev) -> 函数ipv6_generate_eui64最终调用addrconf_ifid_eui48生成地址。将设备的MAC地址dev_addr的前三个字节拷贝到IPv6地址的后半段（s6_addr+8）开始处；在接下来的第4和第5个字节处添加0xFF和0xFE值；拷贝MAC地址的后三个字节到接下来的IPv6地址的第6个字节开始处
            __ib_cache_gid_add(ib_dev, port, &gid, &gid_attr, mask, true)
                rdma_is_zero_gid(gid) -> IB/core：减少使用 zgid 的地方，而不是开放编码 memcmp() 来检查给定的 GID 是否为零，而是使用辅助函数来执行此操作，并用 memset 替换 memcpy(z,&zgid) 的实例
                find_gid(table, gid, attr, default_gid, mask, &empty) -> find gid from cache
                add_modify_gid(table, attr)
                    entry = alloc_gid_entry(attr)
                    add_roce_gid(entry)
                        rdma_cap_roce_gid_table
                        attr->device->ops.add_gid(attr, &entry->context) -> mlx5_ib_add_gid
                    store_gid_entry(table, entry)
                        table->data_vec[entry->attr.index] = entry; -> store gid
                dispatch_gid_change_event(ib_dev, port)
                    event.event		= IB_EVENT_GID_CHANGE
                    ib_dispatch_event_clients(&event) -> IB/核心：让 IB 核心分发缓存更新事件 目前，当低级驱动程序通知 Pkey、GID 和端口更改事件时，它们会按照注册的顺序通知给已注册的处理程序。 IB 核心和其他 ULP（例如 IPoIB）对 GID、LID、Pkey 更改事件感兴趣。 由于 ULP 完成的所有 GID 查询均由 IB 核心提供服务，并且 IB 核心将缓存更新推迟到工作队列，因此其他客户端在处理自己的事件时可能会看到过时的缓存数据。 例如，下面的调用树显示了 ipoib 如何在更新 WQ 中的缓存的同时调用 rdma_query_gid()。 mlx5_ib_handle_event() ib_dispatch_event() ib_cache_event()queue_work() -> 缓存更新速度较慢 [..] ipoib_event()queue_work() [..] 工作处理程序 ipoib_ib_dev_flush_light() __ipoib_ib_dev_flush() ipoib_dev_addr_changed_valid() rdma_query_gid() <- 返回旧 GID ，缓存未更新。 将所有事件分派移至工作队列，以便始终在通知任何客户端之前完成缓存更新
                        list_for_each_entry(handler, &event->device->event_handler_list, list)
                            handler->handler(handler, event)
    is_eth_port_of_netdev_filter
        real_dev = rdma_vlan_dev_real_dev(cookie) -> IB/core：删除从 void 到 net_device 的指针转换，此补丁避免了从 void 到 net_device 的不必要的类型转换 -> IB/核心：为 IBoE 添加 VLAN 支持，为 IBoE 添加 802.1q VLAN 支持。 VLAN 标记按以下方式编码在从链路本地地址派生的 GID 中： 当 GID 包含 VLAN 时，GID[11] GID[12] 包含 VLAN ID。 数据包的 3 位用户优先级字段与 SL 的 3 位相同。 对于 rdma_cm 应用程序，TOS 字段用于通过右移 5 位来生成 SL 字段，从而有效地占用 TOS 字段的 3 MS 位 -> commit: https://github.com/ssbandjl/linux/commit/af7bd463761c6abd8ca8d831f9cc0ac19f3b7d4b
            is_vlan_dev(dev) ? vlan_dev_real_dev(dev) : NULL
                net_device *ret = vlan_dev_priv(dev)->real_dev -> while (is_vlan_dev(ret)) -> 递归拿到vlan设备对应的真实设备
        rdma_is_upper_dev_rcu -> IB/core：将 rdma_is_upper_dev_rcu 移至头文件，为了验证路由，我们需要一种简单的方法来检查网络设备是否属于我们的 RDMA 设备。 将此辅助函数移至头文件以使检查更容易
            netdev_has_upper_dev_all_rcu -> Check if device is linked to an upper device
                netdev_walk_all_upper_dev_rcu(dev, ____netdev_has_upper_dev,
        is_eth_active_slave_of_bonding_rcu -> IB/核心：添加RoCE表绑定(bond)支持，处理绑定和其他设备需要我们所有网络设备的GID，这些网络设备是RoCE端口相关网络设备的上层设备。 活动备份配置带来了更多挑战，因为默认 GID 只能在活动设备上设置（这是必要的，否则相同的 MAC 可以用于多个从设备，因此多个从设备将具有相同的 GID）。 管理这些配置是通过监听来完成的： (a) NETDEV_CHANGEUPPER 事件 (1) 如果链接了相关的网络设备，则删除所有不活动的从设备默认 GID 并添加上层设备 GID。 (2) 如果相关网络设备未链接，则删除所有上层GID，并添加默认GID。 (b) NETDEV_BONDING_FAILOVER: (1) 从非活动从站删除绑定 GID (2) 删除非活动从站的默认 GID (3) 将绑定 GID 添加到活动从站 -> struct bonding
            netif_is_bond_master(upper)
            bond_option_active_slave_get_rcu
                rcu_dereference_rtnl(bond->curr_active_slave)
                bond_uses_primary(bond)
    _add_netdev_ips(ib_dev, port, ndev)
        enum_netdev_ipv4_ips(ib_dev, port, ndev) -> 枚举IPv4设备的IP地址
            __in_dev_get_rcu
            list_add_tail(&entry->list, &sin_list)
            update_gid_ip(GID_ADD, ib_dev, port, ndev, (struct sockaddr *)&sin_iter->ip);
                rdma_ip2gid(addr, &gid) -> IP地址到GID的转换算法 -> IB/core：verbs/cm 结构中的以太网 L2 属性，此补丁添加了对 verbs/cm/cma 结构中的以太网 L2 属性的支持。 在处理 L2 以太网时，我们应该以与使用 IB L2（和 L4 PKEY）属性类似的方式使用 smac、dmac、vlan ID 和优先级。 因此，这些属性被添加到以下结构中： * ib_ah_attr - 添加了 dmac * ib_qp_attr - 添加了 smac 和 vlan_id，（sl 保留 vlan 优先级） * ib_wc - 添加了 smac、vlan_id * ib_sa_path_rec - 添加了 smac、dmac、vlan_id * cm_av - 添加了 smac 和 vlan_id 对于路径记录结构，在将其打包为有线格式时特别注意避免新字段，因此我们不会破坏 IB CM 和 SA 有线协议。 在主动侧，CM 被填充。 其内部结构来自 ULP 提供的路径。 我们添加了 ETH L2 属性并将它们放入 CM 地址句柄（struct cm_av）中。 在被动侧，CM 从与 REQ 消息关联的 WC 中填充其内部结构。 我们添加了从 WC 获取 ETH L2 属性的内容。 当硬件驱动程序在 WC 中提供所需的 ETH L2 属性时，它们会设置 IB_WC_WITH_SMAC 和 IB_WC_WITH_VLAN 标志。 IB 核心代码检查这些标志是否存在，如果没有，则从 ib_init_ah_from_wc() 辅助函数进行地址解析。 ib_modify_qp_is_ok 也被更新以考虑链路层。 有些参数对于以太网链路层是必需的，而对于IB来说则无关。 修改供应商驱动程序以支持新的函数签名
                    case AF_INET: -> ipv4
                        ipv6_addr_set_v4mapped(((struct sockaddr_in *)addr)->sin_addr.s_addr, (struct in6_addr *)gid)
                            ipv6_addr_set(v4mapped, 0, 0, htonl(0x0000FFFF), addr)
                                __ipv6_addr_set_half(&addr->s6_addr32[0], w1, w2)
                                __ipv6_addr_set_half(&addr->s6_addr32[2], w3, w4)
                    case AF_INET6:
                        *(struct in6_addr *)&gid->raw =	((struct sockaddr_in6 *)addr)->sin6_addr
                update_gid(gid_op, ib_dev, port, &gid, &gid_attr)
                    unsigned long gid_type_mask = roce_gid_type_mask_support(ib_dev, port) -> IB/core：将gid_type添加到gid属性中，为了支持多种GID类型，我们需要存储每个GID的gid_type。 这也与 RoCE v2 附件“RoCEv2 端口 GID 表条目应具有表示 L3 地址类型的“GID 类型”属性”保持一致。 当前支持的 GID 是 IB_GID_TYPE_IB，这也是 RoCE v1 GID 类型。 这意味着 gid_type 应添加到 roce_gid_table 元数据中
                    ib_cache_gid_add(ib_dev, port, gid, gid_attr) -> .is_supported = &mlx5_rdma_supported,
                        __ib_cache_gid_add
                    or ib_cache_gid_del(ib_dev, port, gid, gid_attr) -> _ib_cache_gid_del
                        find_gid
                        del_gid(ib_dev, port, table, ix) -> del_gid
                            mlx5r_del_gid_macsec_operations -> del flow
                        dispatch_gid_change_event(ib_dev, port)
        enum_netdev_ipv6_ips(ib_dev, port, ndev)
            in6_dev = in6_dev_get(ndev)
            list_add_tail(&entry->list, &sin6_list)
            rdma_ip2gid((struct sockaddr *)&sin6_iter->sin6, &gid)
            update_gid(GID_ADD, ib_dev, port, &gid, &gid_attr)



ucma_copy_iboe_route struct rdma_route -> RDMA/cma：多路径记录支持 netlink 通道，支持通过 RDMA netlink 通道从用户空间服务接收入站和出站 IB 路径记录（以及 GMP PathRecord）。 这3个PR中的LID可以这样使用： 1. GMP PR：用作标准本地/远程LID； 2、出站PR的DLID：用作出站流量的“dlid”字段； 3.入站PR的DLID：用作响应方出站流量的“dlid”字段。 这样做的目的是支持自适应路由。 使用当前的 IB 路由解决方案，当数据包发出时，每个目标都会被分配一个固定的 DLID，这意味着将使用固定的路由器。 入站/出站路径记录中的 LID 可用于识别允许与另一个子网实体进行通信的路由器组。 通过它们，来自子网间连接的数据包可以通过该组中的任何路由器到达目标。 正如 Jason 所确认的，当发送 netlink 请求时，内核使用 LS_RESOLVE_PATH_USE_ALL 以便服务知道内核支持多个 PR



IB：地址转换以将 IP 映射到 IB 地址 (GID)，添加地址转换服务，使用 IPoIB 将 IP 地址映射到 InfiniBand GID 地址
/**
 * struct rdma_dev_addr - Contains resolved RDMA hardware addresses
 * @src_dev_addr:	Source MAC address.
 * @dst_dev_addr:	Destination MAC address.
 * @broadcast:		Broadcast address of the device.
 * @dev_type:		The interface hardware type of the device.
 * @bound_dev_if:	An optional device interface index.
 * @transport:		The transport type used.
 * @net:		Network namespace containing the bound_dev_if net_dev.
 * @sgid_attr:		GID attribute to use for identified SGID
 */
struct rdma_dev_addr {
	unsigned char src_dev_addr[MAX_ADDR_LEN]; -> 源MAC(SMAC)
	unsigned char dst_dev_addr[MAX_ADDR_LEN]; -> 目的MAC(DMAC)
	unsigned char broadcast[MAX_ADDR_LEN];
	unsigned short dev_type;
	int bound_dev_if;
	enum rdma_transport_type transport;
	struct net *net;
	const struct ib_gid_attr *sgid_attr;
	enum rdma_network_type network;
	int hoplimit;
};



iboe_addr_get_sgid


addr_resolve
    rdma_set_src_addr_rcu
    ...
        rdma_translate_ip  -> Translate a local IP address to an RDMA hardware
            dev = dev_get_by_index(dev_addr->net, dev_addr->bound_dev_if) -> IB/addr：将网络命名空间作为参数传递，为ib_addr模块添加网络命名空间支持。 为此，所有地址解析和匹配都应该使用适当的命名空间而不是 init_net 来完成。 这是通过以下方式实现的： 1. 将显式网络命名空间参数添加到需要命名空间的导出函数。 2. 将命名空间保存在 rdma_addr_client 结构中。 3. 调用网络功能时使用。 为了保留调用模块的行为，&init_net 在其他模块的调用中作为参数传递。 随着在更多级别上添加命名空间支持，此内容已被修改 -> Deprecated for new users, call netdev_get_by_index() instead -> netdev_get_by_index() - 通过 ifindex 查找设备， @net：适用的网络命名空间 @ifindex：设备索引 @tracker：获取引用的跟踪对象 @gfp：跟踪器的分配标志 按索引搜索接口。 如果未找到设备或指向设备的指针，则返回 NULL。 返回的设备已添加了引用，并且指针是安全的，直到用户调用 netdev_put() 表明他们已完成使用它
                dev_get_by_index_rcu(net, ifindex)
                    hlist_for_each_entry_rcu(dev, head, index_hlist)
            rdma_copy_src_l2_addr(dev_addr, dev)
                memcpy(dev_addr->broadcast, dev->broadcast, MAX_ADDR_LEN)
            dev = rdma_find_ndev_for_src_ip_rcu(dev_addr->net, addr)
                switch (src_in->sa_family)
                case AF_INET:
                    __ip_dev_find
                        ifa = inet_lookup_ifaddr_rcu(net, addr)
                            u32 hash = inet_addr_hash(net, addr)
                            net_eq(dev_net(ifa->ifa_dev->dev), net)
                        local = fib_get_table(net, RT_TABLE_LOCAL)
                        fib_table_lookup
                            trace_fib_table_lookup
                case AF_INET6:
                    ipv6_chk_addr -> ipv6_chk_addr_and_flags -> VRF 设备与 ip 规则相结合，提供了在 Linux 网络堆栈中创建虚拟路由和转发域（又名 VRF，具体为 VRF-lite）的能力。 一种用例是多租户问题，其中每个租户都有自己独特的路由表，并且至少需要不同的默认网关。 通过将套接字绑定到 VRF 设备，进程可以“感知 VRF”。 然后，通过套接字的数据包使用与 VRF 设备关联的路由表。 VRF 设备实现的一个重要特征是它仅影响第 3 层及以上层，因此 L2 工具（例如 LLDP）不受影响（即它们不需要在每个 VRF 中运行）。 该设计还允许使用更高优先级的 IP 规则（基于策略的路由，PBR），以优先于根据需要引导特定流量的 VRF 设备规则。 此外，VRF 设备允许 VRF 嵌套在命名空间内。 例如，网络命名空间提供设备层网络接口的分离，命名空间内接口上的 VLAN 提供 L2 分离，然后 VRF 设备提供 L3 分离。 设计 VRF 设备是通过关联的路由表创建的。 然后网络接口被从属于 VRF 设备：-> net/ipv6：更改地址检查以始终采用设备参数，ipv6_chk_addr_and_flags 确定地址是否是本地地址，以及（可选）是否是特定设备上的地址。 例如，由 ip6_route_info_create 调用它来确定给定的网关地址是否是本地地址。 地址检查当前不考虑 L3 域，因此如果下一跳指向第二个 VRF 中的地址，则不允许在一个 VRF 中添加路由。 例如，$ ip route add 2001:db8:1::/64 vrf r2 via 2001:db8:102::23 错误：网关地址无效。 其中 2001:db8:102::23 是 vrf r1 中接口上的地址。 ipv6_chk_addr_and_flags 需要允许调用者始终传入带有单独参数的设备，以免将地址限制为特定设备。 该设备用于确定感兴趣的 L3 域。 为此，添加一个参数以跳过设备检查并更新调用者以始终在可能的情况下传递设备，并使用新参数来表示域中的任何地址。 使用 NULL dev 参数更新 ipv6_chk_addr 的少数用户。 此补丁处理对这些调用者的更改，而无需添加域检查。 ip6_validate_gw 需要处理 2 种情况 - 一种是设备作为下一跳规范的一部分给出，另一种是设备被解析。 至少有 1 种 VRF 情况，将检查推迟到仅在路由查找解决之后，设备会失败并出现不直观的错误“RTNETLINK 答案：没有到主机的路由”，而不是首选的“错误：网关不能是本地地址” ”。 “没有到主机的路由”错误是由于回退到完整查找而导致的。 检查两次以避免此错误
                        inet6_addr_hash
                        l3mdev_master_dev_rcu
                        ipv6_addr_equal


bond type, 
#define BOND_MODE_ROUNDROBIN	0
#define BOND_MODE_ACTIVEBACKUP	1
#define BOND_MODE_XOR		2
#define BOND_MODE_BROADCAST	3
#define BOND_MODE_8023AD        4
#define BOND_MODE_TLB           5
#define BOND_MODE_ALB		6 /* TLB + RLB (receive load balancing) */


IB QP属性
struct ib_qp_attr {
	enum ib_qp_state	qp_state;
	enum ib_qp_state	cur_qp_state;
	enum ib_mtu		path_mtu;
	enum ib_mig_state	path_mig_state;
	u32			qkey;
	u32			rq_psn;
	u32			sq_psn;
	u32			dest_qp_num;
	int			qp_access_flags;
	struct ib_qp_cap	cap;
	struct rdma_ah_attr	ah_attr;
	struct rdma_ah_attr	alt_ah_attr;
	u16			pkey_index;
	u16			alt_pkey_index;
	u8			en_sqd_async_notify;
	u8			sq_draining;
	u8			max_rd_atomic;
	u8			max_dest_rd_atomic;
	u8			min_rnr_timer;
	u32			port_num;
	u8			timeout;
	u8			retry_cnt;
	u8			rnr_retry;
	u32			alt_port_num;
	u8			alt_timeout;
	u32			rate_limit;
	struct net_device	*xmit_slave;
};



位宽和速度:
enum ib_port_width {
	IB_WIDTH_1X	= 1,
	IB_WIDTH_2X	= 16,
	IB_WIDTH_4X	= 2,
	IB_WIDTH_8X	= 4,
	IB_WIDTH_12X	= 8
};

static inline int ib_width_enum_to_int(enum ib_port_width width)
{
	switch (width) {
	case IB_WIDTH_1X:  return  1;
	case IB_WIDTH_2X:  return  2;
	case IB_WIDTH_4X:  return  4;
	case IB_WIDTH_8X:  return  8;
	case IB_WIDTH_12X: return 12;
	default: 	  return -1;
	}
}

enum ib_port_speed {
	IB_SPEED_SDR	= 1,
	IB_SPEED_DDR	= 2,
	IB_SPEED_QDR	= 4,
	IB_SPEED_FDR10	= 8,
	IB_SPEED_FDR	= 16,
	IB_SPEED_EDR	= 32,
	IB_SPEED_HDR	= 64,
	IB_SPEED_NDR	= 128,
	IB_SPEED_XDR	= 256,
};



Intel E810 RDMA硬件属性 -> RDMA/irdma：实现硬件管理队列操作集合，驱动程序将特权命令发布到硬件管理队列（控制 QP 或 CQP）以请求硬件的管理操作。 实现 CQP 的创建/销毁以及支持函数、数据结构和标头以处理不同的 CQP 命令
struct irdma_hw_attrs {
	struct irdma_uk_attrs uk_attrs;
	u64 max_hw_outbound_msg_size;
	u64 max_hw_inbound_msg_size;
	u64 max_mr_size;
	u64 page_size_cap;
	u32 min_hw_qp_id;
	u32 min_hw_aeq_size;
	u32 max_hw_aeq_size;
	u32 min_hw_ceq_size;
	u32 max_hw_ceq_size;
	u32 max_hw_device_pages;
	u32 max_hw_vf_fpm_id;
	u32 first_hw_vf_fpm_id;
	u32 max_hw_ird;
	u32 max_hw_ord;
	u32 max_hw_wqes;
	u32 max_hw_pds;
	u32 max_hw_ena_vf_count;
	u32 max_qp_wr;
	u32 max_pe_ready_count;
	u32 max_done_count;
	u32 max_sleep_count;
	u32 max_cqp_compl_wait_time_ms;
	u16 max_stat_inst;
	u16 max_stat_idx;
};


IB GID类型
enum ib_gid_type {
	IB_GID_TYPE_IB = IB_UVERBS_GID_TYPE_IB,
	IB_GID_TYPE_ROCE = IB_UVERBS_GID_TYPE_ROCE_V1,
	IB_GID_TYPE_ROCE_UDP_ENCAP = IB_UVERBS_GID_TYPE_ROCE_V2,
	IB_GID_TYPE_SIZE
};


#define ROCE_V2_UDP_DPORT      4791


struct net_device {
    __cacheline_group_begin(net_device_read_tx)
    缓存线组织可以在 Documentation/networking/net_cachelines/net_device.rst 中找到文档。 添加新字段时请更新文档
    const struct net_device_ops *netdev_ops;
    const struct ethtool_ops *ethtool_ops;
    unsigned char		broadcast[MAX_ADDR_LEN]
    struct devlink_port	*devlink_port;
}

struct net {
    struct netns_ipvs	*ipvs
    struct netns_mpls	mpls
    struct netns_xdp	xdp
}



GID table:
table->data_vec[entry->attr.index] = entry
|   0   |   1   |...|  31   |
| entry | entry |...| entry |




VLAN设备结构体
/**
 *	struct vlan_dev_priv - VLAN private device data
 *	@nr_ingress_mappings: number of ingress priority mappings
 *	@ingress_priority_map: ingress priority mappings
 *	@nr_egress_mappings: number of egress priority mappings
 *	@egress_priority_map: hash of egress priority mappings
 *	@vlan_proto: VLAN encapsulation protocol
 *	@vlan_id: VLAN identifier
 *	@flags: device flags
 *	@real_dev: underlying netdevice
 *	@dev_tracker: refcount tracker for @real_dev reference
 *	@real_dev_addr: address of underlying netdevice
 *	@dent: proc dir entry
 *	@vlan_pcpu_stats: ptr to percpu rx stats
 */
struct vlan_dev_priv {
	unsigned int				nr_ingress_mappings;
	u32					ingress_priority_map[8];
	unsigned int				nr_egress_mappings;
	struct vlan_priority_tci_mapping	*egress_priority_map[16];

	__be16					vlan_proto;
	u16					vlan_id;
	u16					flags;

	struct net_device			*real_dev; -> vlan对应的真实设备
	netdevice_tracker			dev_tracker;

	unsigned char				real_dev_addr[ETH_ALEN];

	struct proc_dir_entry			*dent;
	struct vlan_pcpu_stats __percpu		*vlan_pcpu_stats;
#ifdef CONFIG_NET_POLL_CONTROLLER
	struct netpoll				*netpoll;
#endif
};


读写信号量, 对于无竞争的 rwsem，计数和所有者是任务在获取 rwsem 时需要接触的唯一字段。 因此，它们被放置在彼此旁边，以增加它们共享相同缓存行的机会。 在竞争的 rwsem 中，所有者可能是结构中最常访问的字段，因为持有 osq 锁的乐观等待者将在所有者上旋转。 对于嵌入式 rwsem，包含结构中的其他热字段应远离 rwsem，以减少它们共享相同缓存行而导致缓存行弹跳问题的机会
参考: http://linux.laoqinren.net/kernel/rw-semaphore/, https://blog.csdn.net/jkzzxQQQ/article/details/109522694
struct rw_semaphore {
};


网络事件通知类型
enum netevent_notif_type {
	NETEVENT_NEIGH_UPDATE = 1, /* arg is struct neighbour ptr */
	NETEVENT_REDIRECT,	   /* arg is struct netevent_redirect ptr */
	NETEVENT_DELAY_PROBE_TIME_UPDATE, /* arg is struct neigh_parms ptr */
	NETEVENT_IPV4_MPATH_HASH_UPDATE, /* arg is struct net ptr */
	NETEVENT_IPV6_MPATH_HASH_UPDATE, /* arg is struct net ptr */
	NETEVENT_IPV4_FWD_UPDATE_PRIORITY_UPDATE, /* arg is struct net ptr */
};

ip_do_redirect -> __ip_do_redirect
    call_netevent_notifiers(NETEVENT_NEIGH_UPDATE, n)



irdma_net_event
    switch (event) {
	case NETEVENT_NEIGH_UPDATE
        real_dev = rdma_vlan_dev_real_dev(netdev)
        iwdev = to_iwdev(ibdev)
        irdma_add_arp(iwdev->rf, local_ipaddr, ipv4, neigh->ha)
            arpidx = irdma_arp_table(rf, &ip[0], ipv4, NULL, IRDMA_ARP_RESOLVE)
                for (arp_index = 0; (u32)arp_index < rf->arp_table_size; arp_index++)
                case IRDMA_ARP_ADD:
                    irdma_alloc_rsrc(rf, rf->allocated_arps, rf->arp_table_size,
                        rsrc_num = find_next_zero_bit(rsrc_array, max_rsrc, *next)
                        __set_bit(rsrc_num, rsrc_array)
                    memcpy(rf->arp_table[arp_index].ip_addr, ip, sizeof(rf->arp_table[arp_index].ip_addr))
                    ether_addr_copy(rf->arp_table[arp_index].mac_addr, mac_addr) -> Copy an Ethernet address
                        a[0] = b[0];
            irdma_manage_arp_cache(rf, mac, ip, ipv4, IRDMA_ARP_ADD) -> manage hw arp cache
                cqp_request = irdma_alloc_and_get_cqp_request(&rf->cqp, false)
                cqp_info->cqp_cmd = IRDMA_OP_ADD_ARP_CACHE_ENTRY
                irdma_handle_cqp_op(rf, cqp_request) -> irdma_sc_add_arp_cache_entry
                    wqe = irdma_sc_cqp_get_next_send_wqe(cqp, scratch)
        or irdma_manage_arp_cache



irdma_inetaddr_event
    case NETDEV_DOWN: -> 网口down
        irdma_manage_arp_cache(iwdev->rf, real_dev->dev_addr, &local_ipaddr, true, IRDMA_ARP_DELETE)
    case NETDEV_UP: -> 网口up
	case NETDEV_CHANGEADDR:
		irdma_add_arp(iwdev->rf, &local_ipaddr, true, real_dev->dev_addr);
		irdma_if_notify(iwdev, real_dev, &local_ipaddr, true, true) -> process an ifdown on an interface
            u16 vlan_id = rdma_vlan_dev_vlan_id(netdev)
                return is_vlan_dev(dev) ? vlan_dev_vlan_id(dev) : 0xffff
            irdma_qhash_ctrl -> irdma_qhash_ctrl - 启用/禁用列表的 qhash @iwdev: 设备指针 @parent_listen_node: 父侦听节点 @nfo: cm 信息节点 @ipaddr: 指向 IPv4 或 IPv6 地址的指针 @ipv4: 为 true 时指示 IPv4 的标志 @ifup: 指示接口打开的标志 true 启用或禁用子监听列表中与 ipaddr 匹配的节点的 qhash。 如果没有找到匹配的 IP，它将分配并添加一个新的子监听节点到父监听节点。 假定在调用时已持有listen_list_lock
                irdma_manage_qhash(iwdev, nfo, IRDMA_QHASH_TYPE_TCP_SYN, op, NULL,
                    cqp_request = irdma_alloc_and_get_cqp_request(iwcqp, wait)
                    cqp_request->callback_fcn = irdma_send_syn_cqp_callback
                    cqp_info->cqp_cmd = IRDMA_OP_MANAGE_QHASH_TABLE_ENTRY -> irdma_sc_manage_qhash_table_entry
                        set_64bit_val(wqe, 0, ether_addr_to_u64(info->mac_addr))
            irdma_manage_qhash
            irdma_cm_teardown_connections
                irdma_teardown_list_prep
                attr.qp_state = IB_QPS_ERR
                irdma_modify_qp(&cm_node->iwqp->ibqp, &attr, IB_QP_STATE, NULL)
                irdma_cm_disconn
                    INIT_WORK(&work->work, irdma_disconnect_worker)
                irdma_rem_ref_cm_node
		irdma_gid_change_event(&iwdev->ibdev);
            ib_event.event = IB_EVENT_GID_CHANGE
            ib_dispatch_event(&ib_event)


rf, 
struct irdma_pci_f {

}




intel cqp ops, 
static const char *const irdma_cqp_cmd_names[IRDMA_MAX_CQP_OPS] = {
	[IRDMA_OP_CEQ_DESTROY] = "Destroy CEQ Cmd",
	[IRDMA_OP_AEQ_DESTROY] = "Destroy AEQ Cmd",
	[IRDMA_OP_DELETE_ARP_CACHE_ENTRY] = "Delete ARP Cache Cmd",
	[IRDMA_OP_MANAGE_APBVT_ENTRY] = "Manage APBV Table Entry Cmd",
	[IRDMA_OP_CEQ_CREATE] = "CEQ Create Cmd",
	[IRDMA_OP_AEQ_CREATE] = "AEQ Destroy Cmd",
	[IRDMA_OP_MANAGE_QHASH_TABLE_ENTRY] = "Manage Quad Hash Table Entry Cmd",
	[IRDMA_OP_QP_MODIFY] = "Modify QP Cmd",
	[IRDMA_OP_QP_UPLOAD_CONTEXT] = "Upload Context Cmd",
	[IRDMA_OP_CQ_CREATE] = "Create CQ Cmd",
	[IRDMA_OP_CQ_DESTROY] = "Destroy CQ Cmd",
	[IRDMA_OP_QP_CREATE] = "Create QP Cmd",
	[IRDMA_OP_QP_DESTROY] = "Destroy QP Cmd",
	[IRDMA_OP_ALLOC_STAG] = "Allocate STag Cmd",
	[IRDMA_OP_MR_REG_NON_SHARED] = "Register Non-Shared MR Cmd",
	[IRDMA_OP_DEALLOC_STAG] = "Deallocate STag Cmd",
	[IRDMA_OP_MW_ALLOC] = "Allocate Memory Window Cmd",
	[IRDMA_OP_QP_FLUSH_WQES] = "Flush QP Cmd",
	[IRDMA_OP_ADD_ARP_CACHE_ENTRY] = "Add ARP Cache Cmd",
	[IRDMA_OP_MANAGE_PUSH_PAGE] = "Manage Push Page Cmd",
	[IRDMA_OP_UPDATE_PE_SDS] = "Update PE SDs Cmd",
	[IRDMA_OP_MANAGE_HMC_PM_FUNC_TABLE] = "Manage HMC PM Function Table Cmd",
	[IRDMA_OP_SUSPEND] = "Suspend QP Cmd",
	[IRDMA_OP_RESUME] = "Resume QP Cmd",
	[IRDMA_OP_MANAGE_VF_PBLE_BP] = "Manage VF PBLE Backing Pages Cmd",
	[IRDMA_OP_QUERY_FPM_VAL] = "Query FPM Values Cmd",
	[IRDMA_OP_COMMIT_FPM_VAL] = "Commit FPM Values Cmd",
	[IRDMA_OP_AH_CREATE] = "Create Address Handle Cmd",
	[IRDMA_OP_AH_MODIFY] = "Modify Address Handle Cmd",
	[IRDMA_OP_AH_DESTROY] = "Destroy Address Handle Cmd",
	[IRDMA_OP_MC_CREATE] = "Create Multicast Group Cmd",
	[IRDMA_OP_MC_DESTROY] = "Destroy Multicast Group Cmd",
	[IRDMA_OP_MC_MODIFY] = "Modify Multicast Group Cmd",
	[IRDMA_OP_STATS_ALLOCATE] = "Add Statistics Instance Cmd",
	[IRDMA_OP_STATS_FREE] = "Free Statistics Instance Cmd",
	[IRDMA_OP_STATS_GATHER] = "Gather Statistics Cmd",
	[IRDMA_OP_WS_ADD_NODE] = "Add Work Scheduler Node Cmd",
	[IRDMA_OP_WS_MODIFY_NODE] = "Modify Work Scheduler Node Cmd",
	[IRDMA_OP_WS_DELETE_NODE] = "Delete Work Scheduler Node Cmd",
	[IRDMA_OP_SET_UP_MAP] = "Set UP-UP Mapping Cmd",
	[IRDMA_OP_GEN_AE] = "Generate AE Cmd",
	[IRDMA_OP_QUERY_RDMA_FEATURES] = "RDMA Get Features Cmd",
	[IRDMA_OP_ALLOC_LOCAL_MAC_ENTRY] = "Allocate Local MAC Entry Cmd",
	[IRDMA_OP_ADD_LOCAL_MAC_ENTRY] = "Add Local MAC Entry Cmd",
	[IRDMA_OP_DELETE_LOCAL_MAC_ENTRY] = "Delete Local MAC Entry Cmd",
	[IRDMA_OP_CQ_MODIFY] = "CQ Modify Cmd",
};


irdma cm,
drivers/infiniband/hw/irdma/cm.h



net/mlx5：添加对端口类型和速度寄存器中引入的 ext_* 字段的支持，此补丁公开了新的链路模式（包括每通道 50Gbps），以及描述端口类型和速度寄存器 (PTYS) 中的新链路模式的 ext_* 字段 。 访问功能、转换功能（速度 <-> HW 位）和链路最大速度功能已修改
enum mlx5e_ext_link_mode {
	MLX5E_SGMII_100M			= 0,
	MLX5E_1000BASE_X_SGMII			= 1,
	MLX5E_5GBASE_R				= 3,
	MLX5E_10GBASE_XFI_XAUI_1		= 4,
	MLX5E_40GBASE_XLAUI_4_XLPPI_4		= 5,
	MLX5E_25GAUI_1_25GBASE_CR_KR		= 6,
	MLX5E_50GAUI_2_LAUI_2_50GBASE_CR2_KR2	= 7,
	MLX5E_50GAUI_1_LAUI_1_50GBASE_CR_KR	= 8,
	MLX5E_CAUI_4_100GBASE_CR4_KR4		= 9,
	MLX5E_100GAUI_2_100GBASE_CR2_KR2	= 10,
	MLX5E_100GAUI_1_100GBASE_CR_KR		= 11,
	MLX5E_200GAUI_4_200GBASE_CR4_KR4	= 12,
	MLX5E_200GAUI_2_200GBASE_CR2_KR2	= 13,
	MLX5E_400GAUI_8_400GBASE_CR8		= 15,
	MLX5E_400GAUI_4_400GBASE_CR4_KR4	= 16,
	MLX5E_800GAUI_8_800GBASE_CR8_KR8	= 19,
	MLX5E_EXT_LINK_MODES_NUMBER,
};

MLX5_BUILD_PTYS2ETHTOOL_CONFIG(MLX5E_1000BASE_CX_SGMII, legacy, ETHTOOL_LINK_MODE_1000baseKX_Full_BIT);
({ 
    struct ptys2ethtool_config *cfg; 
    const unsigned int modes[] = { ETHTOOL_LINK_MODE_1000baseKX_Full_BIT }; 
    unsigned int i, bit, idx; 
    cfg = &ptys2legacy_ethtool_table[MLX5E_1000BASE_CX_SGMII]; 
    bitmap_zero(cfg->supported, __ETHTOOL_LINK_MODE_MASK_NBITS); 
    bitmap_zero(cfg->advertised, __ETHTOOL_LINK_MODE_MASK_NBITS); 
    for (i = 0 ; i < ARRAY_SIZE(modes) ; ++i) { 
        bit = modes[i] % 64; idx = modes[i] / 64; 
        __set_bit(bit, &cfg->supported[idx]); 
        __set_bit(bit, &cfg->advertised[idx]); 
    }
})


commit: https://lore.kernel.org/netdev/1594383913-3295-7-git-send-email-moshe@mellanox.com/T/
* [PATCH net-next v3 0/7] 添加对 devlink 端口的 devlink-health 支持，在每个端口的基础上实现对 devlink health reports 的支持。 该补丁集修复了一个设计问题，因为一些运行状况报告器报告错误并在设备级别运行恢复，而实际功能是在端口级别。 至于当前实现的 devlink health 报告器，它仅与 mlx5 的 Tx 和 Rx 报告器相关，而 mlx5 只有一个端口，因此对功能没有实际影响，但在更多驱动程序使用 devlink health 报告器之前应该修复此问题。 本系列的第一部分为健康报告器的实现准备通用功能部分。 其次介绍了 devlink-health 和 mlx5e 所需的 API，演示了其用法并实现了 mlx5 驱动程序的功能。 每端口报告器功能是通过以类似于现有设备基础设施的方式将 devlink_health_reporters 列表添加到 devlink_port 结构来实现的。 这是唯一的主要区别，它使得完全重用设备报告器操作成为可能。 该效果将与 iproute2 添加一起看到，并将影响所有 devlink health 命令。 用户可以通过查看 devlink 句柄来区分设备和端口报告器。 端口报告器在地址末尾有一个端口索引，并且可以在 devlink-health 接受它的每个地方将此类地址作为参数提供。 这些可以通过 devlink port show 命令获得。 例如： $ devlink health show pci/0000:00:0a.0:reporter fw statehealthy error 0recover 0auto_dump true pci/0000:00:0a.0/1:reportertxstatehealthyerror0recover 0grace_period 500auto_recover true auto_dump true $ devlink health set pci/0000:00:0a.0/1reporter tx Grace_period 1000 \ auto_recover false auto_dump false $devlink health show pci/0000:00:0a.0/1reporter tx pci/0000:00: 0a.0/1:reporter tx statehealthy error 0recover 0grace_period1000auto_recover flase auto_dump false 注意：用户可以使用相同的 devlink health uAPI 命令现在可以获取端口运行状况报告器或设备运行状况报告器。 例如，恢复命令： 在此补丁集之前： devlink health recovery DEV reports REPORTER_NAME 在此补丁集之后： devlink health recovery { DEV | REPORTER_NAME 。 DEV/PORT_INDEX } 记者 REPORTER_NAME


devlink port
PCI 控制器 大多数情况下，一个 PCI 设备只有一个控制器。 控制器可能由多个物理、虚拟功能和子功能组成。 一项功能由一个或多个端口组成。 此端口由 devlink eswitch 端口表示。 然而，连接到多个 CPU 或多个 PCI 根联合体或 SmartNIC 的 PCI 设备可能有多个控制器。 对于具有多个控制器的设备，每个控制器都通过唯一的控制器编号来区分。 eswitch位于PCI设备上，支持多个控制器的端口。 具有两个控制器的系统的示例视图：

```bash
             ---------------------------------------------------------
             |                                                       |
             |           --------- ---------         ------- ------- |
-----------  |           | vf(s) | | sf(s) |         |vf(s)| |sf(s)| |
| server  |  | -------   ----/---- ---/----- ------- ---/--- ---/--- |
| pci rc  |=== | pf0 |______/________/       | pf1 |___/_______/     |
| connect |  | -------                       -------                 |
-----------  |     | controller_num=1 (no eswitch)                   | 外部控制器1
             ------|--------------------------------------------------
             (internal wire 内部线路)
                   |
             ---------------------------------------------------------
             | devlink eswitch ports and reps                        |
             | ----------------------------------------------------- |
             | |ctrl-0 | ctrl-0 | ctrl-0 | ctrl-0 | ctrl-0 |ctrl-0 | |
             | |pf0    | pf0vfN | pf0sfN | pf1    | pf1vfN |pf1sfN | |
             | ----------------------------------------------------- |
             | |ctrl-1 | ctrl-1 | ctrl-1 | ctrl-1 | ctrl-1 |ctrl-1 | |
             | |pf0    | pf0vfN | pf0sfN | pf1    | pf1vfN |pf1sfN | |
             | ----------------------------------------------------- |
             |                                                       |
             |                                                       |
-----------  |           --------- ---------         ------- ------- |
| smartNIC|  |           | vf(s) | | sf(s) |         |vf(s)| |sf(s)| |
| pci rc  |==| -------   ----/---- ---/----- ------- ---/--- ---/--- |
| connect |  | | pf0 |______/________/       | pf1 |___/_______/     |
-----------  | -------                       -------                 |
             |                                                       |
             |  local controller_num=0 (eswitch)                     | 本地控制器0
             ---------------------------------------------------------
```

在上面的示例中，外部控制器（由控制器编号 = 1 标识）没有 eswitch。 本地控制器（由控制器编号 = 0 标识）具有 eswitch。 本地控制器上的 Devlink 实例具有两个控制器的 eswitch devlink 端口




static const struct dcbnl_rtnl_ops mlx5e_dcbnl_ops = {
	.ieee_getets	= mlx5e_dcbnl_ieee_getets,
	.ieee_setets	= mlx5e_dcbnl_ieee_setets,
	.ieee_getmaxrate = mlx5e_dcbnl_ieee_getmaxrate,
	.ieee_setmaxrate = mlx5e_dcbnl_ieee_setmaxrate,
	.ieee_getpfc	= mlx5e_dcbnl_ieee_getpfc,
	.ieee_setpfc	= mlx5e_dcbnl_ieee_setpfc,
	.ieee_setapp    = mlx5e_dcbnl_ieee_setapp,
	.ieee_delapp    = mlx5e_dcbnl_ieee_delapp,
	.getdcbx	= mlx5e_dcbnl_getdcbx,
	.setdcbx	= mlx5e_dcbnl_setdcbx,
	.dcbnl_getbuffer = mlx5e_dcbnl_getbuffer,
	.dcbnl_setbuffer = mlx5e_dcbnl_setbuffer,

/* CEE interfaces */
	.setall         = mlx5e_dcbnl_setall,
	.getstate       = mlx5e_dcbnl_getstate,
	.getpermhwaddr  = mlx5e_dcbnl_getpermhwaddr,

	.setpgtccfgtx   = mlx5e_dcbnl_setpgtccfgtx,
	.setpgbwgcfgtx  = mlx5e_dcbnl_setpgbwgcfgtx,
	.getpgtccfgtx   = mlx5e_dcbnl_getpgtccfgtx,
	.getpgbwgcfgtx  = mlx5e_dcbnl_getpgbwgcfgtx,

	.setpfccfg      = mlx5e_dcbnl_setpfccfg,
	.getpfccfg      = mlx5e_dcbnl_getpfccfg,
	.getcap         = mlx5e_dcbnl_getcap,
	.getnumtcs      = mlx5e_dcbnl_getnumtcs,
	.getpfcstate    = mlx5e_dcbnl_getpfcstate,
	.setpfcstate    = mlx5e_dcbnl_setpfcstate,
};


const struct ethtool_ops mlx5e_ethtool_ops = {
	.cap_rss_ctx_supported	= true,
	.supported_coalesce_params = ETHTOOL_COALESCE_USECS |
				     ETHTOOL_COALESCE_MAX_FRAMES |
				     ETHTOOL_COALESCE_USE_ADAPTIVE |
				     ETHTOOL_COALESCE_USE_CQE,
	.get_drvinfo       = mlx5e_get_drvinfo,
	.get_link          = ethtool_op_get_link,
	.get_link_ext_state  = mlx5e_get_link_ext_state,
	.get_strings       = mlx5e_get_strings,
	.get_sset_count    = mlx5e_get_sset_count,
	.get_ethtool_stats = mlx5e_get_ethtool_stats,
	.get_ringparam     = mlx5e_get_ringparam,
	.set_ringparam     = mlx5e_set_ringparam,
	.get_channels      = mlx5e_get_channels,
	.set_channels      = mlx5e_set_channels,
	.get_coalesce      = mlx5e_get_coalesce,
	.set_coalesce      = mlx5e_set_coalesce,
	.get_link_ksettings  = mlx5e_get_link_ksettings,
	.set_link_ksettings  = mlx5e_set_link_ksettings,
	.get_rxfh_key_size   = mlx5e_get_rxfh_key_size,
	.get_rxfh_indir_size = mlx5e_get_rxfh_indir_size,
	.get_rxfh          = mlx5e_get_rxfh,
	.set_rxfh          = mlx5e_set_rxfh,
	.get_rxnfc         = mlx5e_get_rxnfc,
	.set_rxnfc         = mlx5e_set_rxnfc,
	.get_tunable       = mlx5e_get_tunable,
	.set_tunable       = mlx5e_set_tunable,
	.get_pause_stats   = mlx5e_get_pause_stats,
	.get_pauseparam    = mlx5e_get_pauseparam,
	.set_pauseparam    = mlx5e_set_pauseparam,
	.get_ts_info       = mlx5e_get_ts_info,
	.set_phys_id       = mlx5e_set_phys_id,
	.get_wol	   = mlx5e_get_wol,
	.set_wol	   = mlx5e_set_wol,
	.get_module_info   = mlx5e_get_module_info,
	.get_module_eeprom = mlx5e_get_module_eeprom,
	.get_module_eeprom_by_page = mlx5e_get_module_eeprom_by_page,
	.flash_device      = mlx5e_flash_device,
	.get_priv_flags    = mlx5e_get_priv_flags,
	.set_priv_flags    = mlx5e_set_priv_flags,
	.self_test         = mlx5e_self_test,
	.get_fec_stats     = mlx5e_get_fec_stats,
	.get_fecparam      = mlx5e_get_fecparam,
	.set_fecparam      = mlx5e_set_fecparam,
	.get_eth_phy_stats = mlx5e_get_eth_phy_stats,
	.get_eth_mac_stats = mlx5e_get_eth_mac_stats,
	.get_eth_ctrl_stats = mlx5e_get_eth_ctrl_stats,
	.get_rmon_stats    = mlx5e_get_rmon_stats,
	.get_link_ext_stats = mlx5e_get_link_ext_stats
};





const struct net_device_ops mlx5e_netdev_ops = {
	.ndo_open                = mlx5e_open,
	.ndo_stop                = mlx5e_close,
	.ndo_start_xmit          = mlx5e_xmit,
	.ndo_setup_tc            = mlx5e_setup_tc,
	.ndo_select_queue        = mlx5e_select_queue,
	.ndo_get_stats64         = mlx5e_get_stats,
	.ndo_set_rx_mode         = mlx5e_set_rx_mode,
	.ndo_set_mac_address     = mlx5e_set_mac,
	.ndo_vlan_rx_add_vid     = mlx5e_vlan_rx_add_vid,
	.ndo_vlan_rx_kill_vid    = mlx5e_vlan_rx_kill_vid,
	.ndo_set_features        = mlx5e_set_features,
	.ndo_fix_features        = mlx5e_fix_features,
	.ndo_change_mtu          = mlx5e_change_nic_mtu,
	.ndo_eth_ioctl            = mlx5e_ioctl,
	.ndo_set_tx_maxrate      = mlx5e_set_tx_maxrate,
	.ndo_features_check      = mlx5e_features_check,
	.ndo_tx_timeout          = mlx5e_tx_timeout,
	.ndo_bpf		 = mlx5e_xdp,
	.ndo_xdp_xmit            = mlx5e_xdp_xmit,
	.ndo_xsk_wakeup          = mlx5e_xsk_wakeup,
#ifdef CONFIG_MLX5_EN_ARFS
	.ndo_rx_flow_steer	 = mlx5e_rx_flow_steer,
#endif
#ifdef CONFIG_MLX5_ESWITCH
	.ndo_bridge_setlink      = mlx5e_bridge_setlink,
	.ndo_bridge_getlink      = mlx5e_bridge_getlink,

	/* SRIOV E-Switch NDOs */
	.ndo_set_vf_mac          = mlx5e_set_vf_mac,
	.ndo_set_vf_vlan         = mlx5e_set_vf_vlan,
	.ndo_set_vf_spoofchk     = mlx5e_set_vf_spoofchk,
	.ndo_set_vf_trust        = mlx5e_set_vf_trust,
	.ndo_set_vf_rate         = mlx5e_set_vf_rate,
	.ndo_get_vf_config       = mlx5e_get_vf_config,
	.ndo_set_vf_link_state   = mlx5e_set_vf_link_state,
	.ndo_get_vf_stats        = mlx5e_get_vf_stats,
	.ndo_has_offload_stats   = mlx5e_has_offload_stats,
	.ndo_get_offload_stats   = mlx5e_get_offload_stats,
#endif
};


const struct xdp_metadata_ops mlx5e_xdp_metadata_ops = {
	.xmo_rx_timestamp		= mlx5e_xdp_rx_timestamp,
	.xmo_rx_hash			= mlx5e_xdp_rx_hash,
	.xmo_rx_vlan_tag		= mlx5e_xdp_rx_vlan_tag,
};


const struct xsk_tx_metadata_ops mlx5e_xsk_tx_metadata_ops = {
	.tmo_fill_timestamp		= mlx5e_xsk_fill_timestamp,
	.tmo_request_checksum		= mlx5e_xsk_request_checksum,
};



static int mlx5e_nic_init(struct mlx5_core_dev *mdev,
    mlx5e_build_nic_params
        mlx5e_params_mqprio_reset -> net/mlx5e：提高 MQPRIO 弹性，* 添加 netdev->tc_to_txq 回滚，以防 mlx5e_update_netdev_queues() 失败。 * 修复了两种模式之间损坏的转换：tc==8 的 MQPRIO DCB 模式和 MQPRIO 通道模式。 * 如果使用不同数量的通道重新连接，请禁用 MQPRIO 通道模式。 * 改进代码共享
        params->rx_cqe_compress_def = slow_pci_heuristic(mdev) -> net/mlx5e：统一慢速 PCI 启发式，将链路/pci 速度查询和逻辑集成到单个函数中。 统一启发式并对所有数据使用单一 PCI 阈值 (16G)
        mlx5e_build_rq_params -> net/mlx5e：更改VF表示器的RQ类型，表示器的RQ大小不足以使它们获得足够高的性能，因此需要放大，同时对其内存使用造成最小影响。 为了实现这一点，增加了表示器 RQ 的大小，并且将其类型更改为跨步 RQ（如果支持）。 为了实现这一目标，进行了以下更改： * 将用于设置标准 netdev 的 RQ 参数的序列提取到函数中 * 用标准序列替换用于设置表示器的 RQ 参数的序列 此更改的影响可以在以下测量中看到 通过 VF 设置 VM，通过 VF 表示器连接到 OVS，连接到外部主机： 在当前更改之前：TCP 吞吐量 [Gb/s] VM 到外部主机 ~ 7.2 当前更改后（使用跨步 RQ 测量） )：VM 到外部主机的 TCP 吞吐量 [Gb/s] ~ 23.5 每个表示器现在为其数据包缓冲区消耗 2 [MB] 内存
            首选跨步 RQ，除非满足以下任一条件： - 跨步 RQ 配置不可能/不支持。 - CQE 压缩处于开启状态，并且不支持 stride_index mini_cqe 布局。 - Legacy RQ 将使用线性 SKB，而 Striding RQ 将使用非线性。 无 XSK 参数：一般检查跨步 RQ 的可用性
            mlx5e_rx_mpwqe_is_linear_skb
            mlx5e_set_rq_type
            mlx5e_init_rq_type_params
        mlx5_core_get_terminate_scatter_list_mkey
            mlx5_cmd_exec_inout MLX5_CMD_OP_QUERY_SPECIAL_CONTEXTS
        mlx5e_choose_lro_timeout
        mlx5_query_min_inline -> net/mlx5e：Tx，软化内联模式 VLAN 依赖性，如果有能力，请在 TX WQE 中对非 VLAN 数据包使用零内联模式。 对于 VLAN，请至少保持 L2 内联模式的强制执行，除非 WQE VLAN 插入卸载上限已打开。 性能：经测试单核包速率为64Bytes。 NIC：ConnectX-5 CPU：Intel(R) Xeon(R) Gold 6154 CPU @ 3.00GHz pktgen：之前：12.46 Mpps 之后：14.65 Mpps (+17.5%) XDP_TX：MPWQE 流不受影响，因为它已经有这个 优化。 因此我们使用 priv-flag xdp_tx_mpwqe: off 进行测试。 之前：9.90 Mpps 之后：10.20 Mpps (+3%)
            mlx5_query_nic_vport_min_inline
        AF_XDP -> net/mlx5e：添加 XSK 零拷贝支持，此提交添加了对 AF_XDP 零拷贝 RX 和 TX 的支持。 我们在通道内创建专用的 XSK RQ，这意味着两个 RQ 同时运行：一个用于非 XSK 流量，另一个用于 XSK 流量。 常规 RQ 和 XSK RQ 使用单个 ID 命名空间，分为两半：下半部分是常规 RQ，上半部分是 XSK RQ。 当任何零拷贝 AF_XDP 套接字处于活动状态时，不允许更改通道数，因为这会破坏 XSK RQ ID 和通道之间的映射。 XSK 需要不同的页面分配和释放例程。 mlx5e_{alloc,free}_rx_mpwqe 和 mlx5e_{get,put}_rx_frag 等函数足够通用，可用于常规 RQ 和 XSK RQ，并且它们在实际分配函数周围使用 mlx5e_page_{alloc,release} 包装器。 不使用函数指针以避免损失 retpolines 的性能。 只要确定应该使用常规（非 XSK）页面释放函数，就会直接调用它。 只有对 XSK 有意义的统计信息才会暴露给用户空间。 那些不参与 XSK 流程的不予考虑。 请注意，我们不会等待 XSK RQ 上的 WQE（与常规 RQ 不同），因为较新的 xdpsock 示例在设置阶段不提供任何填充环条目。 我们在频道中创建了专用的 XSK SQ。 这种分离有其优点： 1. 当 UMEM 关闭时，XSK SQ 也可以关闭并停止接收完成。 如果现有的 SQ 用于 XSK，它将继续接收已关闭套接字的数据包的完成情况。 如果此时打开一个新的 UMEM，它将开始获得不属于它的完成。 2、单独计算统计。 当用户空间启动 TX 时，驱动程序通过将 NOP 发布到专用 XSK ICO（内部控制操作）SQ 来触发硬件中断，以便在正确的 CPU 内核上触发 NAPI。 该 XSK ICO SQ 受自旋锁保护，因为用户空间应用程序可能会从任何核心踢出 TX。 将指向 UMEM 的指针存储在网络设备私有上下文中，独立于内核。 这样驱动程序就可以区分零拷贝和非零拷贝 UMEM。 内核函数 xdp_get_umem_from_qid 不关心这种差异，但驱动程序只对零拷贝 UMEM 感兴趣，特别是在清理时，它通过查看 UMEM 的存在来确定是否关闭 XSK RQ 和 SQ。 使用state_lock来保护对UMEM指针该区域的访问。 LRO 与 XDP 不兼容，但在 XDP 关闭时可能存在活动的 UMEM。 如果是这种情况，请不要允许 LRO 确保可以随时重新启用 XDP。 XSK 参数的验证通常在 XSK 队列打开时进行。 但是，当接口关闭或未设置 XDP 程序时，仍然可以拥有活动的 AF_XDP 套接字，甚至可以打开新套接字，但 XSK 队列将被关闭。 为了涵盖这些情况，请还在以下流程中执行验证： 1. 注册新的 UMEM，但由于缺少 XDP 程序或接口已关闭，因此不会创建 XSK 队列。 2. 当有 UMEM 注册时，MTU 会发生变化。 进行此早期检查可防止 mlx5e_open_channels 在稍后阶段失败，此时恢复是不可能的，并且应用程序没有机会处理错误，因为它获得了 MTU 更改或 XSK 打开操作的成功返回值。 性能测试在具有以下配置的计算机上进行： - 24 个 Intel Xeon E5-2620 v3 内核 @ 2.40 GHz - Mellanox ConnectX-5 Ex，具有 100 Gbit/s 链路 禁用 retpoline 的结果，单流：txonly：33.3 Mpps（21.5 Mpps，队列和应用程序固定到同一 CPU） rxdrop：12.2 Mpps l2fwd：9.4 Mpps 启用 retpoline 的结果，单流：txonly：21.3 Mpps（14.1 Mpps，队列和应用程序固定到同一 CPU） rxdrop： 9.9 Mpps l2fwd：6.8 Mpps
    mlx5e_vxlan_set_netdev_info
        mlx5_vxlan_allowed(priv->mdev->vxlan)
        mlx5e_vxlan_set_port
        mlx5e_vxlan_unset_port
        mlx5_vxlan_max_udp_ports
    mlx5e_build_rep_params -> net/mlx5e：在上行链路初始化期间分配流量控制存储，IPsec 代码依赖于有效的 priv->fs 指针，NIC 流量中就是这种情况，但在上行链路中不正确。 在修复行中提到的提交之前，该指针在所有流中都有效，因为它是与 priv 结构一起分配的。 此外，清理表示例程调用了未初始化的 priv->fs 指针及其内部结构，这导致了 NULL 引用。 因此，尽早移动 FS 分配
        mlx5e_build_rq_params
        ...
    mlx5e_timestamp_init
    priv->dfs_root = debugfs_create_dir("nic",
    mlx5e_fs_init
        mlx5e_fs_vlan_alloc
        mlx5e_fs_tc_alloc
            mlx5e_tc_table_alloc -> net/mlx5e：仅为特色配置文件分配 VLAN 和 TC，作为 fs API 的一部分引入流量控制 VLAN 和 TC 的分配和取消分配功能。 将 VLAN 和 TC 的分配添加为 nic 配置文件功能，这样 fs_init() 仅当配置文件中包含 VLAN 和 TC 时才会分配它们。 VLAN 和 TC 仅与 nic_profile 相关
        mlx5e_fs_ethtool_alloc
        mlx5e_fs_debugfs_init
            fs->dfs_root = debugfs_create_dir("fs", dfs_root)
    mlx5e_ktls_init
        mlx5e_is_ktls_device
        mlx5e_tls_debugfs_init
            tls->debugfs.dfs = debugfs_create_dir("tls", dfs_root)
    mlx5e_health_create_reporters
        mlx5e_reporter_tx_create
            priv->tx_reporter = reporter
        mlx5e_reporter_rx_create
            priv->rx_reporter = reporter
    if (take_rtnl) ->  net_device的改变会通过rtnl_lock和rtnl_unlock收到Routing Netlink信号量的保护。这也是为什么register_netdev执行时需要请求锁，并且在返回时要释放锁的原因。一旦register_netdevice完成了它自己的工作，它会通过net_set_todo将net_device结构体添加到net_todo_list中。net_todo_list包含一系列有注册（或除名）操作需要被完成的设备列表。这份列表有register_netdev在释放锁时间接予以处理
    mlx5e_set_xdp_feature(netdev)



mlx5e_init_nic_tx
    mlx5e_accel_init_tx -> mlx5e_ktls_init_tx
        dek_pool = mlx5_crypto_dek_pool_create -> net/mlx5：添加新的API用于快速更新加密密钥，添加新的API以支持快速更新DEK。 由于池是为每个关键目的（类型）创建的，因此需要一对池 API 来获取/放置池。 另一对 DEK API 是从池中获取 DEK 对象并使用用户密钥更新它，或者将其释放回池中。 由于后续补丁将支持批量分配和销毁，因此这里使用旧的实现。 为了支持这些 API，首先定义 pool 和 dek 结构。 其中仅存储少量字段。 例如，pool 结构中的 key_ Purpose 和 refcnt，dek 结构中的 DEK 对象 id。 更多字段将在以后的补丁中添加到这些结构体中，例如，pool 结构体的不同批量列表，批量指针 dek 结构体所属，以及池中列表的 list_entry，用于保存等待被调用的键。 当其他线程正在同步时被释放。 除了创建和销毁接口外，还新增了一个获取obj id的接口。 目前这些 API 计划仅由 TLS 使用
            INIT_LIST_HEAD(&pool->avail_list);
            INIT_WORK(&pool->sync_work, mlx5_crypto_dek_sync_work_fn)
            INIT_WORK(&pool->destroy_work, mlx5_crypto_dek_destroy_work_fn)
        priv->tls->tx_pool = mlx5e_tls_tx_pool_init
            INIT_WORK(&pool->create_work, create_work) -> net/mlx5e：kTLS，动态调整TX回收池的大小，让TLS TX回收池的大小更加灵活，通过不断动态地分配和释放硬件资源以响应连接速率和负载的变化。 批量分配和释放池条目 (16)。 使用工作队列在后台释放/分配。 当池大小低于低阈值 (1K) 时分配新的批量。 当池大小大于上限阈值（4K）时，将执行对称操作。 每个空闲池条目都包含：1 个 TIS、1 DEK（硬件资源）以及主机内存中的约 100 字节。 从空池开始，以最大程度地减少启用了设备卸载 TLS 的非 TLS 用户的内存和硬件资源浪费。 收到新请求时，如果池为空，请不要等待整个批量分配完成。 相反，触发单个资源的即时分配以减少延迟。 性能测试： 之前：11,684 CPS 之后：16,556 CPS
                bulk_async = mlx5e_bulk_async_init(pool->mdev, MLX5E_TLS_TX_POOL_BULK)
                    mlx5_cmd_init_async_ctx
                    bulk_async->arr[i].async_ctx = &bulk_async->async_ctx
                mlx5e_tls_priv_tx_init
                    mlx5e_ktls_create_tis
                    mlx5e_ktls_create_tis_cb create_tis_callback
        mlx5e_tls_tx_debugfs_init(tls, tls->debugfs.dfs)
    mlx5e_set_mqprio_rl
    mlx5e_dcbnl_initialize -> net/mlx5e：ConnectX-4 固件对 DCBX 的支持，默认情况下 DBCX 由设置了 dcbx 功能位的固件控制。 在此模式下，固件负责从远程伙伴读取 TLV 数据包或向远程伙伴发送 TLV 数据包。 该补丁设置基础设施以在 HOST/FW DCBX 控制模式之间移动


流量类型
enum mlx5_traffic_types {
	MLX5_TT_IPV4_TCP,
	MLX5_TT_IPV6_TCP,
	MLX5_TT_IPV4_UDP,
	MLX5_TT_IPV6_UDP,
	MLX5_TT_IPV4_IPSEC_AH,
	MLX5_TT_IPV6_IPSEC_AH,
	MLX5_TT_IPV4_IPSEC_ESP,
	MLX5_TT_IPV6_IPSEC_ESP,
	MLX5_TT_IPV4,
	MLX5_TT_IPV6,
	MLX5_TT_ANY,
	MLX5_NUM_TT,
	MLX5_NUM_INDIR_TIRS = MLX5_TT_ANY,
};


流命名空间类型
enum mlx5_flow_namespace_type {
	MLX5_FLOW_NAMESPACE_BYPASS,
	MLX5_FLOW_NAMESPACE_KERNEL_RX_MACSEC,
	MLX5_FLOW_NAMESPACE_LAG,
	MLX5_FLOW_NAMESPACE_OFFLOADS,
	MLX5_FLOW_NAMESPACE_ETHTOOL,
	MLX5_FLOW_NAMESPACE_KERNEL,
	MLX5_FLOW_NAMESPACE_LEFTOVERS,
	MLX5_FLOW_NAMESPACE_ANCHOR,
	MLX5_FLOW_NAMESPACE_FDB_BYPASS,
	MLX5_FLOW_NAMESPACE_FDB,
	MLX5_FLOW_NAMESPACE_ESW_EGRESS,
	MLX5_FLOW_NAMESPACE_ESW_INGRESS,
	MLX5_FLOW_NAMESPACE_SNIFFER_RX,
	MLX5_FLOW_NAMESPACE_SNIFFER_TX,
	MLX5_FLOW_NAMESPACE_EGRESS,
	MLX5_FLOW_NAMESPACE_EGRESS_IPSEC,
	MLX5_FLOW_NAMESPACE_EGRESS_MACSEC,
	MLX5_FLOW_NAMESPACE_RDMA_RX,
	MLX5_FLOW_NAMESPACE_RDMA_RX_KERNEL,
	MLX5_FLOW_NAMESPACE_RDMA_TX,
	MLX5_FLOW_NAMESPACE_PORT_SEL,
	MLX5_FLOW_NAMESPACE_RDMA_RX_COUNTERS,
	MLX5_FLOW_NAMESPACE_RDMA_TX_COUNTERS,
	MLX5_FLOW_NAMESPACE_RDMA_RX_IPSEC,
	MLX5_FLOW_NAMESPACE_RDMA_TX_IPSEC,
	MLX5_FLOW_NAMESPACE_RDMA_RX_MACSEC,
	MLX5_FLOW_NAMESPACE_RDMA_TX_MACSEC,
};


流表命令集
static const struct mlx5_flow_cmds mlx5_flow_cmds = {
	.create_flow_table = mlx5_cmd_create_flow_table,
	.destroy_flow_table = mlx5_cmd_destroy_flow_table,
	.modify_flow_table = mlx5_cmd_modify_flow_table,
	.create_flow_group = mlx5_cmd_create_flow_group,
	.destroy_flow_group = mlx5_cmd_destroy_flow_group,
	.create_fte = mlx5_cmd_create_fte,
	.update_fte = mlx5_cmd_update_fte,
	.delete_fte = mlx5_cmd_delete_fte,
	.update_root_ft = mlx5_cmd_update_root_ft,
	.packet_reformat_alloc = mlx5_cmd_packet_reformat_alloc,
	.packet_reformat_dealloc = mlx5_cmd_packet_reformat_dealloc,
	.modify_header_alloc = mlx5_cmd_modify_header_alloc,
	.modify_header_dealloc = mlx5_cmd_modify_header_dealloc,
	.create_match_definer = mlx5_cmd_create_match_definer,
	.destroy_match_definer = mlx5_cmd_destroy_match_definer,
	.set_peer = mlx5_cmd_stub_set_peer,
	.create_ns = mlx5_cmd_stub_create_ns,
	.destroy_ns = mlx5_cmd_stub_destroy_ns,
	.get_capabilities = mlx5_cmd_get_capabilities,
};


HCA虚拟端口上下文
struct mlx5_hca_vport_context {
	u32			field_select;
	bool			sm_virt_aware;
	bool			has_smi;
	bool			has_raw;
	enum port_state_policy	policy;
	enum phy_port_state	phys_state;
	enum ib_port_state	vport_state;
	u8			port_physical_state;
	u64			sys_image_guid;
	u64			port_guid;
	u64			node_guid;
	u32			cap_mask1;
	u32			cap_mask1_perm;
	u16			cap_mask2;
	u16			cap_mask2_perm;
	u16			lid;
	u8			init_type_reply; /* bitmask: see ib spec 14.2.5.6 InitTypeReply */
	u8			lmc;
	u8			subnet_timeout;
	u16			sm_lid;
	u8			sm_sl;
	u16			qkey_violation_counter;
	u16			pkey_violation_counter;
	bool			grh_required;
};




一个包含指向所有每个进程、命名空间的指针的结构 - fs (mount)、uts、network、sysvipc 等。 pid 命名空间是一个例外 - 它是使用 task_active_pid_ns 访问的。 这里的pid命名空间是孩子们将使用的命名空间。 “count”是持有引用的任务数量。 那么，每个命名空间的计数将是指向它的 nsproxy 数量，而不是任务数量。 nsproxy 由共享所有命名空间的任务共享。 一旦克隆或取消共享单个命名空间，就会复制 nsproxy。 */
struct nsproxy {
	refcount_t count;
	struct uts_namespace *uts_ns;
	struct ipc_namespace *ipc_ns;
	struct mnt_namespace *mnt_ns;
	struct pid_namespace *pid_ns_for_children;
	struct net 	     *net_ns;
	struct time_namespace *time_ns;
	struct time_namespace *time_ns_for_children;
	struct cgroup_namespace *cgroup_ns;
};

添加了新的系统调用 setns()。 它将调用线程附加到现有的命名空间。 其原型为 int setns(int fd, int nstype); 参数是： • fd：引用命名空间的文件描述符。 这些是通过打开 /proc/<pid>/ns/ 目录中的链接获得的。 • nstype：可选参数。 当它是新的 CLONE_NEW* 命名空间标志之一时，指定的文件描述符必须引用与指定的 CLONE_NEW* 标志的类型匹配的命名空间。 当未设置 nstype（其值为 0）时，fd 参数可以引用任何类型的命名空间。 如果 nstype 与指定 fd 关联的命名空间类型不对应，则返回 –EINVAL 值。 您可以在 kernel/nsproxy.c 中找到 setns() 系统调用的实现。 • 添加了以下六个新克隆标志以支持命名空间： • CLONE_NEWNS（用于装载命名空间） • CLONE_NEWUTS（用于 UTS 命名空间） • CLONE_NEWIPC（用于 IPC 命名空间） • CLONE_NEWPID（用于 PID 命名空间） • CLONE_NEWNET（用于网络命名空间） • CLONE_NEWUSER（用于用户命名空间） 传统上，使用clone() 系统调用来创建新进程。 它经过调整以支持这些新标志，以便它将创建附加到新命名空间（或多个命名空间）的新进程。 请注意，在本章后面的一些示例中，您将遇到使用 CLONE_NEWNET 标志来创建新的网络命名空间的情况。 • 六个具有名称空间支持的子系统中的每个子系统都实现了自己的唯一名称空间。 例如，挂载命名空间由名为 mnt_namespace 的结构体表示，网络命名空间由名为 net 的结构体表示，这将在本节后面讨论。 我将在本章后面提到其他命名空间。 • 对于名称空间创建，添加了名为create_new_namespaces() 的方法(kernel/nsproxy.c)。 此方法获取 CLONE_NEW* 标志或 CLONE_NEW* 标志的位图作为第一个参数。 它首先通过调用create_nsproxy()方法创建一个nsproxy对象，然后根据指定的flag关联一个命名空间； 由于标志可以是标志的位掩码，因此 create_new_namespaces() 方法可以关联多个名称空间。 我们来看看create_new_namespaces()方法


net_device 结构代表网络设备。 它可以是物理设备，如以太网设备，也可以是软件设备，如桥接设备或 VLAN 设备。 与 sk_buff 结构一样，我将列出它的重要成员。 net_device 结构体在 include/linux/netdevice.h 中定义


IB速率
enum ib_rate {
	IB_RATE_PORT_CURRENT = 0,
	IB_RATE_2_5_GBPS = 2,
	IB_RATE_5_GBPS   = 5,
	IB_RATE_10_GBPS  = 3,
	IB_RATE_20_GBPS  = 6,
	IB_RATE_30_GBPS  = 4,
	IB_RATE_40_GBPS  = 7,
	IB_RATE_60_GBPS  = 8,
	IB_RATE_80_GBPS  = 9,
	IB_RATE_120_GBPS = 10,
	IB_RATE_14_GBPS  = 11,
	IB_RATE_56_GBPS  = 12,
	IB_RATE_112_GBPS = 13,
	IB_RATE_168_GBPS = 14,
	IB_RATE_25_GBPS  = 15,
	IB_RATE_100_GBPS = 16,
	IB_RATE_200_GBPS = 17,
	IB_RATE_300_GBPS = 18,
	IB_RATE_28_GBPS  = 19,
	IB_RATE_50_GBPS  = 20,
	IB_RATE_400_GBPS = 21,
	IB_RATE_600_GBPS = 22,
	IB_RATE_800_GBPS = 23,
};

保护域（PD），PD是将QP和SRQ与MR以及AH与QP相关联的RDMA资源。 可以将PD视为一种颜色，例如：红色MR可以与红色QP配合使用，红色AH可以与红色QP配合使用。 使用带有红色 QP 的绿色 AH 将导致错误


扩展可靠连接 (XRC)，XRC 是一种 IB 传输扩展，与原始可靠传输相比，它在发送方为可靠连接 QP 提供了更好的可扩展性。 使用 XRC 将减少两个特定核心之间的 QP 数量：当使用 RC QP 时，对于每个核心，在每台机器中，都有一个 QP。 使用XRC时，每台主机中都会有一个XRC QP。 发送消息时，发送方需要指定接收该消息的远端SRQ号


地址句柄（AH），AH是一种RDMA资源，描述从本地端口到目的地的远程端口的路径。 它正用于 UD QP



VFS 所处理的系统调用,表 8.2 列出 VFS 的系统调用，这些系统调用涉及文件系统、常规文件、目录及符号链接。 另外还有少数几个由 VFS 处理的其他系统调用：诸如 ioperm( )、ioctl( )、pipe( )和 mknod( )，涉及设备文件和管道文件，有些内容在下一章进行讨论。由 VFS 处理的最后一组 系统调用，诸如 socket( )、connect( )、bind( )和 protocols( )，属于套接字系统 调用并用于实现网络功能。 表 8.2 VFS 的部分系统调用 系统调用名 功能  mount( )/ umount( ) 安装/卸载文件系统 sysfs( ) 获取文件系统信息 statfs( )/ fstatfs( ) /ustat( ) 获取文件系统统计信息 chroot( ) 更改根目录 chdir( ) /fchdir( ) /getcwd( ) 更改当前目录 mkdir( ) /rmdir( ) 创建/删除目录 getdents( ) /readdir( )/ link( ) unlink( ) /rename( ) 对目录项进行操作 readlink( ) /symlink( ) 对软链接进行操作 chown( ) /fchown( ) /lchown( ) 更改文件所有者 chmod( )/ fchmod( ) /utime( ) 更改文件属性 stat( ) /fstat( ) /lstat( ) access( ) 读取文件状态 open( ) /close( ) /creat( ) /umask( ) 打开/关闭文件 dup( ) /dup2( ) /fcntl( ) 对文件描述符进行操作 select( ) /poll( ) 异步 I/O 通信 truncate( ) /ftruncate( ) 更改文件长度 lseek( ) /_llseek( ) 更改文件指针 read( )/ write( ) /readv( ) /writev( ) sendfile( ) 文件 I/O 操作 pread( )/ pwrite( ) 搜索并访问文件 mmap( ) /munmap( ) 文件内存映射 fdatasync( ) /fsync( ) /sync( )/ msync( ) 同步访问文件数据 flock( ) 处理文件锁



static void mlx5e_nic_enable(struct mlx5e_priv *priv)
    mlx5e_fs_init_l2_addr(priv->fs, netdev)
        ether_addr_copy(fs->l2.broadcast.addr, netdev->broadcast)
    mlx5e_ipsec_init -> net/mlx5e：支持 IPsec 核心的 devlink 重新加载，更改 IPsec 初始化流程以允许将来创建应在 devlink 重新加载操作期间释放和分配的硬件资源。 作为该更改的一部分，将函数签名更新为无效，因为没有调用者真正对其感兴趣
        ipsec = kzalloc(sizeof(*ipsec), GFP_KERNEL) -> net/mlx5e：IPSec、Innova IPSec 卸载基础设施、添加 Innova IPSec ESP 加密卸载配置路径。 检测 Innova IPSec 设备并设置 NETIF_F_HW_ESP 标志。 使用先前补丁中引入的 API 配置安全关联。 添加软件解析器硬件描述符布局 软件解析器 (swp) 是 ConnectX 中的一项硬件功能，它允许主机软件指定 TX 路径中的协议标头偏移量，从而覆盖硬件解析器。 这对于 ASIC 可能无法自行解析的协议很有用。 请注意，由于内联元数据，Innova IPSec 不支持 XDP
        xa_init_flags
        ipsec->wq = alloc_workqueue("mlx5e_ipsec: %s", WQ_UNBOUND, 0,
        mlx5e_ipsec_aso_init -> net/mlx5e：为 IPsec 创建高级转向操作对象，设置 IPsec 与软件堆栈交互所需的 ASO（高级转向操作）对象，以处理各种快速变化的事件：重播窗口、生命周期限制等
        mlx5e_is_uplink_rep -> net/mlx5e：为 switchdev 模式准备 IPsec 数据包卸载，由于仅在 switchdev 模式下创建上行链路表示器，因此为 IPsec 添加本地变量以指示设备处于此模式。 在此模式下，IPsec ROCE 被禁用，并且加密卸载保持原样。 但是，由于在 FDB 中创建了用于数据包卸载的表，因此添加了 ipsec->rx_esw 和 ipsec->tx_esw
        mlx5e_accel_ipsec_fs_init -> net/mlx5：将 devcom 指针存储在 IPsec RoCE 内，将 mlx5e priv devcom 组件存储在 IPsec RoCE 内，以使 IPsec RoCE 代码能够访问其他设备的私有信息。 这包括检索必要的设备信息和 IPsec 数据库，这有助于确定是否配置了 IPsec
    mlx5e_macsec_init -> net/mlx5e：为 MACsec 创建高级转向操作 (ASO) 对象，添加对 ASO 工作队列条目 (WQE) 数据的支持，以允许在查询 ASO 工作队列 (WQ) 时读取数据。 在 ASO WQ 初始化时注册用户模式内存注册 (UMR)，在 ASO WQ 清理时取消注册 UMR。 MACsec 使用 UMR 来确定硬件触发事件的原因，因为不同的场景可能会触发相同的事件。 设置 MACsec ASO 对象以将硬件与软件同步，了解各种 macsec 流状态功能，例如：重播窗口、生命周期限制等
    mlx5e_modify_admin_state(mdev, MLX5_PORT_DOWN)
    mlx5e_set_netdev_mtu_boundaries
    mlx5e_set_dev_port_mtu
    mlx5_lag_add_netdev
    mlx5e_enable_async_events
    mlx5e_enable_blocking_events
    mlx5e_monitor_counter_init
    mlx5e_hv_vhca_stats_create
    mlx5e_dcbnl_init_app
    mlx5e_nic_set_rx_mode
        mlx5_hv_vhca_agent_create
        INIT_DELAYED_WORK(&priv->stats_agent.work, mlx5e_hv_vhca_stats_work) -> net/mlx5e：添加 mlx5e HV VHCA 统计代理，HV VHCA 统计代理负责运行 preiodic rx/tx 数据包/字节统计更新。 目前支持的格式是版本 MLX5_HV_VHCA_STATS_VERSION。 块 ID 1 专用于从 VF 到 PF 的统计数据传输。 报告器从所有打开的通道中获取统计数据，将其填充到缓冲区中并将其发送到mlx5_hv_vhca_write_agent。 由于统计层应包含每个块的一些元数据（序列和偏移量），因此 HV VHCA 层应在通过块 1 实际发送缓冲区之前修改缓冲区
    mlx5e_open
    udp_tunnel_nic_reset_ntf -> udp_tunnel_nic_reset_ntf() - 设备发起的重置通知，@dev：网络接口设备结构 * 由驱动程序调用，通知核心整个 UDP 隧道端口状态已丢失，通常是由于设备重置。 核心将假定设备忘记了所有端口，并根据需要发出 .set_port 和 .sync_table 回调。 * 该函数必须在持有 rtnl 锁的情况下调用，并且会在返回之前发出所有回调
    netif_device_attach



常用常量, 
#define SZ_1				0x00000001
#define SZ_2				0x00000002
#define SZ_4				0x00000004
#define SZ_8				0x00000008
#define SZ_16				0x00000010
#define SZ_32				0x00000020
#define SZ_64				0x00000040
#define SZ_128				0x00000080
#define SZ_256				0x00000100
#define SZ_512				0x00000200

#define SZ_1K				0x00000400
#define SZ_2K				0x00000800
#define SZ_4K				0x00001000
#define SZ_8K				0x00002000
#define SZ_16K				0x00004000
#define SZ_32K				0x00008000
#define SZ_64K				0x00010000
#define SZ_128K				0x00020000
#define SZ_256K				0x00040000
#define SZ_512K				0x00080000

#define SZ_1M				0x00100000
#define SZ_2M				0x00200000
#define SZ_4M				0x00400000
#define SZ_8M				0x00800000
#define SZ_16M				0x01000000
#define SZ_32M				0x02000000
#define SZ_64M				0x04000000
#define SZ_128M				0x08000000
#define SZ_256M				0x10000000
#define SZ_512M				0x20000000

#define SZ_1G				0x40000000
#define SZ_2G				0x80000000

#define SZ_4G				_AC(0x100000000, ULL)




register addr,
static int irdma_probe(
    struct ice_pf *pf = iidc_adev->pf
    irdma_fill_device_info(iwdev, pf, vsi)
        rf->hw.hw_addr = pf->hw.hw_addr; <- info.bar0 = rf->hw.hw_addr;
    irdma_ctrl_init_hw
        irdma_setup_init_state
            static int irdma_initialize_dev
                info.bar0 = rf->hw.hw_addr;
                irdma_sc_dev_init
                    dev->hw->hw_addr = info->bar0
                    irdma_sc_init_hw                    
                        icrdma_init_hw
                            dev->hw_regs[i] = (u32 __iomem *)(hw_addr + icrdma_regs[i])

irdma_sc_cqp_get_next_send_wqe_idx
    IRDMA_ATOMIC_RING_MOVE_HEAD(cqp->sq_ring, *wqe_idx, ret_code)
    wqe = cqp->sq_base[*wqe_idx].elem -> 从DMA的VA基址依次往后填充
    IRDMA_CQP_INIT_WQE(wqe) -> #define IRDMA_CQP_INIT_WQE(wqe) memset(wqe, 0, 64) -> WQE大小为64字节



ring, 环形链表, 从头部取出一个元数后, 将头指针向后移动一位
#define IRDMA_RING_MOVE_HEAD(_ring, _retcode) \
	{ \
		register u32 size; \
		size = (_ring).size;  \
		if (!IRDMA_RING_FULL_ERR(_ring)) { \
			(_ring).head = ((_ring).head + 1) % size; \
			(_retcode) = 0; \
		} else { \
			(_retcode) = -ENOMEM; \
		} \
	}

分配一段设备和软件共享的DMA内存, 作为发送队列的内存, 起始VA作为发送队列的基址
cqp->sq.va = dma_alloc_coherent(dev->hw->device, cqp->sq.size, &cqp->sq.pa, GFP_KERNEL);


puda: privileged UDA




(gdb) bt
#0  is_ndev_for_default_gid_filter (ib_dev=ib_dev@entry=0xffff88812f172000, port=port@entry=1, rdma_ndev=rdma_ndev@entry=0xffff888034014000, cookie=cookie@entry=0xffff888100db3000)
    at drivers/infiniband/core/roce_gid_mgmt.c:203
#1  0xffffffffc079f758 in enum_all_gids_of_dev_cb (ib_dev=ib_dev@entry=0xffff88812f172000, port=port@entry=1, rdma_ndev=rdma_ndev@entry=0xffff888034014000, cookie=cookie@entry=0x0 <fixed_percpu_data>)
    at drivers/infiniband/core/roce_gid_mgmt.c:493
#2  0xffffffffc079b2fc in ib_enum_roce_netdev (ib_dev=ib_dev@entry=0xffff88812f172000, filter=filter@entry=0xffffffffc079e390 <pass_all_filter>, filter_cookie=filter_cookie@entry=0x0 <fixed_percpu_data>, 
    cb=cb@entry=0xffffffffc079f6c0 <enum_all_gids_of_dev_cb>, cookie=cookie@entry=0x0 <fixed_percpu_data>) at drivers/infiniband/core/device.c:2303
#3  0xffffffffc079e3c1 in rdma_roce_rescan_device (ib_dev=ib_dev@entry=0xffff88812f172000) at drivers/infiniband/core/roce_gid_mgmt.c:513
#4  0xffffffffc079d7c9 in gid_table_setup_one (ib_dev=ib_dev@entry=0xffff88812f172000) at drivers/infiniband/core/cache.c:934
#5  ib_cache_setup_one (device=device@entry=0xffff88812f172000) at drivers/infiniband/core/cache.c:1624
#6  0xffffffffc079a19c in ib_register_device (name=<optimized out>, dma_device=<optimized out>, device=0xffff88812f172000) at drivers/infiniband/core/device.c:1386
#7  ib_register_device (device=0xffff88812f172000, name=<optimized out>, dma_device=<optimized out>) at drivers/infiniband/core/device.c:1365
#8  0xffffffffc06d7d70 in rxe_register_device () at drivers/infiniband/core/device.c:2859
#9  0xffffffffc06cf628 in rxe_add () at drivers/infiniband/core/device.c:2859
#10 0xffffffffc06dd772 in rxe_net_add () at drivers/infiniband/core/device.c:2859
#11 0xffffffffc06cf063 in rxe_newlink () at drivers/infiniband/core/device.c:2859


